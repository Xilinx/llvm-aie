# NOTE: Assertions have been autogenerated by utils/update_mir_test_checks.py
#
# This file is licensed under the Apache License v2.0 with LLVM Exceptions.
# See https://llvm.org/LICENSE.txt for license information.
# SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
#
# (c) Copyright 2024 Advanced Micro Devices, Inc. or its affiliates
# RUN: llc -mtriple aie2 -run-pass=aie2-postlegalizer-custom-combiner %s -verify-machineinstrs -o - | FileCheck %s



---
name:            upd_I512.I256
body:             |
  bb.0:
    liveins: $p0, $wl2, $wl3
    ; CHECK-LABEL: name: upd_I512.I256
    ; CHECK: liveins: $p0, $wl2, $wl3
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(<32 x s8>) = COPY $wl2
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(<32 x s8>) = COPY $wl3
    ; CHECK-NEXT: [[BITCAST:%[0-9]+]]:_(<8 x s32>) = G_BITCAST [[COPY]](<32 x s8>)
    ; CHECK-NEXT: [[BITCAST1:%[0-9]+]]:_(<8 x s32>) = G_BITCAST [[COPY1]](<32 x s8>)
    ; CHECK-NEXT: [[CONCAT_VECTORS:%[0-9]+]]:_(<16 x s32>) = G_CONCAT_VECTORS [[BITCAST]](<8 x s32>), [[BITCAST1]](<8 x s32>)
    ; CHECK-NEXT: $x0 = COPY [[CONCAT_VECTORS]](<16 x s32>)
    %95:_(<32 x s8>) = COPY $wl2
    %98:_(<32 x s8>) = COPY $wl3
    %8:_(<64 x s8>) = G_INTRINSIC intrinsic(@llvm.aie2.v64int8)
    %9:_(<16 x s32>) = G_BITCAST %8(<64 x s8>)
    %21:_(s32) = G_CONSTANT i32 0
    %51:_(s32) = G_CONSTANT i32 1
    %96:_(<8 x s32>) = G_BITCAST %95(<32 x s8>)
    %97:_(<16 x s32>) = G_INTRINSIC intrinsic(@llvm.aie2.upd.I512.I256), %9(<16 x s32>), %96(<8 x s32>), %21(s32)
    %99:_(<8 x s32>) = G_BITCAST %98(<32 x s8>)
    %100:_(<16 x s32>) = G_INTRINSIC intrinsic(@llvm.aie2.upd.I512.I256), %97(<16 x s32>), %99(<8 x s32>), %51(s32)
    $x0 = COPY %100:_(<16 x s32>)
...

---
name:            upd_I1024.I256
body:             |
  bb.0:
    liveins: $p0, $wl2, $wl3, $wl4, $wl4
    ; CHECK-LABEL: name: upd_I1024.I256
    ; CHECK: liveins: $p0, $wl2, $wl3, $wl4, $wl4
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(<32 x s8>) = COPY $wl2
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(<32 x s8>) = COPY $wl3
    ; CHECK-NEXT: [[COPY2:%[0-9]+]]:_(<32 x s8>) = COPY $wl4
    ; CHECK-NEXT: [[COPY3:%[0-9]+]]:_(<32 x s8>) = COPY $wl5
    ; CHECK-NEXT: [[BITCAST:%[0-9]+]]:_(<8 x s32>) = G_BITCAST [[COPY]](<32 x s8>)
    ; CHECK-NEXT: [[BITCAST1:%[0-9]+]]:_(<8 x s32>) = G_BITCAST [[COPY1]](<32 x s8>)
    ; CHECK-NEXT: [[BITCAST2:%[0-9]+]]:_(<8 x s32>) = G_BITCAST [[COPY2]](<32 x s8>)
    ; CHECK-NEXT: [[BITCAST3:%[0-9]+]]:_(<8 x s32>) = G_BITCAST [[COPY3]](<32 x s8>)
    ; CHECK-NEXT: [[CONCAT_VECTORS:%[0-9]+]]:_(<32 x s32>) = G_CONCAT_VECTORS [[BITCAST]](<8 x s32>), [[BITCAST1]](<8 x s32>), [[BITCAST2]](<8 x s32>), [[BITCAST3]](<8 x s32>)
    ; CHECK-NEXT: $y2 = COPY [[CONCAT_VECTORS]](<32 x s32>)
    %10:_(<32 x s8>) = COPY $wl2
    %15:_(<32 x s8>) = COPY $wl3
    %20:_(<32 x s8>) = COPY $wl4
    %25:_(<32 x s8>) = COPY $wl5
    %8:_(<128 x s8>) = G_INTRINSIC intrinsic(@llvm.aie2.v128int8)
    %9:_(<32 x s32>) = G_BITCAST %8(<128 x s8>)
    %21:_(s32) = G_CONSTANT i32 0
    %51:_(s32) = G_CONSTANT i32 1
    %61:_(s32) = G_CONSTANT i32 2
    %71:_(s32) = G_CONSTANT i32 3
    %96:_(<8 x s32>) = G_BITCAST %10(<32 x s8>)
    %97:_(<32 x s32>) = G_INTRINSIC intrinsic(@llvm.aie2.upd.I1024.I256), %9(<32 x s32>), %96(<8 x s32>), %21(s32)
    %90:_(<8 x s32>) = G_BITCAST %15(<32 x s8>)
    %100:_(<32 x s32>) = G_INTRINSIC intrinsic(@llvm.aie2.upd.I1024.I256), %97(<32 x s32>), %90(<8 x s32>), %51(s32)
    %91:_(<8 x s32>) = G_BITCAST %20(<32 x s8>)
    %110:_(<32 x s32>) = G_INTRINSIC intrinsic(@llvm.aie2.upd.I1024.I256), %100(<32 x s32>), %91(<8 x s32>), %61(s32)
    %92:_(<8 x s32>) = G_BITCAST %25(<32 x s8>)
    %120:_(<32 x s32>) = G_INTRINSIC intrinsic(@llvm.aie2.upd.I1024.I256), %110(<32 x s32>), %92(<8 x s32>), %71(s32)
    %252:_(<8 x s32>), %253:_(<8 x s32>), %254:_(<8 x s32>), %255:_(<8 x s32>) = G_UNMERGE_VALUES %120(<32 x s32>)
    $y2 = COPY %120:_(<32 x s32>)
...

---
name:            upd_I1024.I256_fail_missing_upd
body:             |
  bb.0:
    liveins: $p0, $wl3, $wl4, $wl4
    ; CHECK-LABEL: name: upd_I1024.I256_fail_missing_upd
    ; CHECK: liveins: $p0, $wl3, $wl4, $wl4
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(<32 x s8>) = COPY $wl3
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(<32 x s8>) = COPY $wl4
    ; CHECK-NEXT: [[COPY2:%[0-9]+]]:_(<32 x s8>) = COPY $wl5
    ; CHECK-NEXT: [[INT:%[0-9]+]]:_(<128 x s8>) = G_INTRINSIC intrinsic(@llvm.aie2.v128int8)
    ; CHECK-NEXT: [[BITCAST:%[0-9]+]]:_(<32 x s32>) = G_BITCAST [[INT]](<128 x s8>)
    ; CHECK-NEXT: [[C:%[0-9]+]]:_(s32) = G_CONSTANT i32 1
    ; CHECK-NEXT: [[C1:%[0-9]+]]:_(s32) = G_CONSTANT i32 2
    ; CHECK-NEXT: [[C2:%[0-9]+]]:_(s32) = G_CONSTANT i32 3
    ; CHECK-NEXT: [[BITCAST1:%[0-9]+]]:_(<8 x s32>) = G_BITCAST [[COPY]](<32 x s8>)
    ; CHECK-NEXT: [[INT1:%[0-9]+]]:_(<32 x s32>) = G_INTRINSIC intrinsic(@llvm.aie2.upd.I1024.I256), [[BITCAST]](<32 x s32>), [[BITCAST1]](<8 x s32>), [[C]](s32)
    ; CHECK-NEXT: [[BITCAST2:%[0-9]+]]:_(<8 x s32>) = G_BITCAST [[COPY1]](<32 x s8>)
    ; CHECK-NEXT: [[INT2:%[0-9]+]]:_(<32 x s32>) = G_INTRINSIC intrinsic(@llvm.aie2.upd.I1024.I256), [[INT1]](<32 x s32>), [[BITCAST2]](<8 x s32>), [[C1]](s32)
    ; CHECK-NEXT: [[BITCAST3:%[0-9]+]]:_(<8 x s32>) = G_BITCAST [[COPY2]](<32 x s8>)
    ; CHECK-NEXT: [[INT3:%[0-9]+]]:_(<32 x s32>) = G_INTRINSIC intrinsic(@llvm.aie2.upd.I1024.I256), [[INT2]](<32 x s32>), [[BITCAST3]](<8 x s32>), [[C2]](s32)
    ; CHECK-NEXT: [[UV:%[0-9]+]]:_(<8 x s32>), [[UV1:%[0-9]+]]:_(<8 x s32>), [[UV2:%[0-9]+]]:_(<8 x s32>), [[UV3:%[0-9]+]]:_(<8 x s32>) = G_UNMERGE_VALUES [[INT3]](<32 x s32>)
    ; CHECK-NEXT: $wl0 = COPY [[UV]](<8 x s32>)
    ; CHECK-NEXT: $wl1 = COPY [[UV1]](<8 x s32>)
    ; CHECK-NEXT: $wh0 = COPY [[UV2]](<8 x s32>)
    ; CHECK-NEXT: $wh1 = COPY [[UV3]](<8 x s32>)
    %15:_(<32 x s8>) = COPY $wl3
    %20:_(<32 x s8>) = COPY $wl4
    %25:_(<32 x s8>) = COPY $wl5
    %8:_(<128 x s8>) = G_INTRINSIC intrinsic(@llvm.aie2.v128int8)
    %9:_(<32 x s32>) = G_BITCAST %8(<128 x s8>)
    %21:_(s32) = G_CONSTANT i32 0
    %51:_(s32) = G_CONSTANT i32 1
    %61:_(s32) = G_CONSTANT i32 2
    %71:_(s32) = G_CONSTANT i32 3
    %90:_(<8 x s32>) = G_BITCAST %15(<32 x s8>)
    %100:_(<32 x s32>) = G_INTRINSIC intrinsic(@llvm.aie2.upd.I1024.I256), %9(<32 x s32>), %90(<8 x s32>), %51(s32)
    %91:_(<8 x s32>) = G_BITCAST %20(<32 x s8>)
    %110:_(<32 x s32>) = G_INTRINSIC intrinsic(@llvm.aie2.upd.I1024.I256), %100(<32 x s32>), %91(<8 x s32>), %61(s32)
    %92:_(<8 x s32>) = G_BITCAST %25(<32 x s8>)
    %120:_(<32 x s32>) = G_INTRINSIC intrinsic(@llvm.aie2.upd.I1024.I256), %110(<32 x s32>), %92(<8 x s32>), %71(s32)
    %252:_(<8 x s32>), %253:_(<8 x s32>), %254:_(<8 x s32>), %255:_(<8 x s32>) = G_UNMERGE_VALUES %120(<32 x s32>)
    $wl0 = COPY %252:_(<8 x s32>)
    $wl1 = COPY %253:_(<8 x s32>)
    $wh0 = COPY %254:_(<8 x s32>)
    $wh1 = COPY %255:_(<8 x s32>)
...

---
name:            upd_I1024.I256_fail_duplicated_upd
body:             |
  bb.0:
    liveins: $p0, $wl2, $wl3, $wl4, $wl4
    ; CHECK-LABEL: name: upd_I1024.I256_fail_duplicated_upd
    ; CHECK: liveins: $p0, $wl2, $wl3, $wl4, $wl4
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(<32 x s8>) = COPY $wl2
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(<32 x s8>) = COPY $wl3
    ; CHECK-NEXT: [[COPY2:%[0-9]+]]:_(<32 x s8>) = COPY $wl4
    ; CHECK-NEXT: [[COPY3:%[0-9]+]]:_(<32 x s8>) = COPY $wl5
    ; CHECK-NEXT: [[INT:%[0-9]+]]:_(<128 x s8>) = G_INTRINSIC intrinsic(@llvm.aie2.v128int8)
    ; CHECK-NEXT: [[BITCAST:%[0-9]+]]:_(<32 x s32>) = G_BITCAST [[INT]](<128 x s8>)
    ; CHECK-NEXT: [[C:%[0-9]+]]:_(s32) = G_CONSTANT i32 0
    ; CHECK-NEXT: [[C1:%[0-9]+]]:_(s32) = G_CONSTANT i32 2
    ; CHECK-NEXT: [[C2:%[0-9]+]]:_(s32) = G_CONSTANT i32 3
    ; CHECK-NEXT: [[BITCAST1:%[0-9]+]]:_(<8 x s32>) = G_BITCAST [[COPY]](<32 x s8>)
    ; CHECK-NEXT: [[INT1:%[0-9]+]]:_(<32 x s32>) = G_INTRINSIC intrinsic(@llvm.aie2.upd.I1024.I256), [[BITCAST]](<32 x s32>), [[BITCAST1]](<8 x s32>), [[C]](s32)
    ; CHECK-NEXT: [[BITCAST2:%[0-9]+]]:_(<8 x s32>) = G_BITCAST [[COPY1]](<32 x s8>)
    ; CHECK-NEXT: [[INT2:%[0-9]+]]:_(<32 x s32>) = G_INTRINSIC intrinsic(@llvm.aie2.upd.I1024.I256), [[INT1]](<32 x s32>), [[BITCAST2]](<8 x s32>), [[C]](s32)
    ; CHECK-NEXT: [[BITCAST3:%[0-9]+]]:_(<8 x s32>) = G_BITCAST [[COPY2]](<32 x s8>)
    ; CHECK-NEXT: [[INT3:%[0-9]+]]:_(<32 x s32>) = G_INTRINSIC intrinsic(@llvm.aie2.upd.I1024.I256), [[INT2]](<32 x s32>), [[BITCAST3]](<8 x s32>), [[C1]](s32)
    ; CHECK-NEXT: [[BITCAST4:%[0-9]+]]:_(<8 x s32>) = G_BITCAST [[COPY3]](<32 x s8>)
    ; CHECK-NEXT: [[INT4:%[0-9]+]]:_(<32 x s32>) = G_INTRINSIC intrinsic(@llvm.aie2.upd.I1024.I256), [[INT3]](<32 x s32>), [[BITCAST4]](<8 x s32>), [[C2]](s32)
    ; CHECK-NEXT: [[UV:%[0-9]+]]:_(<8 x s32>), [[UV1:%[0-9]+]]:_(<8 x s32>), [[UV2:%[0-9]+]]:_(<8 x s32>), [[UV3:%[0-9]+]]:_(<8 x s32>) = G_UNMERGE_VALUES [[INT4]](<32 x s32>)
    ; CHECK-NEXT: $wl0 = COPY [[UV]](<8 x s32>)
    ; CHECK-NEXT: $wl1 = COPY [[UV1]](<8 x s32>)
    ; CHECK-NEXT: $wh0 = COPY [[UV2]](<8 x s32>)
    ; CHECK-NEXT: $wh1 = COPY [[UV3]](<8 x s32>)
    %10:_(<32 x s8>) = COPY $wl2
    %15:_(<32 x s8>) = COPY $wl3
    %20:_(<32 x s8>) = COPY $wl4
    %25:_(<32 x s8>) = COPY $wl5
    %8:_(<128 x s8>) = G_INTRINSIC intrinsic(@llvm.aie2.v128int8)
    %9:_(<32 x s32>) = G_BITCAST %8(<128 x s8>)
    %21:_(s32) = G_CONSTANT i32 0
    %61:_(s32) = G_CONSTANT i32 2
    %71:_(s32) = G_CONSTANT i32 3
    %96:_(<8 x s32>) = G_BITCAST %10(<32 x s8>)
    %97:_(<32 x s32>) = G_INTRINSIC intrinsic(@llvm.aie2.upd.I1024.I256), %9(<32 x s32>), %96(<8 x s32>), %21(s32)
    %90:_(<8 x s32>) = G_BITCAST %15(<32 x s8>)
    %100:_(<32 x s32>) = G_INTRINSIC intrinsic(@llvm.aie2.upd.I1024.I256), %97(<32 x s32>), %90(<8 x s32>), %21(s32)
    %91:_(<8 x s32>) = G_BITCAST %20(<32 x s8>)
    %110:_(<32 x s32>) = G_INTRINSIC intrinsic(@llvm.aie2.upd.I1024.I256), %100(<32 x s32>), %91(<8 x s32>), %61(s32)
    %92:_(<8 x s32>) = G_BITCAST %25(<32 x s8>)
    %120:_(<32 x s32>) = G_INTRINSIC intrinsic(@llvm.aie2.upd.I1024.I256), %110(<32 x s32>), %92(<8 x s32>), %71(s32)
    %252:_(<8 x s32>), %253:_(<8 x s32>), %254:_(<8 x s32>), %255:_(<8 x s32>) = G_UNMERGE_VALUES %120(<32 x s32>)
    $wl0 = COPY %252:_(<8 x s32>)
    $wl1 = COPY %253:_(<8 x s32>)
    $wh0 = COPY %254:_(<8 x s32>)
    $wh1 = COPY %255:_(<8 x s32>)
...
