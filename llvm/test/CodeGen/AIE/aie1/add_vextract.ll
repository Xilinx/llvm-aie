;
; This file is licensed under the Apache License v2.0 with LLVM Exceptions.
; See https://llvm.org/LICENSE.txt for license information.
; SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
;
; (c) Copyright 2023-2024 Advanced Micro Devices, Inc. or its affiliates
; RUN: llc -mtriple=aie --issue-limit=1 -verify-machineinstrs < %s | FileCheck %s

; This code is generated by clang -O2 from the following code:
; It's complex because clang attempts to partially unroll the loop.
;
; extern float buf0[8];
; extern float buf1[8];
; extern float buf2[8];
; extern "C" void _main(int n)
; {
;   union caster { int i; float f;};
;   caster nan;
;   nan.i = 0x7F800001;
;   buf0[5] = nan.f;
;   for(int i = 0; i < n; i++)
;     buf2[i] = buf0[i] + buf1[i];
; }


; ModuleID = 'add_vextract.cc'
source_filename = "add_vextract.cc"
target datalayout = "e-m:e-p:20:32-i1:8:32-i8:8:32-i16:16:32-i32:32:32-f32:32:32-i64:32-f64:32-a:0:32-n32"
target triple = "aie"

@buf0 = external dso_local local_unnamed_addr global [8 x float], align 4
@buf1 = external dso_local local_unnamed_addr global [8 x float], align 4
@buf2 = external dso_local local_unnamed_addr global [8 x float], align 4

; Function Attrs: mustprogress nofree norecurse nosync nounwind
define dso_local void @_main(i32 noundef %n) local_unnamed_addr #0 {
; CHECK-LABEL: _main:
; CHECK:         bnez {{r.*}}, .LBB0_7
; CHECK:       .LBB0_1: // %for.body.preheader
; CHECK:         bnez {{r.*}}, .LBB0_4
; CHECK:       .LBB0_2: // %for.body.preheader.new
; CHECK:       .LBB0_3: // %for.body
; CHECK:         vfpmac
; CHECK:         vfpmac
; CHECK:         vfpmac
; CHECK:         vfpmac
; CHECK:         vfpmac
; CHECK:         vfpmac
; CHECK:         vfpmac
; CHECK:         vfpmac
; CHECK:         beqz {{r.*}}, .LBB0_3
; CHECK:       .LBB0_4: // %for.cond.cleanup.loopexit.unr-lcssa
; CHECK:         bnez {{r.*}}, .LBB0_7
; CHECK:       .LBB0_5: // %for.body.epil.preheader
; CHECK:       .LBB0_6: // %for.body.epil
; CHECK:         vfpmac
; CHECK:         bnez {{r.*}}, .LBB0_6
; CHECK:       .LBB0_7: // %for.cond.cleanup
; CHECK:         ret lr
entry:
  store float 0x7FF0000020000000, float* getelementptr inbounds ([8 x float], [8 x float]* @buf0, i20 0, i20 5), align 4, !tbaa !2
  %cmp10 = icmp sgt i32 %n, 0
  br i1 %cmp10, label %for.body.preheader, label %for.cond.cleanup

for.body.preheader:                               ; preds = %entry
  %0 = add i32 %n, -1
  %xtraiter = and i32 %n, 7
  %1 = icmp ult i32 %0, 7
  br i1 %1, label %for.cond.cleanup.loopexit.unr-lcssa, label %for.body.preheader.new

for.body.preheader.new:                           ; preds = %for.body.preheader
  %unroll_iter = and i32 %n, -8
  br label %for.body

for.cond.cleanup.loopexit.unr-lcssa:              ; preds = %for.body, %for.body.preheader
  %i1.011.unr = phi i32 [ 0, %for.body.preheader ], [ %inc.7, %for.body ]
  %lcmp.mod.not = icmp eq i32 %xtraiter, 0
  br i1 %lcmp.mod.not, label %for.cond.cleanup, label %for.body.epil

for.body.epil:                                    ; preds = %for.cond.cleanup.loopexit.unr-lcssa, %for.body.epil
  %i1.011.epil = phi i32 [ %inc.epil, %for.body.epil ], [ %i1.011.unr, %for.cond.cleanup.loopexit.unr-lcssa ]
  %epil.iter = phi i32 [ %epil.iter.next, %for.body.epil ], [ 0, %for.cond.cleanup.loopexit.unr-lcssa ]
  %2 = trunc i32 %i1.011.epil to i20
  %arrayidx.epil = getelementptr inbounds [8 x float], [8 x float]* @buf0, i20 0, i20 %2
  %3 = load float, float* %arrayidx.epil, align 4, !tbaa !2
  %arrayidx2.epil = getelementptr inbounds [8 x float], [8 x float]* @buf1, i20 0, i20 %2
  %4 = load float, float* %arrayidx2.epil, align 4, !tbaa !2
  %add.epil = fadd float %3, %4
  %arrayidx3.epil = getelementptr inbounds [8 x float], [8 x float]* @buf2, i20 0, i20 %2
  store float %add.epil, float* %arrayidx3.epil, align 4, !tbaa !2
  %inc.epil = add nuw nsw i32 %i1.011.epil, 1
  %epil.iter.next = add i32 %epil.iter, 1
  %epil.iter.cmp.not = icmp eq i32 %epil.iter.next, %xtraiter
  br i1 %epil.iter.cmp.not, label %for.cond.cleanup, label %for.body.epil, !llvm.loop !6

for.cond.cleanup:                                 ; preds = %for.cond.cleanup.loopexit.unr-lcssa, %for.body.epil, %entry
  ret void

for.body:                                         ; preds = %for.body, %for.body.preheader.new
  %i1.011 = phi i32 [ 0, %for.body.preheader.new ], [ %inc.7, %for.body ]
  %niter = phi i32 [ 0, %for.body.preheader.new ], [ %niter.next.7, %for.body ]
  %5 = trunc i32 %i1.011 to i20
  %arrayidx = getelementptr inbounds [8 x float], [8 x float]* @buf0, i20 0, i20 %5
  %6 = load float, float* %arrayidx, align 4, !tbaa !2
  %arrayidx2 = getelementptr inbounds [8 x float], [8 x float]* @buf1, i20 0, i20 %5
  %7 = load float, float* %arrayidx2, align 4, !tbaa !2
  %add = fadd float %6, %7
  %arrayidx3 = getelementptr inbounds [8 x float], [8 x float]* @buf2, i20 0, i20 %5
  store float %add, float* %arrayidx3, align 4, !tbaa !2
  %inc = or i32 %i1.011, 1
  %8 = trunc i32 %inc to i20
  %arrayidx.1 = getelementptr inbounds [8 x float], [8 x float]* @buf0, i20 0, i20 %8
  %9 = load float, float* %arrayidx.1, align 4, !tbaa !2
  %arrayidx2.1 = getelementptr inbounds [8 x float], [8 x float]* @buf1, i20 0, i20 %8
  %10 = load float, float* %arrayidx2.1, align 4, !tbaa !2
  %add.1 = fadd float %9, %10
  %arrayidx3.1 = getelementptr inbounds [8 x float], [8 x float]* @buf2, i20 0, i20 %8
  store float %add.1, float* %arrayidx3.1, align 4, !tbaa !2
  %inc.1 = or i32 %i1.011, 2
  %11 = trunc i32 %inc.1 to i20
  %arrayidx.2 = getelementptr inbounds [8 x float], [8 x float]* @buf0, i20 0, i20 %11
  %12 = load float, float* %arrayidx.2, align 4, !tbaa !2
  %arrayidx2.2 = getelementptr inbounds [8 x float], [8 x float]* @buf1, i20 0, i20 %11
  %13 = load float, float* %arrayidx2.2, align 4, !tbaa !2
  %add.2 = fadd float %12, %13
  %arrayidx3.2 = getelementptr inbounds [8 x float], [8 x float]* @buf2, i20 0, i20 %11
  store float %add.2, float* %arrayidx3.2, align 4, !tbaa !2
  %inc.2 = or i32 %i1.011, 3
  %14 = trunc i32 %inc.2 to i20
  %arrayidx.3 = getelementptr inbounds [8 x float], [8 x float]* @buf0, i20 0, i20 %14
  %15 = load float, float* %arrayidx.3, align 4, !tbaa !2
  %arrayidx2.3 = getelementptr inbounds [8 x float], [8 x float]* @buf1, i20 0, i20 %14
  %16 = load float, float* %arrayidx2.3, align 4, !tbaa !2
  %add.3 = fadd float %15, %16
  %arrayidx3.3 = getelementptr inbounds [8 x float], [8 x float]* @buf2, i20 0, i20 %14
  store float %add.3, float* %arrayidx3.3, align 4, !tbaa !2
  %inc.3 = or i32 %i1.011, 4
  %17 = trunc i32 %inc.3 to i20
  %arrayidx.4 = getelementptr inbounds [8 x float], [8 x float]* @buf0, i20 0, i20 %17
  %18 = load float, float* %arrayidx.4, align 4, !tbaa !2
  %arrayidx2.4 = getelementptr inbounds [8 x float], [8 x float]* @buf1, i20 0, i20 %17
  %19 = load float, float* %arrayidx2.4, align 4, !tbaa !2
  %add.4 = fadd float %18, %19
  %arrayidx3.4 = getelementptr inbounds [8 x float], [8 x float]* @buf2, i20 0, i20 %17
  store float %add.4, float* %arrayidx3.4, align 4, !tbaa !2
  %inc.4 = or i32 %i1.011, 5
  %20 = trunc i32 %inc.4 to i20
  %arrayidx.5 = getelementptr inbounds [8 x float], [8 x float]* @buf0, i20 0, i20 %20
  %21 = load float, float* %arrayidx.5, align 4, !tbaa !2
  %arrayidx2.5 = getelementptr inbounds [8 x float], [8 x float]* @buf1, i20 0, i20 %20
  %22 = load float, float* %arrayidx2.5, align 4, !tbaa !2
  %add.5 = fadd float %21, %22
  %arrayidx3.5 = getelementptr inbounds [8 x float], [8 x float]* @buf2, i20 0, i20 %20
  store float %add.5, float* %arrayidx3.5, align 4, !tbaa !2
  %inc.5 = or i32 %i1.011, 6
  %23 = trunc i32 %inc.5 to i20
  %arrayidx.6 = getelementptr inbounds [8 x float], [8 x float]* @buf0, i20 0, i20 %23
  %24 = load float, float* %arrayidx.6, align 4, !tbaa !2
  %arrayidx2.6 = getelementptr inbounds [8 x float], [8 x float]* @buf1, i20 0, i20 %23
  %25 = load float, float* %arrayidx2.6, align 4, !tbaa !2
  %add.6 = fadd float %24, %25
  %arrayidx3.6 = getelementptr inbounds [8 x float], [8 x float]* @buf2, i20 0, i20 %23
  store float %add.6, float* %arrayidx3.6, align 4, !tbaa !2
  %inc.6 = or i32 %i1.011, 7
  %26 = trunc i32 %inc.6 to i20
  %arrayidx.7 = getelementptr inbounds [8 x float], [8 x float]* @buf0, i20 0, i20 %26
  %27 = load float, float* %arrayidx.7, align 4, !tbaa !2
  %arrayidx2.7 = getelementptr inbounds [8 x float], [8 x float]* @buf1, i20 0, i20 %26
  %28 = load float, float* %arrayidx2.7, align 4, !tbaa !2
  %add.7 = fadd float %27, %28
  %arrayidx3.7 = getelementptr inbounds [8 x float], [8 x float]* @buf2, i20 0, i20 %26
  store float %add.7, float* %arrayidx3.7, align 4, !tbaa !2
  %inc.7 = add nuw nsw i32 %i1.011, 8
  %niter.next.7 = add i32 %niter, 8
  %niter.ncmp.7 = icmp eq i32 %niter.next.7, %unroll_iter
  br i1 %niter.ncmp.7, label %for.cond.cleanup.loopexit.unr-lcssa, label %for.body, !llvm.loop !8
}

attributes #0 = { mustprogress nofree norecurse nosync nounwind "frame-pointer"="none" "min-legal-vector-width"="0" "no-builtins" "no-trapping-math"="true" "stack-protector-buffer-size"="8" }

!llvm.module.flags = !{!0}
!llvm.ident = !{!1}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{!"clang version 15.0.0"}
!2 = !{!3, !3, i64 0}
!3 = !{!"float", !4, i64 0}
!4 = !{!"omnipotent char", !5, i64 0}
!5 = !{!"Simple C++ TBAA"}
!6 = distinct !{!6, !7}
!7 = !{!"llvm.loop.unroll.disable"}
!8 = distinct !{!8, !9}
!9 = !{!"llvm.loop.mustprogress"}
