; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
;
; This file is licensed under the Apache License v2.0 with LLVM Exceptions.
; See https://llvm.org/LICENSE.txt for license information.
; SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
;
; (c) Copyright 2024 Advanced Micro Devices, Inc. or its affiliates
; RUN: llc -O2 -mtriple=aie2 --enable-pipeliner=1 --enable-aie-hardware-loops=false \
; RUN:     --enable-aie-zero-overhead-loops=false %s -o - | FileCheck %s --check-prefix=DCL
; RUN: llc -O2 -mtriple=aie2 --enable-pipeliner=1 %s -o - | FileCheck %s --check-prefix=ZOL
; RUN: llc -O2 -mtriple=aie2 --enable-pipeliner=0 %s -o - --debug-only=machine-scheduler  \
; RUN:    2>&1 | %imisched -d - \
; RUN:    | FileCheck %s --check-prefix=SCHED-DUMP

; Variation of the already existent test, but enabling SWP under different flavors:
; *DownCountLoops (DCL),
; *ZeroOverheadLoops (ZOL).

; This is a reduced version of the Conv2D_0 MLLib benchmark which only contains
; the interesting loop nest. It was obtained with this command:
; ```
; export PATH=build/bin
; llvm-extract --bb='conv2d_fn:for.body.i112;for.body104.i;for.cond.cleanup103.i' Conv2D.ll \
;   | opt -strip-debug | llvm-dis -o Conv2D-red.ll
; ```
; Note that some manual intervention is still needed to:
; - Change the mangled name of the conv2d<> function into conv2d_fn in the original IR
; - Remove the (rather useless) !noalias metadata in extracted IR
; - Rename BBs to human-readable names in extracted IR.

; The test is meant as a quick way to spot QoR regressions, but if the ASM is
; too unstable, we can use different FileCheck lines.


; SCHED-DUMP: Region: conv2d.loop.nest:bb.2
; SCHED-DUMP: Region: conv2d.loop.nest:bb.4
; SCHED-DUMP: Region: conv2d.loop.nest:bb.3
; SCHED-DUMP: Region: conv2d.loop.nest:bb.1
; SCHED-DUMP: Region: conv2d.loop.nest:bb.0

define dso_local void @conv2d.loop.nest(ptr %add.ptr6.i51, ptr %add.ptr5, ptr %cond, ptr %cond.i50, <16 x i32> %0, i32 %cond67.i79, i20 %idx.ext.i.i81, i20 %idx.ext.i404.i, i20 %idx.ext.i410.i, i20 %idx.ext.i434.i85, i32 %1, i20 %2, i20 %3, i20 %4, i20 %5, i20 %6, i32 %7, i32 %8, i32 %or9.i.i.i.i.i96, i32 %9, i20 %idx.ext.i422.i82, i20 %10, i20 %11, i20 %12, i20 %13, i20 %14, i20 %15, i20 %16, i20 %17, i20 %18, i20 %19, i20 %20, i20 %21, i20 %22, i20 %23, i32 %conv192.i107, i20 %24, i20 %idx.ext.i428.i, i20 %25, i20 %26, i20 %27, i32 %28) #1 {
; ASM-LABEL: conv2d.loop.nest:
; ASM:         .p2align 4
; ASM-NEXT:  // %bb.0: // %newFuncRoot
; ASM-NEXT:    mova dj3, #0; nopb ; nopx
; ASM-NEXT:    mov s0, r0
; ASM-NEXT:    mov s1, r1
; ASM-NEXT:    mov s2, r6
; ASM-NEXT:    mov m5, p4
; ASM-NEXT:    mov m4, p5
; ASM-NEXT:    mov dc0, dj3
; ASM-NEXT:    mov dc4, dj3
; ASM-NEXT:    mov dc1, dj3
; ASM-NEXT:    mov dc5, dj3
; ASM-NEXT:    paddb [sp], #192; mov dc2, dj3
; ASM-NEXT:    st p6, [sp, #-188] // 4-byte Folded Spill
; ASM-NEXT:    st p7, [sp, #-192] // 4-byte Folded Spill
; ASM-NEXT:    mov p7, sp
; ASM-NEXT:    paddb [p7], #-272; mov p6, sp
; ASM-NEXT:    lda r25, [p7, #0]; paddb [p6], #-204; mov dc6, dj3
; ASM-NEXT:    lda m0, [p6, #0]; mov p6, sp
; ASM-NEXT:    paddb [p6], #-208; mov dc3, dj3
; ASM-NEXT:    lda dj0, [p6, #0]; mov p6, sp
; ASM-NEXT:    paddb [p6], #-212; mov r28, dj3
; ASM-NEXT:    lda dj4, [p6, #0]; mov p6, sp
; ASM-NEXT:    paddb [p6], #-216
; ASM-NEXT:    lda dn0, [p6, #0]
; ASM-NEXT:    mov p6, sp
; ASM-NEXT:    paddb [p6], #-220
; ASM-NEXT:    lda dn4, [p6, #0]; mov p6, sp
; ASM-NEXT:    paddb [p6], #-228
; ASM-NEXT:    lda r10, [p6, #0]; mov p6, sp
; ASM-NEXT:    paddb [p6], #-232
; ASM-NEXT:    lda dj1, [p6, #0]; mov p6, sp
; ASM-NEXT:    paddb [p6], #-236; mov p7, sp
; ASM-NEXT:    lda r11, [p6, #0]
; ASM-NEXT:    mov p6, sp
; ASM-NEXT:    paddb [p6], #-240
; ASM-NEXT:    lda dn1, [p6, #0]; mov p6, sp
; ASM-NEXT:    paddb [p6], #-244
; ASM-NEXT:    lda dn5, [p6, #0]; mov p6, sp
; ASM-NEXT:    paddb [p6], #-292
; ASM-NEXT:    lda m2, [p6, #0]; paddb [p7], #-200; mov p6, sp
; ASM-NEXT:    lda m6, [p7, #0]; paddb [p6], #-296; mov dc7, dj3
; ASM-NEXT:    lda dj2, [p6, #0]
; ASM-NEXT:    mov p6, sp
; ASM-NEXT:    paddb [p6], #-300
; ASM-NEXT:    lda dn2, [p6, #0]; mov p6, sp
; ASM-NEXT:    paddb [p6], #-248
; ASM-NEXT:    lda r12, [p6, #0]
; ASM-NEXT:    st m2, [sp, #-96] // 4-byte Folded Spill
; ASM-NEXT:    lda m7, [sp, #-96]; mov p6, sp // 4-byte Folded Reload
; ASM-NEXT:    paddb [p6], #-252; mov p7, sp
; ASM-NEXT:    lda dj2, [p6, #0]; st dj2, [sp, #-88] // 4-byte Folded Spill
; ASM-NEXT:    lda dj7, [sp, #-88]; mov p6, sp // 4-byte Folded Reload
; ASM-NEXT:    paddb [p6], #-256
; ASM-NEXT:    lda dj6, [p6, #0]; mov p6, sp
; ASM-NEXT:    paddb [p6], #-260
; ASM-NEXT:    lda dn2, [p6, #0]; mov p6, sp
; ASM-NEXT:    paddb [p6], #-264
; ASM-NEXT:    lda dn6, [p6, #0]; st dn2, [sp, #-92] // 4-byte Folded Spill
; ASM-NEXT:    mov p6, sp
; ASM-NEXT:    lda dn7, [sp, #-92]; paddb [p6], #-268 // 4-byte Folded Reload
; ASM-NEXT:    lda r13, [p6, #0]; mov p6, sp
; ASM-NEXT:    paddb [p6], #-276
; ASM-NEXT:    lda dn3, [p6, #0]; mov p6, sp
; ASM-NEXT:    paddb [p6], #-280
; ASM-NEXT:    lda r26, [p6, #0]; mov p6, sp
; ASM-NEXT:    paddb [p6], #-196
; ASM-NEXT:    lda r14, [p6, #0]; st dc7, [sp, #-84] // 4-byte Folded Spill
; ASM-NEXT:    vst wl0, [sp, #-64]; mov p6, sp // 32-byte Folded Spill
; ASM-NEXT:    paddb [p6], #-224; st m7, [sp, #-96] // 4-byte Folded Spill
; ASM-NEXT:    lda r15, [p6, #0]; paddb [p7], #-288; vst wh0, [sp, #-32]; mov p6, sp // 32-byte Folded Spill
; ASM-NEXT:    lda r24, [p7, #0]; paddb [p6], #-284; st dj7, [sp, #-88] // 4-byte Folded Spill
; ASM-NEXT:    lda r27, [p6, #0]; st dn7, [sp, #-92]; movx r9, #31; mov r8, #11 // 4-byte Folded Spill
; ASM-NEXT:    // implicit-def: $x4
; ASM-NEXT:    // implicit-def: $x2
; ASM-NEXT:    .p2align 4
; ASM-NEXT:  .LBB0_1: // %outer.loop.header
; ASM-NEXT:    // =>This Loop Header: Depth=1
; ASM-NEXT:    // Child Loop BB0_2 Depth 2
; ASM-NEXT:    vlda wl6, [p1], #32; nopb ; nopxm
; ASM-NEXT:    vlda wl5, [p0], m6; mov r0, p0
; ASM-NEXT:    vlda.ups.s32.s16 bmh0, s0, [p2, #32]
; ASM-NEXT:    vlda.ups.s32.s16 bml0, s0, [p2], m5
; ASM-NEXT:    vlda wh6, [p1], #32
; ASM-NEXT:    vlda wh5, [p0], m6
; ASM-NEXT:    vlda.ups.s32.s16 bmh1, s0, [p2, #32]
; ASM-NEXT:    vlda.ups.s32.s16 bml1, s0, [p2], m4
; ASM-NEXT:    vlda wl8, [p1], #32
; ASM-NEXT:    vlda wl7, [p0], m6
; ASM-NEXT:    vlda.ups.s32.s16 bmh2, s0, [p2, #32]
; ASM-NEXT:    vlda.ups.s32.s16 bml2, s0, [p2], m5
; ASM-NEXT:    vlda wh8, [p1], #32
; ASM-NEXT:    vlda.3d wh7, [p0], d0
; ASM-NEXT:    vlda.ups.s32.s16 bmh3, s0, [p2, #32]; mov m1, r14
; ASM-NEXT:    vlda.ups.s32.s16 bml3, s0, [p2], m1
; ASM-NEXT:    vlda.ups.s32.s16 bmh4, s0, [p2, #32]
; ASM-NEXT:    vlda.ups.s32.s16 bml4, s0, [p2], m5
; ASM-NEXT:    vlda.ups.s32.s16 bmh5, s0, [p2, #32]
; ASM-NEXT:    vlda.ups.s32.s16 bml5, s0, [p2], m4
; ASM-NEXT:    vlda.ups.s32.s16 bmh6, s0, [p2, #32]
; ASM-NEXT:    vlda.ups.s32.s16 bml6, s0, [p2], m5
; ASM-NEXT:    vlda.ups.s32.s16 bmh7, s0, [p2, #32]
; ASM-NEXT:    vlda wl10, [p1], #32
; ASM-NEXT:    vlda wl3, [p0], m6; mov r1, p0
; ASM-NEXT:    vlda.ups.s32.s16 bml7, s0, [p2, #0]; and r0, r0, r9
; ASM-NEXT:    vlda wh3, [p0], m6; add r0, r0, #33
; ASM-NEXT:    vlda wl5, [p0], m6; vshift.align x4, x4, s1, x5, r0
; ASM-NEXT:    vlda.3d wh5, [p0], d0; and r6, r1, r9; vshift.align x2, x2, s1, x7, r0
; ASM-NEXT:    vlda wh10, [p1], #32; add r0, r6, #33; mov r6, p0
; ASM-NEXT:    vlda wl1, [p1], #32; add r1, r5, #-1; vshuffle x7, x4, x2, r2
; ASM-NEXT:    vlda wh1, [p1], #32; add r1, r1, #-1; vshuffle x9, x7, x0, r8
; ASM-NEXT:    and r6, r6, r9
; ASM-NEXT:    .p2align 4
; ASM-NEXT:  .LBB0_2: // %inner.loop
; ASM-NEXT:    // Parent Loop BB0_1 Depth=1
; ASM-NEXT:    // => This Inner Loop Header: Depth=2
; ASM-NEXT:    nopb ; nopa ; nops ; nopx ; vshuffle x9, x4, x2, r3; vmac cm1, cm1, x9, x6, r4
; ASM-NEXT:    nopa ; nopb ; nopx ; vshift.align x4, x4, s1, x3, r0; vmac cm5, cm5, x9, x8, r4
; ASM-NEXT:    vlda wl3, [p0], m6; vshift.align x2, x2, s1, x5, r0
; ASM-NEXT:    vlda wh3, [p0], m6; vshuffle x11, x9, x0, r8
; ASM-NEXT:    vlda wl5, [p0], m6; add r1, r1, #-1; vshuffle x7, x4, x2, r2; vmac cm0, cm0, x7, x6, r4
; ASM-NEXT:    vlda wl10, [p1], #32; jnz r1, #.LBB0_2; vmac cm4, cm4, x7, x8, r4
; ASM-NEXT:    vlda.3d wh5, [p0], d0; vshuffle x9, x7, x0, r8; vmac cm2, cm2, x9, x6, r4 // Delay Slot 5
; ASM-NEXT:    vlda wh10, [p1], #32; vmov x6, x10; vmac cm6, cm6, x9, x8, r4 // Delay Slot 4
; ASM-NEXT:    vlda wl1, [p1], #32; vmov x8, x1; vmac cm3, cm3, x11, x6, r4 // Delay Slot 3
; ASM-NEXT:    vlda wh1, [p1], #32; add r0, r6, #33; mov r6, p0; vmac cm7, cm7, x11, x8, r4 // Delay Slot 2
; ASM-NEXT:    and r6, r6, r9 // Delay Slot 1
; ASM-NEXT:  // %bb.3: // in Loop: Header=BB0_1 Depth=1
; ASM-NEXT:    nopa ; nopx ; vmov x11, x0
; ASM-NEXT:    vshuffle x0, x4, x2, r3
; ASM-NEXT:    vshuffle x11, x0, x11, r8
; ASM-NEXT:    lda m7, [sp, #-96] // 4-byte Folded Reload
; ASM-NEXT:    vlda wl0, [sp, #-64]; vst wl11, [sp, #-160] // 32-byte Folded Reload32-byte Folded Spill
; ASM-NEXT:    vlda wl11, [sp, #-160]; vst wh11, [sp, #-128] // 32-byte Folded Reload32-byte Folded Spill
; ASM-NEXT:    vlda wh11, [sp, #-128] // 32-byte Folded Reload
; ASM-NEXT:    vlda wl6, [sp, #-160]; vmac cm0, cm0, x7, x6, r4 // 32-byte Folded Reload
; ASM-NEXT:    vlda wh6, [sp, #-128]; vmac cm1, cm1, x9, x6, r4 // 32-byte Folded Reload
; ASM-NEXT:    vlda wh0, [sp, #-32]; vmac cm2, cm2, x0, x6, r4 // 32-byte Folded Reload
; ASM-NEXT:    lda dn7, [sp, #-92]; vmac cm5, cm6, x0, x8, r4 // 4-byte Folded Reload
; ASM-NEXT:    vmac cm4, cm5, x9, x8, r4
; ASM-NEXT:    lda dj7, [sp, #-88]; vshift.align x4, x4, s1, x3, r0; vmac cm8, cm4, x7, x8, r4 // 4-byte Folded Reload
; ASM-NEXT:    vshift.align x2, x2, s1, x5, r0; vmac cm3, cm3, x11, x6, r4
; ASM-NEXT:    st m7, [sp, #-96]; vshuffle x6, x4, x2, r2 // 4-byte Folded Spill
; ASM-NEXT:    vmac cm6, cm7, x6, x8, r4
; ASM-NEXT:    vshuffle x8, x6, x0, r8; vmac cm7, cm0, x6, x10, r4
; ASM-NEXT:    st dn7, [sp, #-92] // 4-byte Folded Spill
; ASM-NEXT:    vshuffle x3, x4, x2, r3; vmac cm0, cm1, x8, x10, r4
; ASM-NEXT:    st dj7, [sp, #-88] // 4-byte Folded Spill
; ASM-NEXT:    vshuffle x5, x3, x0, r8; vmac cm1, cm2, x3, x10, r4
; ASM-NEXT:    vst.srs.s16.s32 bmh7, s2, [p3, #32]
; ASM-NEXT:    vst.srs.s16.s32 bml7, s2, [p3], #64; vmac cm2, cm3, x5, x10, r4
; ASM-NEXT:    vst.srs.s16.s32 bmh0, s2, [p3, #32]; mov m2, r27
; ASM-NEXT:    vst.srs.s16.s32 bml0, s2, [p3], m2; vmac cm3, cm8, x6, x1, r4
; ASM-NEXT:    vst.srs.s16.s32 bmh1, s2, [p3, #32]
; ASM-NEXT:    vst.srs.s16.s32 bml1, s2, [p3], #64; vmac cm8, cm4, x8, x1, r4
; ASM-NEXT:    lda dc7, [sp, #-84]; vst.srs.s16.s32 bmh2, s2, [p3, #32]; mov m1, r24 // 4-byte Folded Reload
; ASM-NEXT:    vst.srs.s16.s32 bml2, s2, [p3], m1; vmac cm5, cm5, x3, x1, r4
; ASM-NEXT:    vst.srs.s16.s32 bmh3, s2, [p3, #32]
; ASM-NEXT:    vst.srs.s16.s32 bml3, s2, [p3], #64; vmac cm4, cm6, x5, x1, r4
; ASM-NEXT:    vst.srs.s16.s32 bmh8, s2, [p3, #32]; mov dj5, r11
; ASM-NEXT:    vst.srs.s16.s32 bml8, s2, [p3], m2; mov m3, r13
; ASM-NEXT:    vst.srs.s16.s32 bmh5, s2, [p3, #32]
; ASM-NEXT:    vst.srs.s16.s32 bml5, s2, [p3], #64; mov m1, r10
; ASM-NEXT:    padda.3d [p0], d1; vst.srs.s16.s32 bmh4, s2, [p3, #32]; mov m1, r15
; ASM-NEXT:    padda.2d [p3], d7; vst.srs.s16.s32 bml4, s2, [p3, #0]; add r7, r7, #-1; mov dj7, r25
; ASM-NEXT:    jnz r7, #.LBB0_1
; ASM-NEXT:    mov dn7, r26 // Delay Slot 5
; ASM-NEXT:    st dc7, [sp, #-84] // 4-byte Folded Spill Delay Slot 4
; ASM-NEXT:    paddb [p2], m1; mov dc7, r28 // Delay Slot 3
; ASM-NEXT:    padda.3d [p2], d3; mov m2, r12 // Delay Slot 2
; ASM-NEXT:    padda.3d [p1], d2; mov r28, dc7 // Delay Slot 1
; ASM-NEXT:  // %bb.4: // %exitStub
; ASM-NEXT:    lda p7, [sp, #-192]; nopb ; nopxm // 4-byte Folded Reload
; ASM-NEXT:    lda p6, [sp, #-188] // 4-byte Folded Reload
; ASM-NEXT:    ret lr
; ASM-NEXT:    nop // Delay Slot 5
; ASM-NEXT:    nop // Delay Slot 4
; ASM-NEXT:    nop // Delay Slot 3
; ASM-NEXT:    nop // Delay Slot 2
; ASM-NEXT:    paddb [sp], #-192 // Delay Slot 1
;
; DCL-LABEL: conv2d.loop.nest:
; DCL:         .p2align 4
; DCL-NEXT:  // %bb.0: // %newFuncRoot
; DCL-NEXT:    paddb [sp], #192; nopa ; nops ; nopxm ; nopv
; DCL-NEXT:    st p6, [sp, #-188]; nopx // 4-byte Folded Spill
; DCL-NEXT:    mov p6, sp
; DCL-NEXT:    paddb [p6], #-292
; DCL-NEXT:    lda m0, [p6, #0]; mov p6, sp
; DCL-NEXT:    paddb [p6], #-296
; DCL-NEXT:    lda dj0, [p6, #0]; mov p6, sp
; DCL-NEXT:    paddb [p6], #-300
; DCL-NEXT:    lda dn0, [p6, #0]; mov p6, sp
; DCL-NEXT:    paddb [p6], #-204; mov r29, r16
; DCL-NEXT:    lda m0, [p6, #0]; mov p6, sp
; DCL-NEXT:    paddb [p6], #-208; mov s0, r0
; DCL-NEXT:    lda dj0, [p6, #0]; mov p6, sp
; DCL-NEXT:    paddb [p6], #-212; mov s1, r1
; DCL-NEXT:    lda dj4, [p6, #0]; mov p6, sp
; DCL-NEXT:    paddb [p6], #-216; st m0, [sp, #-96] // 4-byte Folded Spill
; DCL-NEXT:    lda dn0, [p6, #0]; mov p6, sp
; DCL-NEXT:    mova dj3, #0; paddb [p6], #-220; st dj0, [sp, #-88] // 4-byte Folded Spill
; DCL-NEXT:    lda dn4, [p6, #0]; mov p6, sp
; DCL-NEXT:    paddb [p6], #-228; mov dc0, dj3
; DCL-NEXT:    lda r11, [p6, #0]; mov p6, sp
; DCL-NEXT:    paddb [p6], #-232; st dn0, [sp, #-92] // 4-byte Folded Spill
; DCL-NEXT:    lda dj1, [p6, #0]; mov p6, sp
; DCL-NEXT:    paddb [p6], #-236; mov dc4, dj3
; DCL-NEXT:    lda r12, [p6, #0]; mov p6, sp
; DCL-NEXT:    paddb [p6], #-240; mov dc1, dj3
; DCL-NEXT:    lda dn1, [p6, #0]; mov p6, sp
; DCL-NEXT:    paddb [p6], #-244; mov dc5, dj3
; DCL-NEXT:    lda dn5, [p6, #0]; mov p6, sp
; DCL-NEXT:    paddb [p6], #-248; st p7, [sp, #-192] // 4-byte Folded Spill
; DCL-NEXT:    lda r13, [p6, #0]; mov p6, sp
; DCL-NEXT:    vst wl0, [sp, #-64]; paddb [p6], #-252; mov p7, sp // 32-byte Folded Spill
; DCL-NEXT:    lda dj2, [p6, #0]; mov p6, sp
; DCL-NEXT:    vst wh0, [sp, #-32]; paddb [p6], #-256; mov dc7, dj3 // 32-byte Folded Spill
; DCL-NEXT:    lda dj6, [p6, #0]; mov p6, sp
; DCL-NEXT:    paddb [p6], #-260; st dc7, [sp, #-84] // 4-byte Folded Spill
; DCL-NEXT:    lda dn2, [p6, #0]; paddb [p7], #-272; mov p6, sp
; DCL-NEXT:    lda r25, [p7, #0]; paddb [p6], #-264; mov p7, sp
; DCL-NEXT:    lda dn6, [p6, #0]; paddb [p7], #-200; mov p6, sp
; DCL-NEXT:    lda m6, [p7, #0]; paddb [p6], #-268; mov dc2, dj3
; DCL-NEXT:    lda r14, [p6, #0]; mov p6, sp
; DCL-NEXT:    lda m7, [sp, #-96]; paddb [p6], #-276; mov dc6, dj3 // 4-byte Folded Reload
; DCL-NEXT:    lda dn3, [p6, #0]; mov p6, sp
; DCL-NEXT:    lda dj7, [sp, #-88]; paddb [p6], #-280; mov dc3, dj3 // 4-byte Folded Reload
; DCL-NEXT:    lda r26, [p6, #0]; mov p6, sp
; DCL-NEXT:    lda dn7, [sp, #-92]; paddb [p6], #-196; mov p7, sp // 4-byte Folded Reload
; DCL-NEXT:    lda r15, [p6, #0]; paddb [p7], #-288; mov p6, sp
; DCL-NEXT:    lda r27, [p7, #0]; paddb [p6], #-224; mov s2, r6
; DCL-NEXT:    lda r24, [p6, #0]; mov p6, sp
; DCL-NEXT:    paddb [p6], #-284; st m7, [sp, #-96] // 4-byte Folded Spill
; DCL-NEXT:    lda m4, [p6, #0]; mov r28, dj3
; DCL-NEXT:    st dj7, [sp, #-88] // 4-byte Folded Spill
; DCL-NEXT:    st dn7, [sp, #-92]; movx r9, #31; mov r8, #11 // 4-byte Folded Spill
; DCL-NEXT:    // implicit-def: $x4
; DCL-NEXT:    // implicit-def: $x2
; DCL-NEXT:    .p2align 4
; DCL-NEXT:  .LBB0_1: // %outer.loop.header
; DCL-NEXT:    // =>This Loop Header: Depth=1
; DCL-NEXT:    // Child Loop BB0_2 Depth 2
; DCL-NEXT:    vldb wl6, [p1], #32; nopxm
; DCL-NEXT:    vldb wl3, [p0], m6; mov r0, p0
; DCL-NEXT:    vlda.ups.s32.s16 bmh0, s0, [p2, #32]
; DCL-NEXT:    vldb wh6, [p1], #32
; DCL-NEXT:    vldb wh3, [p0], m6; mov m5, p4
; DCL-NEXT:    vlda.ups.s32.s16 bml0, s0, [p2], m5
; DCL-NEXT:    vldb wl8, [p1], #32
; DCL-NEXT:    vldb wl7, [p0], m6
; DCL-NEXT:    vlda.ups.s32.s16 bmh1, s0, [p2, #32]; mov m1, p5
; DCL-NEXT:    vlda.ups.s32.s16 bml1, s0, [p2], m1
; DCL-NEXT:    vldb.3d wh7, [p0], d0
; DCL-NEXT:    vlda.ups.s32.s16 bmh2, s0, [p2, #32]
; DCL-NEXT:    vlda.ups.s32.s16 bml2, s0, [p2], m5
; DCL-NEXT:    vlda.ups.s32.s16 bmh3, s0, [p2, #32]; mov m2, r15
; DCL-NEXT:    vlda.ups.s32.s16 bml3, s0, [p2], m2
; DCL-NEXT:    vlda.ups.s32.s16 bmh4, s0, [p2, #32]
; DCL-NEXT:    vlda.ups.s32.s16 bml4, s0, [p2], m5
; DCL-NEXT:    vlda.ups.s32.s16 bmh5, s0, [p2, #32]
; DCL-NEXT:    vlda.ups.s32.s16 bml5, s0, [p2], m1
; DCL-NEXT:    vlda.ups.s32.s16 bmh6, s0, [p2, #32]
; DCL-NEXT:    vlda.ups.s32.s16 bml6, s0, [p2], m5
; DCL-NEXT:    vlda.ups.s32.s16 bmh7, s0, [p2, #32]
; DCL-NEXT:    vldb wh8, [p1], #32
; DCL-NEXT:    vldb wl5, [p0], m6; mov r1, p0
; DCL-NEXT:    vlda.ups.s32.s16 bml7, s0, [p2, #0]; and r0, r0, r9
; DCL-NEXT:    vldb wh5, [p0], m6; add r0, r0, #33
; DCL-NEXT:    vldb wl3, [p0], m6; vshift.align x4, x4, s1, x3, r0
; DCL-NEXT:    vldb.3d wh3, [p0], d0; and r10, r1, r9; vshift.align x2, x2, s1, x7, r0
; DCL-NEXT:    vldb wl1, [p1], #32; add r0, r10, #33; mov r10, p0
; DCL-NEXT:    vldb wh1, [p1], #32; add r1, r5, #-1; vshuffle x7, x4, x2, r2
; DCL-NEXT:    vldb wl10, [p1], #32; add r1, r1, #-1; vshuffle x9, x7, x0, r8
; DCL-NEXT:    vldb wh10, [p1], #32; and r16, r10, r9
; DCL-NEXT:    .p2align 4
; DCL-NEXT:  .LBB0_2: // %inner.loop
; DCL-NEXT:    // Parent Loop BB0_1 Depth=1
; DCL-NEXT:    // => This Inner Loop Header: Depth=2
; DCL-NEXT:    nopb ; nopa ; nops ; nopx ; vshuffle x9, x4, x2, r3; vmac cm1, cm1, x9, x6, r4
; DCL-NEXT:    nopa ; nopb ; nopx ; vshift.align x4, x4, s1, x5, r0; vmac cm5, cm5, x9, x8, r4
; DCL-NEXT:    vldb wl5, [p0], m6; vshift.align x2, x2, s1, x3, r0
; DCL-NEXT:    vldb wh5, [p0], m6; add r1, r1, #-1; vshuffle x11, x9, x0, r8
; DCL-NEXT:    vldb wl3, [p0], m6; jnz r1, #.LBB0_2; vmac cm0, cm0, x7, x6, r4
; DCL-NEXT:    vldb.3d wh3, [p0], d0; vshuffle x7, x4, x2, r2; vmac cm4, cm4, x7, x8, r4 // Delay Slot 5
; DCL-NEXT:    vldb wl1, [p1], #32; vshuffle x9, x7, x0, r8; vmac cm2, cm2, x9, x6, r4 // Delay Slot 4
; DCL-NEXT:    vldb wh1, [p1], #32; vmov x6, x1; vmac cm6, cm6, x9, x8, r4 // Delay Slot 3
; DCL-NEXT:    vldb wl10, [p1], #32; add r0, r16, #33; mov r10, p0; vmac cm3, cm3, x11, x6, r4 // Delay Slot 2
; DCL-NEXT:    vldb wh10, [p1], #32; and r16, r10, r9; vmov x8, x10; vmac cm7, cm7, x11, x8, r4 // Delay Slot 1
; DCL-NEXT:  // %bb.3: // in Loop: Header=BB0_1 Depth=1
; DCL-NEXT:    nopa ; nopx ; vmov x11, x0
; DCL-NEXT:    vshuffle x0, x4, x2, r3
; DCL-NEXT:    vshuffle x11, x0, x11, r8
; DCL-NEXT:    vlda wl0, [sp, #-64] // 32-byte Folded Reload
; DCL-NEXT:    vst wl11, [sp, #-160] // 32-byte Folded Spill
; DCL-NEXT:    vst wh11, [sp, #-128] // 32-byte Folded Spill
; DCL-NEXT:    vlda wl11, [sp, #-160] // 32-byte Folded Reload
; DCL-NEXT:    vlda wh11, [sp, #-128] // 32-byte Folded Reload
; DCL-NEXT:    vlda wl6, [sp, #-160]; vmac cm2, cm2, x0, x6, r4 // 32-byte Folded Reload
; DCL-NEXT:    vlda wh6, [sp, #-128]; vmac cm5, cm6, x0, x8, r4 // 32-byte Folded Reload
; DCL-NEXT:    vlda wh0, [sp, #-32]; vmac cm4, cm5, x9, x8, r4 // 32-byte Folded Reload
; DCL-NEXT:    lda dn7, [sp, #-92]; vmac cm8, cm4, x7, x8, r4 // 4-byte Folded Reload
; DCL-NEXT:    vmac cm0, cm0, x7, x6, r4
; DCL-NEXT:    lda dj7, [sp, #-88]; vshift.align x4, x4, s1, x5, r0; vmac cm1, cm1, x9, x6, r4 // 4-byte Folded Reload
; DCL-NEXT:    vshift.align x2, x2, s1, x3, r0; vmac cm3, cm3, x11, x6, r4
; DCL-NEXT:    vshuffle x6, x4, x2, r2
; DCL-NEXT:    vmac cm6, cm7, x6, x8, r4
; DCL-NEXT:    vshuffle x8, x6, x0, r8; vmac cm7, cm0, x6, x1, r4
; DCL-NEXT:    st dn7, [sp, #-92] // 4-byte Folded Spill
; DCL-NEXT:    vshuffle x3, x4, x2, r3; vmac cm0, cm1, x8, x1, r4
; DCL-NEXT:    st dj7, [sp, #-88] // 4-byte Folded Spill
; DCL-NEXT:    vshuffle x5, x3, x0, r8; vmac cm1, cm2, x3, x1, r4
; DCL-NEXT:    lda m7, [sp, #-96]; vst.srs.s16.s32 bmh7, s2, [p3, #32]; mov s3, r6 // 4-byte Folded Reload
; DCL-NEXT:    lda dc7, [sp, #-84]; vst.srs.s16.s32 bml7, s3, [p3], #64; vmac cm2, cm3, x5, x1, r4 // 4-byte Folded Reload
; DCL-NEXT:    vst.srs.s16.s32 bmh0, s3, [p3, #32]
; DCL-NEXT:    vst.srs.s16.s32 bml0, s3, [p3], m4; vmac cm3, cm8, x6, x10, r4
; DCL-NEXT:    vst.srs.s16.s32 bmh1, s3, [p3, #32]
; DCL-NEXT:    vst.srs.s16.s32 bml1, s3, [p3], #64; mov m1, r27; vmac cm8, cm4, x8, x10, r4
; DCL-NEXT:    vst.srs.s16.s32 bmh2, s3, [p3, #32]
; DCL-NEXT:    vst.srs.s16.s32 bml2, s3, [p3], m1; vmac cm5, cm5, x3, x10, r4
; DCL-NEXT:    vst.srs.s16.s32 bmh3, s3, [p3, #32]
; DCL-NEXT:    vst.srs.s16.s32 bml3, s3, [p3], #64; vmac cm4, cm6, x5, x10, r4
; DCL-NEXT:    vst.srs.s16.s32 bmh8, s3, [p3, #32]; mov dj5, r12
; DCL-NEXT:    vst.srs.s16.s32 bml8, s3, [p3], m4; mov m2, r13
; DCL-NEXT:    vst.srs.s16.s32 bmh5, s3, [p3, #32]; mov m3, r14
; DCL-NEXT:    vst.srs.s16.s32 bml5, s3, [p3], #64; mov m1, r11
; DCL-NEXT:    padda.3d [p0], d1; vst.srs.s16.s32 bmh4, s3, [p3, #32]; mov m1, r24
; DCL-NEXT:    padda.2d [p3], d7; vst.srs.s16.s32 bml4, s3, [p3, #0]; add r7, r7, #-1; mov dj7, r25
; DCL-NEXT:    jnz r7, #.LBB0_1
; DCL-NEXT:    mov dn7, r26 // Delay Slot 5
; DCL-NEXT:    st dc7, [sp, #-84] // 4-byte Folded Spill Delay Slot 4
; DCL-NEXT:    paddb [p2], m1; mov dc7, r28 // Delay Slot 3
; DCL-NEXT:    padda.3d [p2], d3; st m7, [sp, #-96] // 4-byte Folded Spill Delay Slot 2
; DCL-NEXT:    padda.3d [p1], d2; mov r28, dc7 // Delay Slot 1
; DCL-NEXT:  // %bb.4: // %exitStub
; DCL-NEXT:    lda p7, [sp, #-192]; nopxm // 4-byte Folded Reload
; DCL-NEXT:    lda p6, [sp, #-188] // 4-byte Folded Reload
; DCL-NEXT:    ret lr
; DCL-NEXT:    nop // Delay Slot 5
; DCL-NEXT:    nop // Delay Slot 4
; DCL-NEXT:    nop // Delay Slot 3
; DCL-NEXT:    nop // Delay Slot 2
; DCL-NEXT:    paddb [sp], #-192; mov r16, r29 // Delay Slot 1
;
; ZOL-LABEL: conv2d.loop.nest:
; ZOL:         .p2align 4
; ZOL-NEXT:  // %bb.0: // %newFuncRoot
; ZOL-NEXT:    paddb [sp], #192; nopa ; nops ; nopxm ; nopv
; ZOL-NEXT:    st p6, [sp, #-188]; nopx // 4-byte Folded Spill
; ZOL-NEXT:    mov p6, sp
; ZOL-NEXT:    paddb [p6], #-292
; ZOL-NEXT:    lda m0, [p6, #0]; mov p6, sp
; ZOL-NEXT:    paddb [p6], #-296
; ZOL-NEXT:    lda dj0, [p6, #0]; mov p6, sp
; ZOL-NEXT:    paddb [p6], #-300
; ZOL-NEXT:    lda dn0, [p6, #0]; mov p6, sp
; ZOL-NEXT:    paddb [p6], #-204; mov r28, r16
; ZOL-NEXT:    lda m0, [p6, #0]; mov p6, sp
; ZOL-NEXT:    paddb [p6], #-208; mov s0, r0
; ZOL-NEXT:    lda dj0, [p6, #0]; mov p6, sp
; ZOL-NEXT:    paddb [p6], #-212; mov s1, r1
; ZOL-NEXT:    lda dj4, [p6, #0]; mov p6, sp
; ZOL-NEXT:    paddb [p6], #-216; st m0, [sp, #-96] // 4-byte Folded Spill
; ZOL-NEXT:    lda dn0, [p6, #0]; mov p6, sp
; ZOL-NEXT:    mova dj3, #0; paddb [p6], #-220; st dj0, [sp, #-88] // 4-byte Folded Spill
; ZOL-NEXT:    lda dn4, [p6, #0]; mov p6, sp
; ZOL-NEXT:    paddb [p6], #-228; mov dc0, dj3
; ZOL-NEXT:    lda r10, [p6, #0]; mov p6, sp
; ZOL-NEXT:    paddb [p6], #-232; st dn0, [sp, #-92] // 4-byte Folded Spill
; ZOL-NEXT:    lda dj1, [p6, #0]; mov p6, sp
; ZOL-NEXT:    paddb [p6], #-236; mov dc4, dj3
; ZOL-NEXT:    lda r11, [p6, #0]; mov p6, sp
; ZOL-NEXT:    paddb [p6], #-240; mov dc1, dj3
; ZOL-NEXT:    lda dn1, [p6, #0]; mov p6, sp
; ZOL-NEXT:    paddb [p6], #-244; mov dc5, dj3
; ZOL-NEXT:    lda dn5, [p6, #0]; mov p6, sp
; ZOL-NEXT:    paddb [p6], #-248; st p7, [sp, #-192] // 4-byte Folded Spill
; ZOL-NEXT:    lda r12, [p6, #0]; mov p6, sp
; ZOL-NEXT:    vst wl0, [sp, #-64]; paddb [p6], #-252; mov p7, sp // 32-byte Folded Spill
; ZOL-NEXT:    lda dj2, [p6, #0]; mov p6, sp
; ZOL-NEXT:    vst wh0, [sp, #-32]; paddb [p6], #-256; mov dc7, dj3 // 32-byte Folded Spill
; ZOL-NEXT:    lda dj6, [p6, #0]; mov p6, sp
; ZOL-NEXT:    paddb [p6], #-260; st dc7, [sp, #-84] // 4-byte Folded Spill
; ZOL-NEXT:    lda dn2, [p6, #0]; paddb [p7], #-272; mov p6, sp
; ZOL-NEXT:    lda r24, [p7, #0]; paddb [p6], #-264; mov p7, sp
; ZOL-NEXT:    lda dn6, [p6, #0]; paddb [p7], #-200; mov p6, sp
; ZOL-NEXT:    lda m6, [p7, #0]; paddb [p6], #-268; mov dc2, dj3
; ZOL-NEXT:    lda r13, [p6, #0]; mov p6, sp
; ZOL-NEXT:    lda m7, [sp, #-96]; paddb [p6], #-276; mov dc6, dj3 // 4-byte Folded Reload
; ZOL-NEXT:    lda dn3, [p6, #0]; mov p6, sp
; ZOL-NEXT:    lda dj7, [sp, #-88]; paddb [p6], #-280; mov dc3, dj3 // 4-byte Folded Reload
; ZOL-NEXT:    lda r25, [p6, #0]; mov p6, sp
; ZOL-NEXT:    lda dn7, [sp, #-92]; paddb [p6], #-196; mov p7, sp // 4-byte Folded Reload
; ZOL-NEXT:    lda r14, [p6, #0]; paddb [p7], #-288; mov p6, sp
; ZOL-NEXT:    lda r26, [p7, #0]; paddb [p6], #-224; mov s2, r6
; ZOL-NEXT:    lda r15, [p6, #0]; mov p6, sp
; ZOL-NEXT:    paddb [p6], #-284; st m7, [sp, #-96] // 4-byte Folded Spill
; ZOL-NEXT:    lda m4, [p6, #0]; mov r27, dj3
; ZOL-NEXT:    st dj7, [sp, #-88] // 4-byte Folded Spill
; ZOL-NEXT:    st dn7, [sp, #-92]; movx r9, #31; mov r8, #11 // 4-byte Folded Spill
; ZOL-NEXT:    // implicit-def: $x4
; ZOL-NEXT:    // implicit-def: $x2
; ZOL-NEXT:    .p2align 4
; ZOL-NEXT:  .LBB0_1: // %outer.loop.header
; ZOL-NEXT:    // =>This Loop Header: Depth=1
; ZOL-NEXT:    // Child Loop BB0_2 Depth 2
; ZOL-NEXT:    vldb wl6, [p1], #32; nopa ; nops ; nopxm ; nopv
; ZOL-NEXT:    vldb wl3, [p0], m6; mov r0, p0
; ZOL-NEXT:    vlda.ups.s32.s16 bmh0, s0, [p2, #32]
; ZOL-NEXT:    vldb wh6, [p1], #32
; ZOL-NEXT:    vldb wh3, [p0], m6; mov m5, p4
; ZOL-NEXT:    vlda.ups.s32.s16 bml0, s0, [p2], m5
; ZOL-NEXT:    vldb wl8, [p1], #32
; ZOL-NEXT:    vldb wl7, [p0], m6
; ZOL-NEXT:    vlda.ups.s32.s16 bmh1, s0, [p2, #32]; mov m1, p5
; ZOL-NEXT:    vlda.ups.s32.s16 bml1, s0, [p2], m1
; ZOL-NEXT:    vldb wh8, [p1], #32
; ZOL-NEXT:    vldb.3d wh7, [p0], d0
; ZOL-NEXT:    vlda.ups.s32.s16 bmh2, s0, [p2, #32]
; ZOL-NEXT:    vlda.ups.s32.s16 bml2, s0, [p2], m5
; ZOL-NEXT:    vldb wl1, [p1], #32
; ZOL-NEXT:    vlda.ups.s32.s16 bmh3, s0, [p2, #32]; mov m2, r14
; ZOL-NEXT:    vlda.ups.s32.s16 bml3, s0, [p2], m2
; ZOL-NEXT:    vlda.ups.s32.s16 bmh4, s0, [p2, #32]
; ZOL-NEXT:    vlda.ups.s32.s16 bml4, s0, [p2], m5
; ZOL-NEXT:    vlda.ups.s32.s16 bmh5, s0, [p2, #32]
; ZOL-NEXT:    vlda.ups.s32.s16 bml5, s0, [p2], m1
; ZOL-NEXT:    vlda.ups.s32.s16 bmh6, s0, [p2, #32]
; ZOL-NEXT:    vlda.ups.s32.s16 bml6, s0, [p2], m5; movxm ls, #.LBB0_2
; ZOL-NEXT:    vldb wl5, [p0], m6; mov r1, p0
; ZOL-NEXT:    vldb wh5, [p0], m6; movxm le, #.L_LEnd0
; ZOL-NEXT:    vlda.ups.s32.s16 bmh7, s0, [p2, #32]; and r0, r0, r9; add.nc lc, r5, #-2
; ZOL-NEXT:    vldb wl3, [p0], m6; nopa ; nops ; add r0, r0, #33; nopm ; nopv
; ZOL-NEXT:    vldb.3d wh3, [p0], d0; nopa ; nops ; nopx ; vshift.align x4, x4, s1, x3, r0; nopv
; ZOL-NEXT:    nopb ; vlda.ups.s32.s16 bml7, s0, [p2, #0]; nops ; and r1, r1, r9; vshift.align x2, x2, s1, x7, r0; nopv
; ZOL-NEXT:    vldb wh1, [p1], #32; nopa ; nops ; add r0, r1, #33; mov r1, p0; nopv
; ZOL-NEXT:    vldb wl10, [p1], #32; nopa ; nops ; nopx ; vshuffle x7, x4, x2, r2; nopv
; ZOL-NEXT:    vldb wh10, [p1], #32; nopa ; nops ; nopx ; vshuffle x9, x7, x0, r8; nopv
; ZOL-NEXT:    nopb ; nopa ; nops ; and r16, r1, r9; nopm ; nopv
; ZOL-NEXT:    .p2align 4
; ZOL-NEXT:  .LBB0_2: // %inner.loop
; ZOL-NEXT:    // Parent Loop BB0_1 Depth=1
; ZOL-NEXT:    // => This Inner Loop Header: Depth=2
; ZOL-NEXT:    nopa ; nopx ; vshuffle x9, x4, x2, r3; vmac cm1, cm1, x9, x6, r4
; ZOL-NEXT:    vldb wl5, [p0], m6; vshift.align x4, x4, s1, x5, r0; vmac cm5, cm5, x9, x8, r4
; ZOL-NEXT:    vldb wh5, [p0], m6; vshift.align x2, x2, s1, x3, r0
; ZOL-NEXT:    vldb wl3, [p0], m6; vshuffle x11, x9, x0, r8; vmac cm0, cm0, x7, x6, r4
; ZOL-NEXT:    vldb.3d wh3, [p0], d0; vshuffle x7, x4, x2, r2; vmac cm4, cm4, x7, x8, r4
; ZOL-NEXT:    vldb wl1, [p1], #32; vshuffle x9, x7, x0, r8; vmac cm2, cm2, x9, x6, r4
; ZOL-NEXT:    vldb wh1, [p1], #32; vmov x6, x1; vmac cm6, cm6, x9, x8, r4
; ZOL-NEXT:    vldb wl10, [p1], #32; add r0, r16, #33; mov r1, p0; vmac cm3, cm3, x11, x6, r4
; ZOL-NEXT:  .L_LEnd0:
; ZOL-NEXT:    vldb wh10, [p1], #32; nopa ; nops ; and r16, r1, r9; vmov x8, x10; vmac cm7, cm7, x11, x8, r4
; ZOL-NEXT:  // %bb.3: // in Loop: Header=BB0_1 Depth=1
; ZOL-NEXT:    nopa ; nopx ; vmov x11, x0
; ZOL-NEXT:    vshuffle x0, x4, x2, r3
; ZOL-NEXT:    vshuffle x11, x0, x11, r8
; ZOL-NEXT:    vlda wl0, [sp, #-64] // 32-byte Folded Reload
; ZOL-NEXT:    vst wl11, [sp, #-160] // 32-byte Folded Spill
; ZOL-NEXT:    vst wh11, [sp, #-128] // 32-byte Folded Spill
; ZOL-NEXT:    vlda wl11, [sp, #-160] // 32-byte Folded Reload
; ZOL-NEXT:    vlda wh11, [sp, #-128] // 32-byte Folded Reload
; ZOL-NEXT:    vlda wl6, [sp, #-160]; vmac cm2, cm2, x0, x6, r4 // 32-byte Folded Reload
; ZOL-NEXT:    vlda wh6, [sp, #-128]; vmac cm5, cm6, x0, x8, r4 // 32-byte Folded Reload
; ZOL-NEXT:    vlda wh0, [sp, #-32]; vmac cm4, cm5, x9, x8, r4 // 32-byte Folded Reload
; ZOL-NEXT:    lda dn7, [sp, #-92]; vmac cm8, cm4, x7, x8, r4 // 4-byte Folded Reload
; ZOL-NEXT:    vmac cm0, cm0, x7, x6, r4
; ZOL-NEXT:    lda dj7, [sp, #-88]; vshift.align x4, x4, s1, x5, r0; vmac cm1, cm1, x9, x6, r4 // 4-byte Folded Reload
; ZOL-NEXT:    vshift.align x2, x2, s1, x3, r0; vmac cm3, cm3, x11, x6, r4
; ZOL-NEXT:    vshuffle x6, x4, x2, r2
; ZOL-NEXT:    vmac cm6, cm7, x6, x8, r4
; ZOL-NEXT:    vshuffle x8, x6, x0, r8; vmac cm7, cm0, x6, x1, r4
; ZOL-NEXT:    st dn7, [sp, #-92] // 4-byte Folded Spill
; ZOL-NEXT:    vshuffle x3, x4, x2, r3; vmac cm0, cm1, x8, x1, r4
; ZOL-NEXT:    st dj7, [sp, #-88] // 4-byte Folded Spill
; ZOL-NEXT:    vshuffle x5, x3, x0, r8; vmac cm1, cm2, x3, x1, r4
; ZOL-NEXT:    lda m7, [sp, #-96]; vst.srs.s16.s32 bmh7, s2, [p3, #32]; mov s3, r6 // 4-byte Folded Reload
; ZOL-NEXT:    lda dc7, [sp, #-84]; vst.srs.s16.s32 bml7, s3, [p3], #64; vmac cm2, cm3, x5, x1, r4 // 4-byte Folded Reload
; ZOL-NEXT:    vst.srs.s16.s32 bmh0, s3, [p3, #32]
; ZOL-NEXT:    vst.srs.s16.s32 bml0, s3, [p3], m4; vmac cm3, cm8, x6, x10, r4
; ZOL-NEXT:    vst.srs.s16.s32 bmh1, s3, [p3, #32]
; ZOL-NEXT:    vst.srs.s16.s32 bml1, s3, [p3], #64; mov m1, r26; vmac cm8, cm4, x8, x10, r4
; ZOL-NEXT:    vst.srs.s16.s32 bmh2, s3, [p3, #32]
; ZOL-NEXT:    vst.srs.s16.s32 bml2, s3, [p3], m1; vmac cm5, cm5, x3, x10, r4
; ZOL-NEXT:    vst.srs.s16.s32 bmh3, s3, [p3, #32]
; ZOL-NEXT:    vst.srs.s16.s32 bml3, s3, [p3], #64; vmac cm4, cm6, x5, x10, r4
; ZOL-NEXT:    vst.srs.s16.s32 bmh8, s3, [p3, #32]; mov dj5, r11
; ZOL-NEXT:    vst.srs.s16.s32 bml8, s3, [p3], m4; mov m2, r12
; ZOL-NEXT:    vst.srs.s16.s32 bmh5, s3, [p3, #32]; mov m3, r13
; ZOL-NEXT:    vst.srs.s16.s32 bml5, s3, [p3], #64; mov m1, r10
; ZOL-NEXT:    padda.3d [p0], d1; vst.srs.s16.s32 bmh4, s3, [p3, #32]; mov m1, r15
; ZOL-NEXT:    padda.2d [p3], d7; vst.srs.s16.s32 bml4, s3, [p3, #0]; add r7, r7, #-1; mov dj7, r24
; ZOL-NEXT:    jnz r7, #.LBB0_1
; ZOL-NEXT:    mov dn7, r25 // Delay Slot 5
; ZOL-NEXT:    st dc7, [sp, #-84] // 4-byte Folded Spill Delay Slot 4
; ZOL-NEXT:    paddb [p2], m1; mov dc7, r27 // Delay Slot 3
; ZOL-NEXT:    padda.3d [p2], d3; st m7, [sp, #-96] // 4-byte Folded Spill Delay Slot 2
; ZOL-NEXT:    padda.3d [p1], d2; mov r27, dc7 // Delay Slot 1
; ZOL-NEXT:  // %bb.4: // %exitStub
; ZOL-NEXT:    lda p7, [sp, #-192]; nopxm // 4-byte Folded Reload
; ZOL-NEXT:    lda p6, [sp, #-188] // 4-byte Folded Reload
; ZOL-NEXT:    ret lr
; ZOL-NEXT:    nop // Delay Slot 5
; ZOL-NEXT:    nop // Delay Slot 4
; ZOL-NEXT:    nop // Delay Slot 3
; ZOL-NEXT:    nop // Delay Slot 2
; ZOL-NEXT:    paddb [sp], #-192; mov r16, r28 // Delay Slot 1
newFuncRoot:
  br label %outer.loop.header

outer.loop.header:                                    ; preds = %newFuncRoot, %outer.loop.latch
  %p_in.0672.i = phi ptr [ %add.ptr6.i51, %newFuncRoot ], [ %111, %outer.loop.latch ]
  %p_w.0671.i = phi ptr [ %add.ptr5, %newFuncRoot ], [ %119, %outer.loop.latch ]
  %p_init16.0670.i = phi ptr [ %cond, %newFuncRoot ], [ %127, %outer.loop.latch ]
  %p_out.0669.i = phi ptr [ %cond.i50, %newFuncRoot ], [ %140, %outer.loop.latch ]
  %j.0668.i = phi i32 [ 0, %newFuncRoot ], [ %inc237.i, %outer.loop.latch ]
  %29 = phi <16 x i32> [ undef, %newFuncRoot ], [ %60, %outer.loop.latch ]
  %30 = phi <16 x i32> [ undef, %newFuncRoot ], [ %59, %outer.loop.latch ]
  %Ybuff0.sroa.0.0667.i = phi <16 x i32> [ %0, %newFuncRoot ], [ %80, %outer.loop.latch ]
  %Ybuff1.sroa.0.0666.i = phi <16 x i32> [ %0, %newFuncRoot ], [ %84, %outer.loop.latch ]
  %iterator_inner_cnt0.0665.i = phi i32 [ 0, %newFuncRoot ], [ %65, %outer.loop.latch ]
  %iterator_inner_cnt1.0664.i = phi i32 [ 0, %newFuncRoot ], [ %67, %outer.loop.latch ]
  %iterator_outer_cnt0.0663.i = phi i32 [ 0, %newFuncRoot ], [ %108, %outer.loop.latch ]
  %iterator_outer_cnt1.0662.i = phi i32 [ 0, %newFuncRoot ], [ %110, %outer.loop.latch ]
  %iterator_weights_cnt0.0661.i = phi i32 [ 0, %newFuncRoot ], [ %116, %outer.loop.latch ]
  %iterator_weights_cnt1.0660.i = phi i32 [ 0, %newFuncRoot ], [ %118, %outer.loop.latch ]
  %iterator_psum_cnt0.0659.i = phi i32 [ 0, %newFuncRoot ], [ %124, %outer.loop.latch ]
  %iterator_psum_cnt1.0658.i = phi i32 [ 0, %newFuncRoot ], [ %126, %outer.loop.latch ]
  %iterator_pout_cnt0.0657.i = phi i32 [ 0, %newFuncRoot ], [ %139, %outer.loop.latch ]
  %31 = ptrtoint ptr %p_in.0672.i to i20
  %32 = and i20 %31, 31
  %narrow.i108 = add nuw nsw i20 %32, 33
  %add76.i = zext i20 %narrow.i108 to i32
  %33 = load <32 x i16>, ptr %p_init16.0670.i, align 64, !tbaa !4
  %34 = tail call <16 x i64> @llvm.aie2.acc32.v32.I512.ups(<32 x i16> %33, i32 %cond67.i79, i32 1)
  %add.ptr.i.i109 = getelementptr inbounds i8, ptr %p_init16.0670.i, i20 %idx.ext.i.i81
  %35 = load <32 x i16>, ptr %add.ptr.i.i109, align 64, !tbaa !4
  %36 = tail call <16 x i64> @llvm.aie2.acc32.v32.I512.ups(<32 x i16> %35, i32 %cond67.i79, i32 1)
  %add.ptr.i405.i = getelementptr inbounds i8, ptr %add.ptr.i.i109, i20 %idx.ext.i404.i
  %37 = load <32 x i16>, ptr %add.ptr.i405.i, align 64, !tbaa !4
  %38 = tail call <16 x i64> @llvm.aie2.acc32.v32.I512.ups(<32 x i16> %37, i32 %cond67.i79, i32 1)
  %add.ptr.i408.i = getelementptr inbounds i8, ptr %add.ptr.i405.i, i20 %idx.ext.i.i81
  %39 = load <32 x i16>, ptr %add.ptr.i408.i, align 64, !tbaa !4
  %40 = tail call <16 x i64> @llvm.aie2.acc32.v32.I512.ups(<32 x i16> %39, i32 %cond67.i79, i32 1)
  %add.ptr.i411.i = getelementptr inbounds i8, ptr %add.ptr.i408.i, i20 %idx.ext.i410.i
  %41 = load <32 x i16>, ptr %add.ptr.i411.i, align 64, !tbaa !4
  %42 = tail call <16 x i64> @llvm.aie2.acc32.v32.I512.ups(<32 x i16> %41, i32 %cond67.i79, i32 1)
  %add.ptr.i414.i = getelementptr inbounds i8, ptr %add.ptr.i411.i, i20 %idx.ext.i.i81
  %43 = load <32 x i16>, ptr %add.ptr.i414.i, align 64, !tbaa !4
  %44 = tail call <16 x i64> @llvm.aie2.acc32.v32.I512.ups(<32 x i16> %43, i32 %cond67.i79, i32 1)
  %add.ptr.i417.i110 = getelementptr inbounds i8, ptr %add.ptr.i414.i, i20 %idx.ext.i404.i
  %45 = load <32 x i16>, ptr %add.ptr.i417.i110, align 64, !tbaa !4
  %46 = tail call <16 x i64> @llvm.aie2.acc32.v32.I512.ups(<32 x i16> %45, i32 %cond67.i79, i32 1)
  %add.ptr.i420.i111 = getelementptr inbounds i8, ptr %add.ptr.i417.i110, i20 %idx.ext.i.i81
  %47 = load <32 x i16>, ptr %add.ptr.i420.i111, align 64, !tbaa !4
  %48 = tail call <16 x i64> @llvm.aie2.acc32.v32.I512.ups(<32 x i16> %47, i32 %cond67.i79, i32 1)
  br label %inner.loop

inner.loop:                                    ; preds = %inner.loop, %outer.loop.header
  %p_in.1655.i = phi ptr [ %p_in.0672.i, %outer.loop.header ], [ %68, %inner.loop ]
  %p_w.1654.i = phi ptr [ %p_w.0671.i, %outer.loop.header ], [ %add.ptr161.i, %inner.loop ]
  %i.0653.i = phi i32 [ 0, %outer.loop.header ], [ %inc.i119, %inner.loop ]
  %49 = phi <16 x i32> [ %29, %outer.loop.header ], [ %60, %inner.loop ]
  %50 = phi <16 x i32> [ %30, %outer.loop.header ], [ %59, %inner.loop ]
  %frac.0652.i = phi i32 [ %add76.i, %outer.loop.header ], [ %add187.i, %inner.loop ]
  %Ybuff0.sroa.0.1651.i = phi <16 x i32> [ %Ybuff0.sroa.0.0667.i, %outer.loop.header ], [ %80, %inner.loop ]
  %Ybuff1.sroa.0.1650.i = phi <16 x i32> [ %Ybuff1.sroa.0.0666.i, %outer.loop.header ], [ %84, %inner.loop ]
  %iterator_inner_cnt0.1649.i = phi i32 [ %iterator_inner_cnt0.0665.i, %outer.loop.header ], [ %65, %inner.loop ]
  %iterator_inner_cnt1.1648.i = phi i32 [ %iterator_inner_cnt1.0664.i, %outer.loop.header ], [ %67, %inner.loop ]
  %Cbuff0.sroa.0.0647.i = phi <16 x i64> [ %34, %outer.loop.header ], [ %87, %inner.loop ]
  %Cbuff1.sroa.0.0646.i = phi <16 x i64> [ %36, %outer.loop.header ], [ %90, %inner.loop ]
  %Cbuff2.sroa.0.0645.i = phi <16 x i64> [ %38, %outer.loop.header ], [ %93, %inner.loop ]
  %Cbuff3.sroa.0.0644.i = phi <16 x i64> [ %40, %outer.loop.header ], [ %96, %inner.loop ]
  %Cbuff4.sroa.0.0643.i = phi <16 x i64> [ %42, %outer.loop.header ], [ %97, %inner.loop ]
  %Cbuff5.sroa.0.0642.i = phi <16 x i64> [ %44, %outer.loop.header ], [ %98, %inner.loop ]
  %Cbuff6.sroa.0.0641.i = phi <16 x i64> [ %46, %outer.loop.header ], [ %99, %inner.loop ]
  %Cbuff7.sroa.0.0640.i = phi <16 x i64> [ %48, %outer.loop.header ], [ %100, %inner.loop ]
  %51 = load <8 x i32>, ptr %p_in.1655.i, align 32, !tbaa !4
  %52 = tail call <16 x i32> @llvm.aie2.upd.I512.I256(<16 x i32> %0, <8 x i32> %51, i32 0)
  %add.ptr.i435.i117 = getelementptr inbounds i8, ptr %p_in.1655.i, i20 %idx.ext.i434.i85
  %53 = load <8 x i32>, ptr %add.ptr.i435.i117, align 32, !tbaa !4
  %54 = tail call <16 x i32> @llvm.aie2.upd.I512.I256(<16 x i32> %52, <8 x i32> %53, i32 1)
  %add.ptr.i437.i = getelementptr inbounds i8, ptr %add.ptr.i435.i117, i20 %idx.ext.i434.i85
  %55 = load <8 x i32>, ptr %add.ptr.i437.i, align 32, !tbaa !4
  %56 = tail call <16 x i32> @llvm.aie2.upd.I512.I256(<16 x i32> %0, <8 x i32> %55, i32 0)
  %add.ptr.i439.i118 = getelementptr inbounds i8, ptr %add.ptr.i437.i, i20 %idx.ext.i434.i85
  %57 = load <8 x i32>, ptr %add.ptr.i439.i118, align 32, !tbaa !4
  %58 = tail call <16 x i32> @llvm.aie2.upd.I512.I256(<16 x i32> %56, <8 x i32> %57, i32 1)
  %59 = tail call <16 x i32> @llvm.aie2.vshift.I512.I512(<16 x i32> %50, <16 x i32> %54, i32 %1, i32 %frac.0652.i)
  %60 = tail call <16 x i32> @llvm.aie2.vshift.I512.I512(<16 x i32> %49, <16 x i32> %58, i32 %1, i32 %frac.0652.i)
  %61 = trunc i32 %iterator_inner_cnt0.1649.i to i20
  %62 = trunc i32 %iterator_inner_cnt1.1648.i to i20
  %63 = tail call { ptr, i20, i20 } @llvm.aie2.add.3d(ptr nonnull %add.ptr.i439.i118, i20 %2, i20 %3, i20 %4, i20 %5, i20 %61, i20 %6, i20 %62)
  %64 = extractvalue { ptr, i20, i20 } %63, 1
  %65 = zext i20 %64 to i32
  %66 = extractvalue { ptr, i20, i20 } %63, 2
  %67 = zext i20 %66 to i32
  %68 = extractvalue { ptr, i20, i20 } %63, 0
  %69 = tail call <16 x i32> @llvm.aie2.vshuffle(<16 x i32> %59, <16 x i32> %60, i32 %7)
  %70 = tail call <16 x i32> @llvm.aie2.vshuffle(<16 x i32> %69, <16 x i32> %0, i32 11)
  %71 = tail call <16 x i32> @llvm.aie2.vshuffle(<16 x i32> %59, <16 x i32> %60, i32 %8)
  %72 = tail call <16 x i32> @llvm.aie2.vshuffle(<16 x i32> %71, <16 x i32> %0, i32 11)
  %73 = tail call <8 x i32> @llvm.aie2.ext.I256.I512(<16 x i32> %69, i32 0)
  %74 = tail call <8 x i32> @llvm.aie2.ext.I256.I512(<16 x i32> %70, i32 0)
  %75 = tail call <8 x i32> @llvm.aie2.ext.I256.I512(<16 x i32> %71, i32 0)
  %76 = tail call <8 x i32> @llvm.aie2.ext.I256.I512(<16 x i32> %72, i32 0)
  %77 = load <8 x i32>, ptr %p_w.1654.i, align 32, !tbaa !4
  %78 = tail call <16 x i32> @llvm.aie2.upd.I512.I256(<16 x i32> %Ybuff0.sroa.0.1651.i, <8 x i32> %77, i32 0)
  %add.ptr152.i = getelementptr inbounds i8, ptr %p_w.1654.i, i20 32
  %79 = load <8 x i32>, ptr %add.ptr152.i, align 32, !tbaa !4
  %80 = tail call <16 x i32> @llvm.aie2.upd.I512.I256(<16 x i32> %78, <8 x i32> %79, i32 1)
  %add.ptr155.i = getelementptr inbounds i8, ptr %p_w.1654.i, i20 64
  %81 = load <8 x i32>, ptr %add.ptr155.i, align 32, !tbaa !4
  %82 = tail call <16 x i32> @llvm.aie2.upd.I512.I256(<16 x i32> %Ybuff1.sroa.0.1650.i, <8 x i32> %81, i32 0)
  %add.ptr158.i = getelementptr inbounds i8, ptr %p_w.1654.i, i20 96
  %83 = load <8 x i32>, ptr %add.ptr158.i, align 32, !tbaa !4
  %84 = tail call <16 x i32> @llvm.aie2.upd.I512.I256(<16 x i32> %82, <8 x i32> %83, i32 1)
  %add.ptr161.i = getelementptr inbounds i8, ptr %p_w.1654.i, i20 128
  %85 = tail call <16 x i32> @llvm.aie2.set.I512.I256(<8 x i32> %73, i32 0)
  %86 = bitcast <16 x i32> %85 to <64 x i8>
  %87 = tail call <16 x i64> @llvm.aie2.I512.I512.ACC1024.acc32.mac.conf(<64 x i8> %86, <16 x i32> %80, <16 x i64> %Cbuff0.sroa.0.0647.i, i32 %or9.i.i.i.i.i96)
  %88 = tail call <16 x i32> @llvm.aie2.set.I512.I256(<8 x i32> %74, i32 0)
  %89 = bitcast <16 x i32> %88 to <64 x i8>
  %90 = tail call <16 x i64> @llvm.aie2.I512.I512.ACC1024.acc32.mac.conf(<64 x i8> %89, <16 x i32> %80, <16 x i64> %Cbuff1.sroa.0.0646.i, i32 %or9.i.i.i.i.i96)
  %91 = tail call <16 x i32> @llvm.aie2.set.I512.I256(<8 x i32> %75, i32 0)
  %92 = bitcast <16 x i32> %91 to <64 x i8>
  %93 = tail call <16 x i64> @llvm.aie2.I512.I512.ACC1024.acc32.mac.conf(<64 x i8> %92, <16 x i32> %80, <16 x i64> %Cbuff2.sroa.0.0645.i, i32 %or9.i.i.i.i.i96)
  %94 = tail call <16 x i32> @llvm.aie2.set.I512.I256(<8 x i32> %76, i32 0)
  %95 = bitcast <16 x i32> %94 to <64 x i8>
  %96 = tail call <16 x i64> @llvm.aie2.I512.I512.ACC1024.acc32.mac.conf(<64 x i8> %95, <16 x i32> %80, <16 x i64> %Cbuff3.sroa.0.0644.i, i32 %or9.i.i.i.i.i96)
  %97 = tail call <16 x i64> @llvm.aie2.I512.I512.ACC1024.acc32.mac.conf(<64 x i8> %86, <16 x i32> %84, <16 x i64> %Cbuff4.sroa.0.0643.i, i32 %or9.i.i.i.i.i96)
  %98 = tail call <16 x i64> @llvm.aie2.I512.I512.ACC1024.acc32.mac.conf(<64 x i8> %89, <16 x i32> %84, <16 x i64> %Cbuff5.sroa.0.0642.i, i32 %or9.i.i.i.i.i96)
  %99 = tail call <16 x i64> @llvm.aie2.I512.I512.ACC1024.acc32.mac.conf(<64 x i8> %92, <16 x i32> %84, <16 x i64> %Cbuff6.sroa.0.0641.i, i32 %or9.i.i.i.i.i96)
  %100 = tail call <16 x i64> @llvm.aie2.I512.I512.ACC1024.acc32.mac.conf(<64 x i8> %95, <16 x i32> %84, <16 x i64> %Cbuff7.sroa.0.0640.i, i32 %or9.i.i.i.i.i96)
  %101 = ptrtoint ptr %68 to i20
  %102 = and i20 %101, 31
  %narrow402.i = add nuw nsw i20 %102, 33
  %add187.i = zext i20 %narrow402.i to i32
  %inc.i119 = add nuw i32 %i.0653.i, 1
  %exitcond.not.i120 = icmp eq i32 %inc.i119, %9
  br i1 %exitcond.not.i120, label %outer.loop.latch, label %inner.loop, !llvm.loop !119

outer.loop.latch:                            ; preds = %inner.loop
  %103 = extractvalue { ptr, i20, i20 } %63, 0
  %add.ptr.i423.i113 = getelementptr inbounds i8, ptr %add.ptr.i420.i111, i20 %idx.ext.i422.i82
  %104 = trunc i32 %iterator_outer_cnt0.0663.i to i20
  %105 = trunc i32 %iterator_outer_cnt1.0662.i to i20
  %106 = tail call { ptr, i20, i20 } @llvm.aie2.add.3d(ptr %103, i20 %10, i20 %11, i20 %12, i20 %13, i20 %104, i20 %14, i20 %105)
  %107 = extractvalue { ptr, i20, i20 } %106, 1
  %108 = zext i20 %107 to i32
  %109 = extractvalue { ptr, i20, i20 } %106, 2
  %110 = zext i20 %109 to i32
  %111 = extractvalue { ptr, i20, i20 } %106, 0
  %112 = trunc i32 %iterator_weights_cnt0.0661.i to i20
  %113 = trunc i32 %iterator_weights_cnt1.0660.i to i20
  %114 = tail call { ptr, i20, i20 } @llvm.aie2.add.3d(ptr nonnull %add.ptr161.i, i20 %15, i20 %16, i20 %17, i20 %18, i20 %112, i20 %19, i20 %113)
  %115 = extractvalue { ptr, i20, i20 } %114, 1
  %116 = zext i20 %115 to i32
  %117 = extractvalue { ptr, i20, i20 } %114, 2
  %118 = zext i20 %117 to i32
  %119 = extractvalue { ptr, i20, i20 } %114, 0
  %120 = trunc i32 %iterator_psum_cnt0.0659.i to i20
  %121 = trunc i32 %iterator_psum_cnt1.0658.i to i20
  %122 = tail call { ptr, i20, i20 } @llvm.aie2.add.3d(ptr nonnull %add.ptr.i423.i113, i20 %20, i20 0, i20 %21, i20 %22, i20 %120, i20 %23, i20 %121)
  %123 = extractvalue { ptr, i20, i20 } %122, 1
  %124 = zext i20 %123 to i32
  %125 = extractvalue { ptr, i20, i20 } %122, 2
  %126 = zext i20 %125 to i32
  %127 = extractvalue { ptr, i20, i20 } %122, 0
  %128 = tail call <32 x i16> @llvm.aie2.I512.v32.acc32.srs(<16 x i64> %87, i32 %conv192.i107, i32 1)
  store <32 x i16> %128, ptr %p_out.0669.i, align 64, !tbaa !4
  %add.ptr.i424.i = getelementptr inbounds i8, ptr %p_out.0669.i, i20 64
  %129 = tail call <32 x i16> @llvm.aie2.I512.v32.acc32.srs(<16 x i64> %90, i32 %conv192.i107, i32 1)
  store <32 x i16> %129, ptr %add.ptr.i424.i, align 64, !tbaa !4
  %add.ptr.i426.i114 = getelementptr inbounds i8, ptr %add.ptr.i424.i, i20 %24
  %130 = tail call <32 x i16> @llvm.aie2.I512.v32.acc32.srs(<16 x i64> %93, i32 %conv192.i107, i32 1)
  store <32 x i16> %130, ptr %add.ptr.i426.i114, align 64, !tbaa !4
  %add.ptr.i427.i = getelementptr inbounds i8, ptr %add.ptr.i426.i114, i20 64
  %131 = tail call <32 x i16> @llvm.aie2.I512.v32.acc32.srs(<16 x i64> %96, i32 %conv192.i107, i32 1)
  store <32 x i16> %131, ptr %add.ptr.i427.i, align 64, !tbaa !4
  %add.ptr.i429.i115 = getelementptr inbounds i8, ptr %add.ptr.i427.i, i20 %idx.ext.i428.i
  %132 = tail call <32 x i16> @llvm.aie2.I512.v32.acc32.srs(<16 x i64> %97, i32 %conv192.i107, i32 1)
  store <32 x i16> %132, ptr %add.ptr.i429.i115, align 64, !tbaa !4
  %add.ptr.i430.i = getelementptr inbounds i8, ptr %add.ptr.i429.i115, i20 64
  %133 = tail call <32 x i16> @llvm.aie2.I512.v32.acc32.srs(<16 x i64> %98, i32 %conv192.i107, i32 1)
  store <32 x i16> %133, ptr %add.ptr.i430.i, align 64, !tbaa !4
  %add.ptr.i432.i116 = getelementptr inbounds i8, ptr %add.ptr.i430.i, i20 %24
  %134 = tail call <32 x i16> @llvm.aie2.I512.v32.acc32.srs(<16 x i64> %99, i32 %conv192.i107, i32 1)
  store <32 x i16> %134, ptr %add.ptr.i432.i116, align 64, !tbaa !4
  %add.ptr.i433.i = getelementptr inbounds i8, ptr %add.ptr.i432.i116, i20 64
  %135 = tail call <32 x i16> @llvm.aie2.I512.v32.acc32.srs(<16 x i64> %100, i32 %conv192.i107, i32 1)
  store <32 x i16> %135, ptr %add.ptr.i433.i, align 64, !tbaa !4
  %136 = trunc i32 %iterator_pout_cnt0.0657.i to i20
  %137 = tail call { ptr, i20 } @llvm.aie2.add.2d(ptr nonnull %add.ptr.i433.i, i20 %25, i20 %26, i20 %27, i20 %136)
  %138 = extractvalue { ptr, i20 } %137, 1
  %139 = zext i20 %138 to i32
  %140 = extractvalue { ptr, i20 } %137, 0
  %inc237.i = add nuw i32 %j.0668.i, 1
  %exitcond687.not.i = icmp eq i32 %inc237.i, %28
  br i1 %exitcond687.not.i, label %exitStub, label %outer.loop.header, !llvm.loop !122

exitStub:                               ; preds = %outer.loop.latch
  ret void
}

; Function Attrs: nounwind memory(none)
declare <16 x i64> @llvm.aie2.acc32.v32.I512.ups(<32 x i16>, i32, i32) #0

; Function Attrs: nounwind memory(none)
declare <32 x i16> @llvm.aie2.I512.v32.acc32.srs(<16 x i64>, i32, i32) #0

; Function Attrs: nounwind memory(none)
declare { ptr, i20 } @llvm.aie2.add.2d(ptr, i20, i20, i20, i20) #0

; Function Attrs: nounwind memory(none)
declare <16 x i32> @llvm.aie2.upd.I512.I256(<16 x i32>, <8 x i32>, i32) #0

; Function Attrs: nounwind memory(none)
declare <16 x i32> @llvm.aie2.vshift.I512.I512(<16 x i32>, <16 x i32>, i32, i32) #0

; Function Attrs: nounwind memory(none)
declare { ptr, i20, i20 } @llvm.aie2.add.3d(ptr, i20, i20, i20, i20, i20, i20, i20) #0

; Function Attrs: nounwind memory(none)
declare <16 x i32> @llvm.aie2.vshuffle(<16 x i32>, <16 x i32>, i32) #0

; Function Attrs: nounwind memory(none)
declare <8 x i32> @llvm.aie2.ext.I256.I512(<16 x i32>, i32) #0

; Function Attrs: nounwind memory(none)
declare <16 x i64> @llvm.aie2.I512.I512.ACC1024.acc32.mac.conf(<64 x i8>, <16 x i32>, <16 x i64>, i32) #0

; Function Attrs: nounwind memory(none)
declare <16 x i32> @llvm.aie2.set.I512.I256(<8 x i32>, i32) #0

attributes #0 = { nounwind memory(none) }
attributes #1 = { "no-jump-tables"="true" "no-trapping-math"="true" "stack-protector-buffer-size"="8" }

!llvm.linker.options = !{}
!llvm.module.flags = !{!0, !1, !2}
!llvm.ident = !{!3}

!0 = !{i32 7, !"Dwarf Version", i32 4}
!1 = !{i32 2, !"Debug Info Version", i32 3}
!2 = !{i32 1, !"wchar_size", i32 4}
!3 = !{!"clang version 17.0.0 (git@gitenterprise.xilinx.com:XRLabs/llvm-aie.git bbdf5affb7caccf6d5d27edd19fdf423dc9ab998)"}
!4 = !{!5, !5, i64 0}
!5 = !{!"omnipotent char", !6, i64 0}
!6 = !{!"Simple C++ TBAA"}
!119 = distinct !{!119, !120, !121, !123}
!120 = !{!"llvm.loop.mustprogress"}
!121 = !{!"llvm.loop.unroll.disable"}
!122 = distinct !{!122, !120, !121}
!123 = !{!"llvm.loop.itercount.range", i64 4}
