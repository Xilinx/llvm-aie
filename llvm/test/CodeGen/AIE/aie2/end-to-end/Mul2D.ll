; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc -O2 -mtriple=aie2 --enable-pipeliner=0 %s -o - | FileCheck %s
;
; This file is licensed under the Apache License v2.0 with LLVM Exceptions.
; See https://llvm.org/LICENSE.txt for license information.
; SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
;
; (c) Copyright 2023-2024 Advanced Micro Devices, Inc. or its affiliates

; RUN: opt -mtriple=aie2 -passes=aa-eval -print-all-alias-modref-info -disable-output < %s 2>&1 | FileCheck %s --check-prefix=AA

; A reduced example from MLLib's mul2d benchmark.

declare { ptr, i20 } @llvm.aie2.add.2d(ptr, i20, i20, i20, i20)
declare { ptr, i20, i20 } @llvm.aie2.add.3d(ptr, i20, i20, i20, i20, i20, i20, i20)
%struct.mul2d_params = type { i8, i8, i8, i8, i16, i8, i8, i16, i8, i32, i32, i32, i32, i32 }
declare <32 x i8> @llvm.aie2.v32int8()
declare <64 x i8> @llvm.aie2.v64int8()
declare <64 x i8> @llvm.aie2.vbroadcast8.I512(i32)
declare <8 x i32> @llvm.aie2.ext.I256.I512(<16 x i32>, i32)
declare <16 x i32> @llvm.aie2.set.I512.I256(<8 x i32>, i32)
declare <16 x i32> @llvm.aie2.upd.I512.I256(<16 x i32>, <8 x i32>, i32)
declare <16 x i64> @llvm.aie2.I512.I512.acc32.mul.conf(<64 x i8>, <16 x i32>, i32)
declare <32 x i8> @llvm.aie2.I256.v32.acc32.srs(<16 x i64>, i32, i32)
declare <16 x i64> @llvm.aie2.v32acc32()

; AA-LABEL: Function: mul2d
; AA:  NoAlias:      <8 x i32> addrspace(5)* %in_ptr0.addr.058.ascast, <8 x i32> addrspace(5)* %in_ptr1.addr.057.ascast
; AA:  NoAlias:      <8 x i32> addrspace(5)* %in_ptr0.addr.058.ascast, <32 x i8> addrspace(6)* %out_ptr.addr.056.ascast
; AA:  NoAlias:      <8 x i32> addrspace(5)* %in_ptr1.addr.057.ascast, <32 x i8> addrspace(6)* %out_ptr.addr.056.ascast
; AA:  NoAlias:      <8 x i32> addrspace(5)* %ascast.13, <8 x i32> addrspace(5)* %in_ptr0.addr.058.ascast
; AA:  NoAlias:      <8 x i32> addrspace(5)* %ascast.13, <8 x i32> addrspace(5)* %in_ptr1.addr.057.ascast
; AA:  NoAlias:      <8 x i32> addrspace(5)* %ascast.13, <32 x i8> addrspace(6)* %out_ptr.addr.056.ascast
; AA:  NoAlias:      <8 x i32> addrspace(5)* %ascast.add.ptr.i, <8 x i32> addrspace(5)* %in_ptr0.addr.058.ascast
; AA:  NoAlias:      <8 x i32> addrspace(5)* %ascast.add.ptr.i, <8 x i32> addrspace(5)* %in_ptr1.addr.057.ascast
; AA:  NoAlias:      <8 x i32> addrspace(5)* %ascast.add.ptr.i, <32 x i8> addrspace(6)* %out_ptr.addr.056.ascast
; AA:  NoAlias:      <8 x i32> addrspace(5)* %ascast.13, <8 x i32> addrspace(5)* %ascast.add.ptr.i
; AA:  NoAlias:      <32 x i8> addrspace(6)* %add.ptr.ascast, <8 x i32> addrspace(5)* %in_ptr0.addr.058.ascast
; AA:  NoAlias:      <32 x i8> addrspace(6)* %add.ptr.ascast, <8 x i32> addrspace(5)* %in_ptr1.addr.057.ascast
; AA:  NoAlias:      <32 x i8> addrspace(6)* %add.ptr.ascast, <32 x i8> addrspace(6)* %out_ptr.addr.056.ascast
; AA:  NoAlias:      <32 x i8> addrspace(6)* %add.ptr.ascast, <8 x i32> addrspace(5)* %ascast.13
; AA:  NoAlias:      <32 x i8> addrspace(6)* %add.ptr.ascast, <8 x i32> addrspace(5)* %ascast.add.ptr.i

; Two vectors are loaded and fed to a vmul: one through a vlda.postinc, the
; other through a vlda.3d.
; After the first vmul, we should immediately start loading the next inputs for
; the second vmul.
;
; FIXME: This does not happen for the second "vlda.3d wl4, [p0], d0", which
; somehow gets an ordering edge with the vst.srs.
define void @mul2d(ptr noalias %in_ptr0, ptr noalias %in_ptr1, ptr noalias %out_ptr, %struct.mul2d_params %params.coerce) {
; CHECK-LABEL: mul2d:
; CHECK:         .p2align 4
; CHECK-NEXT:  // %bb.0: // %entry
; CHECK-NEXT:    mova r0, #2; nopb ; extend.u16 r1, r4; nopm
; CHECK-NEXT:    ltu r0, r1, r0
; CHECK-NEXT:    jnz r0, #.LBB0_4
; CHECK-NEXT:    nop // Delay Slot 5
; CHECK-NEXT:    nop // Delay Slot 4
; CHECK-NEXT:    nop // Delay Slot 3
; CHECK-NEXT:    nop // Delay Slot 2
; CHECK-NEXT:    nop // Delay Slot 1
; CHECK-NEXT:  // %bb.1: // %for.body.lr.ph
; CHECK-NEXT:    nopa ; nopb ; nopx ; mov p3, sp; nops
; CHECK-NEXT:    paddb [p3], #-4
; CHECK-NEXT:    lda.u8 r0, [p3, #0]; mov p3, sp
; CHECK-NEXT:    paddb [p3], #-8
; CHECK-NEXT:    lda dj0, [p3, #0]; mov p3, sp
; CHECK-NEXT:    paddb [p3], #-12
; CHECK-NEXT:    lda dj4, [p3, #0]; mov p3, sp
; CHECK-NEXT:    paddb [p3], #-16
; CHECK-NEXT:    lda dn0, [p3, #0]; mov p3, sp
; CHECK-NEXT:    paddb [p3], #-20
; CHECK-NEXT:    lda dn4, [p3, #0]; mov p3, sp
; CHECK-NEXT:    paddb [p3], #-24
; CHECK-NEXT:    lda m0, [p3, #0]
; CHECK-NEXT:    extend.u8 r5, r5
; CHECK-NEXT:    mova dc0, #0; mov s0, r5
; CHECK-NEXT:    mova r3, #0; movx r2, #1; mov dc4, dc0
; CHECK-NEXT:    mova r4, #-1; ne r2, r0, r2; vbcst.8 x0, r3
; CHECK-NEXT:    mova r0, #808; lshl r1, r1, r4; mov crSRSSign, r2
; CHECK-NEXT:    .p2align 4
; CHECK-NEXT:  .LBB0_2: // %for.body
; CHECK-NEXT:    // =>This Inner Loop Header: Depth=1
; CHECK-NEXT:    vldb wl2, [p1], #32; nopx
; CHECK-NEXT:    vldb.3d wl6, [p0], d0
; CHECK-NEXT:    vldb wl4, [p1], #32
; CHECK-NEXT:    vldb.3d wl2, [p0], d0
; CHECK-NEXT:    nop
; CHECK-NEXT:    nop
; CHECK-NEXT:    nop
; CHECK-NEXT:    vmov wh6, wl0
; CHECK-NEXT:    vmov wh2, wl0
; CHECK-NEXT:    add r1, r1, #-1; vmul cm0, x6, x2, r0
; CHECK-NEXT:    jnz r1, #.LBB0_2; vmul cm1, x2, x4, r0
; CHECK-NEXT:    nop // Delay Slot 5
; CHECK-NEXT:    nop // Delay Slot 4
; CHECK-NEXT:    nop // Delay Slot 3
; CHECK-NEXT:    vst.srs.d8.s32 cm0, s0, [p2], #32 // Delay Slot 2
; CHECK-NEXT:    vst.srs.d8.s32 cm1, s0, [p2], #32 // Delay Slot 1
; CHECK-NEXT:  // %bb.3:
; CHECK-NEXT:    nopa ; nopxm
; CHECK-NEXT:    nop
; CHECK-NEXT:    mov crSRSSign, #0
; CHECK-NEXT:    .p2align 4
; CHECK-NEXT:  .LBB0_4: // %for.cond.cleanup
; CHECK-NEXT:    nopa ; ret lr
; CHECK-NEXT:    nop // Delay Slot 5
; CHECK-NEXT:    nop // Delay Slot 4
; CHECK-NEXT:    nop // Delay Slot 3
; CHECK-NEXT:    nop // Delay Slot 2
; CHECK-NEXT:    nop // Delay Slot 1
  entry:
    %params.coerce.fca.4.extract = extractvalue %struct.mul2d_params %params.coerce, 4
    %cmp53.not = icmp ult i16 %params.coerce.fca.4.extract, 2
    br i1 %cmp53.not, label %for.cond.cleanup, label %for.body.lr.ph

  for.body.lr.ph:                                   ; preds = %entry
    %0 = lshr i16 %params.coerce.fca.4.extract, 1
    %params.coerce.fca.13.extract = extractvalue %struct.mul2d_params %params.coerce, 13
    %params.coerce.fca.12.extract = extractvalue %struct.mul2d_params %params.coerce, 12
    %params.coerce.fca.11.extract = extractvalue %struct.mul2d_params %params.coerce, 11
    %params.coerce.fca.10.extract = extractvalue %struct.mul2d_params %params.coerce, 10
    %params.coerce.fca.9.extract = extractvalue %struct.mul2d_params %params.coerce, 9
    %params.coerce.fca.8.extract = extractvalue %struct.mul2d_params %params.coerce, 8
    %params.coerce.fca.5.extract = extractvalue %struct.mul2d_params %params.coerce, 5
    %1 = tail call <32 x i8> @llvm.aie2.v32int8()
    %2 = trunc i32 %params.coerce.fca.13.extract to i20
    %3 = trunc i32 %params.coerce.fca.9.extract to i20
    %4 = trunc i32 %params.coerce.fca.10.extract to i20
    %5 = trunc i32 %params.coerce.fca.11.extract to i20
    %6 = trunc i32 %params.coerce.fca.12.extract to i20
    %tobool = icmp ne i8 %params.coerce.fca.8.extract, 1
    %conv5 = zext i8 %params.coerce.fca.5.extract to i32
    %conv.i.i.i = zext i1 %tobool to i32
    %umax = zext i16 %0 to i32
    br label %for.body

  for.cond.cleanup:                                 ; preds = %for.body, %entry
    ret void

  for.body:                                         ; preds = %for.body.lr.ph, %for.body
    %lsr.iv = phi i32 [ %umax, %for.body.lr.ph ], [ %lsr.iv.next, %for.body ]
    %in_ptr0.addr.058 = phi ptr [ %in_ptr0, %for.body.lr.ph ], [ %32, %for.body ]
    %in_ptr1.addr.057 = phi ptr [ %in_ptr1, %for.body.lr.ph ], [ %add.ptr.i39, %for.body ]
    %out_ptr.addr.056 = phi ptr [ %out_ptr, %for.body.lr.ph ], [ %add.ptr21, %for.body ]
    %itr_left_cnt0.055 = phi i32 [ 0, %for.body.lr.ph ], [ %29, %for.body ]
    %itr_left_cnt1.054 = phi i32 [ 0, %for.body.lr.ph ], [ %31, %for.body ]
    %in_ptr0.addr.058.ascast = addrspacecast ptr %in_ptr0.addr.058 to ptr addrspace(5)
    %7 = load <8 x i32>, ptr addrspace(5) %in_ptr0.addr.058.ascast, align 32
    %8 = trunc i32 %itr_left_cnt0.055 to i20
    %9 = trunc i32 %itr_left_cnt1.054 to i20
    %10 = tail call { ptr, i20, i20 } @llvm.aie2.add.3d(ptr nonnull %in_ptr0.addr.058, i20 %2, i20 %3, i20 %4, i20 %5, i20 %8, i20 %6, i20 %9)
    %11 = extractvalue { ptr, i20, i20 } %10, 1
    %12 = extractvalue { ptr, i20, i20 } %10, 2
    %13 = extractvalue { ptr, i20, i20 } %10, 0
    %in_ptr1.addr.057.ascast = addrspacecast ptr %in_ptr1.addr.057 to ptr addrspace(5)
    %14 = load <8 x i32>, ptr addrspace(5) %in_ptr1.addr.057.ascast, align 32
    %add.ptr.i = getelementptr inbounds i8, ptr %in_ptr1.addr.057, i20 32
    %15 = tail call <16 x i64> @llvm.aie2.v32acc32()
    %16 = tail call <64 x i8> @llvm.aie2.v64int8()
    %17 = tail call <64 x i8> @llvm.aie2.vbroadcast8.I512(i32 0)
    %18 = bitcast <64 x i8> %17 to <16 x i32>
    %19 = tail call <8 x i32> @llvm.aie2.ext.I256.I512(<16 x i32> %18, i32 0)
    %20 = tail call <16 x i32> @llvm.aie2.set.I512.I256(<8 x i32> %7, i32 0)
    %21 = tail call <16 x i32> @llvm.aie2.upd.I512.I256(<16 x i32> %20, <8 x i32> %19, i32 1)
    %22 = tail call <16 x i32> @llvm.aie2.set.I512.I256(<8 x i32> %14, i32 0)
    %23 = bitcast <16 x i32> %21 to <64 x i8>
    %24 = tail call <16 x i64> @llvm.aie2.I512.I512.acc32.mul.conf(<64 x i8> %23, <16 x i32> %22, i32 808)
    %25 = tail call <32 x i8> @llvm.aie2.I256.v32.acc32.srs(<16 x i64> %24, i32 %conv5, i32 %conv.i.i.i)
    %out_ptr.addr.056.ascast = addrspacecast ptr %out_ptr.addr.056 to ptr addrspace(6)
    store <32 x i8> %25, ptr addrspace(6) %out_ptr.addr.056.ascast , align 32
    %add.ptr = getelementptr inbounds i8, ptr %out_ptr.addr.056, i20 32
    %ascast.13 = addrspacecast ptr %13 to ptr addrspace(5)
    %26 = load <8 x i32>, ptr addrspace(5) %ascast.13, align 32
    %27 = tail call { ptr, i20, i20 } @llvm.aie2.add.3d(ptr nonnull %13, i20 %2, i20 %3, i20 %4, i20 %5, i20 %11, i20 %6, i20 %12)
    %28 = extractvalue { ptr, i20, i20 } %27, 1
    %29 = zext i20 %28 to i32
    %30 = extractvalue { ptr, i20, i20 } %27, 2
    %31 = zext i20 %30 to i32
    %32 = extractvalue { ptr, i20, i20 } %27, 0
    %ascast.add.ptr.i = addrspacecast ptr %add.ptr.i to ptr addrspace(5)
    %33 = load <8 x i32>, ptr addrspace(5) %ascast.add.ptr.i, align 32
    %add.ptr.i39 = getelementptr inbounds i8, ptr %in_ptr1.addr.057, i20 64
    %34 = tail call <16 x i32> @llvm.aie2.set.I512.I256(<8 x i32> %26, i32 0)
    %35 = tail call <16 x i32> @llvm.aie2.upd.I512.I256(<16 x i32> %34, <8 x i32> %19, i32 1)
    %36 = tail call <16 x i32> @llvm.aie2.set.I512.I256(<8 x i32> %33, i32 0)
    %37 = bitcast <16 x i32> %35 to <64 x i8>
    %38 = tail call <16 x i64> @llvm.aie2.I512.I512.acc32.mul.conf(<64 x i8> %37, <16 x i32> %36, i32 808)
    %39 = tail call <32 x i8> @llvm.aie2.I256.v32.acc32.srs(<16 x i64> %38, i32 %conv5, i32 %conv.i.i.i)
    %add.ptr.ascast = addrspacecast ptr %add.ptr to ptr addrspace(6)
    store <32 x i8> %39, ptr addrspace(6) %add.ptr.ascast, align 32
    %add.ptr21 = getelementptr inbounds i8, ptr %out_ptr.addr.056, i20 64
    %lsr.iv.next = add nsw i32 %lsr.iv, -1
    %exitcond.not = icmp eq i32 %lsr.iv.next, 0
    br i1 %exitcond.not, label %for.cond.cleanup, label %for.body
  }
