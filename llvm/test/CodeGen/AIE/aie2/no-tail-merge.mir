# NOTE: Assertions have been autogenerated by utils/update_mir_test_checks.py
#
# This file is licensed under the Apache License v2.0 with LLVM Exceptions.
# See https://llvm.org/LICENSE.txt for license information.
# SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
#
# (c) Copyright 2024 Advanced Micro Devices, Inc. or its affiliates

# RUN: llc -mtriple=aie2 -start-before=branch-folder --stop-after=block-placement \
# RUN:   --tail-merge-size=1 %s -o - \
# RUN:   | FileCheck %s --check-prefix=TAILMERGE-DEF
# RUN: llc -mtriple=aie2 -start-before=branch-folder --stop-after=block-placement \
# RUN:   --aie-enable-tail-merge=1 --tail-merge-size=1 %s -o - \
# RUN:   | FileCheck %s --check-prefix=TAILMERGE-ON

# This is a small test that shows how tail merging can absolutely destroy
# carefully crafted SW pipelines. If we are unlucky to have common instructions
# between a prologue and the steady state, tail merging can insert an unconditional
# jump in the middle of that loop to share the instruciton sequence. Obviously this
# is bad for AIE, because of delay slots. Complex control flow also makes scheduling
# harder.
---
name: mini_add_swp
tracksRegLiveness: true
body: |
  ; TAILMERGE-DEF-LABEL: name: mini_add_swp
  ; TAILMERGE-DEF: bb.0.entry:
  ; TAILMERGE-DEF-NEXT:   successors: %bb.1(0x40000000), %bb.2(0x40000000)
  ; TAILMERGE-DEF-NEXT:   liveins: $p0, $p1, $p2, $m0, $s0, $x0, $r0, $r1, $d0_3d
  ; TAILMERGE-DEF-NEXT: {{  $}}
  ; TAILMERGE-DEF-NEXT:   $r0 = ADD_add_r_ri $r0, -4, implicit-def $srcarry
  ; TAILMERGE-DEF-NEXT:   $cm0, $p0 = VLDA_UPS_S32_D8_ag_pstm_nrm $s0, $p0, $m0, implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<32 x s8>) from stack - 64)
  ; TAILMERGE-DEF-NEXT:   $cm1, $p1, $dc0, $dc4 = VLDA_3D_UPS_S32_D8 $s0, $p1, $d0_3d, implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<32 x s8>) from stack - 32)
  ; TAILMERGE-DEF-NEXT:   $cm2 = VADD $cm0, $cm1, $r1
  ; TAILMERGE-DEF-NEXT:   $r0 = ADD_add_r_ri $r0, -4, implicit-def $srcarry
  ; TAILMERGE-DEF-NEXT:   $cm0, $p0 = VLDA_UPS_S32_D8_ag_pstm_nrm $s0, $p0, $m0, implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<32 x s8>) from stack - 64)
  ; TAILMERGE-DEF-NEXT:   $cm1, $p1, $dc0, $dc4 = VLDA_3D_UPS_S32_D8 $s0, $p1, $d0_3d, implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<32 x s8>) from stack - 32)
  ; TAILMERGE-DEF-NEXT:   PseudoJZ $r0, %bb.2
  ; TAILMERGE-DEF-NEXT: {{  $}}
  ; TAILMERGE-DEF-NEXT: bb.1:
  ; TAILMERGE-DEF-NEXT:   successors: %bb.2(0x04000000), %bb.1(0x7c000000)
  ; TAILMERGE-DEF-NEXT:   liveins: $p0, $p1, $p2, $m0, $cm0, $cm1, $cm2, $s0, $x0, $r0, $r1, $d0_3d
  ; TAILMERGE-DEF-NEXT: {{  $}}
  ; TAILMERGE-DEF-NEXT:   $p2 = VST_SRS_D8_S32_ag_pstm_nrm_imm $p2, 32, $cm2, $s0, implicit-def $srsrs_of, implicit $crsat, implicit $crrnd, implicit $crsrssign :: (store (<32 x s8>) into stack - 128)
  ; TAILMERGE-DEF-NEXT:   $cm2 = VADD $cm0, $cm1, $r1
  ; TAILMERGE-DEF-NEXT:   $r0 = ADD_add_r_ri $r0, -4, implicit-def $srcarry
  ; TAILMERGE-DEF-NEXT:   $cm0, $p0 = VLDA_UPS_S32_D8_ag_pstm_nrm $s0, $p0, $m0, implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<32 x s8>) from stack - 64)
  ; TAILMERGE-DEF-NEXT:   $cm1, $p1, $dc0, $dc4 = VLDA_3D_UPS_S32_D8 $s0, $p1, $d0_3d, implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<32 x s8>) from stack - 32)
  ; TAILMERGE-DEF-NEXT:   PseudoJNZ $r0, %bb.1
  ; TAILMERGE-DEF-NEXT: {{  $}}
  ; TAILMERGE-DEF-NEXT: bb.2:
  ; TAILMERGE-DEF-NEXT:   liveins: $p2, $cm0, $cm1, $cm2, $s0, $r1
  ; TAILMERGE-DEF-NEXT: {{  $}}
  ; TAILMERGE-DEF-NEXT:   $p2 = VST_SRS_D8_S32_ag_pstm_nrm_imm $p2, 32, $cm2, $s0, implicit-def $srsrs_of, implicit $crsat, implicit $crrnd, implicit $crsrssign :: (store (<32 x s8>) into stack - 128)
  ; TAILMERGE-DEF-NEXT:   $cm2 = VADD $cm0, $cm1, $r1
  ; TAILMERGE-DEF-NEXT:   $p2 = VST_SRS_D8_S32_ag_pstm_nrm_imm $p2, 32, $cm2, $s0, implicit-def $srsrs_of, implicit $crsat, implicit $crrnd, implicit $crsrssign :: (store (<32 x s8>) into stack - 128)
  ; TAILMERGE-DEF-NEXT:   PseudoRET implicit $lr
  ;
  ; TAILMERGE-ON-LABEL: name: mini_add_swp
  ; TAILMERGE-ON: bb.0.entry:
  ; TAILMERGE-ON-NEXT:   successors: %bb.2(0x80000000)
  ; TAILMERGE-ON-NEXT:   liveins: $p0, $p1, $p2, $m0, $s0, $x0, $r0, $r1, $d0_3d
  ; TAILMERGE-ON-NEXT: {{  $}}
  ; TAILMERGE-ON-NEXT:   $r0 = ADD_add_r_ri $r0, -4, implicit-def $srcarry
  ; TAILMERGE-ON-NEXT:   $cm0, $p0 = VLDA_UPS_S32_D8_ag_pstm_nrm $s0, $p0, $m0, implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<32 x s8>) from stack - 64)
  ; TAILMERGE-ON-NEXT:   $cm1, $p1, $dc0, $dc4 = VLDA_3D_UPS_S32_D8 $s0, $p1, $d0_3d, implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<32 x s8>) from stack - 32)
  ; TAILMERGE-ON-NEXT: {{  $}}
  ; TAILMERGE-ON-NEXT: bb.2:
  ; TAILMERGE-ON-NEXT:   successors: %bb.3(0x07878788), %bb.1(0x78787878)
  ; TAILMERGE-ON-NEXT:   liveins: $p2, $d0_3d, $p0, $r1, $s0, $p1, $x0, $r0, $cm0, $cm1
  ; TAILMERGE-ON-NEXT: {{  $}}
  ; TAILMERGE-ON-NEXT:   $cm2 = VADD $cm0, $cm1, $r1
  ; TAILMERGE-ON-NEXT:   $r0 = ADD_add_r_ri $r0, -4, implicit-def $srcarry
  ; TAILMERGE-ON-NEXT:   $cm0, $p0 = VLDA_UPS_S32_D8_ag_pstm_nrm $s0, $p0, $m0, implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<32 x s8>) from stack - 64)
  ; TAILMERGE-ON-NEXT:   $cm1, $p1, $dc0, $dc4 = VLDA_3D_UPS_S32_D8 $s0, $p1, $d0_3d, implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<32 x s8>) from stack - 32)
  ; TAILMERGE-ON-NEXT:   PseudoJZ $r0, %bb.3
  ; TAILMERGE-ON-NEXT: {{  $}}
  ; TAILMERGE-ON-NEXT: bb.1:
  ; TAILMERGE-ON-NEXT:   successors: %bb.2(0x80000000)
  ; TAILMERGE-ON-NEXT:   liveins: $p0, $p1, $p2, $m0, $cm0, $cm1, $cm2, $s0, $x0, $r0, $r1, $d0_3d
  ; TAILMERGE-ON-NEXT: {{  $}}
  ; TAILMERGE-ON-NEXT:   $p2 = VST_SRS_D8_S32_ag_pstm_nrm_imm $p2, 32, $cm2, $s0, implicit-def $srsrs_of, implicit $crsat, implicit $crrnd, implicit $crsrssign :: (store (<32 x s8>) into stack - 128)
  ; TAILMERGE-ON-NEXT:   PseudoJ_jump_imm %bb.2
  ; TAILMERGE-ON-NEXT: {{  $}}
  ; TAILMERGE-ON-NEXT: bb.3:
  ; TAILMERGE-ON-NEXT:   liveins: $p2, $cm0, $cm1, $cm2, $s0, $r1
  ; TAILMERGE-ON-NEXT: {{  $}}
  ; TAILMERGE-ON-NEXT:   $p2 = VST_SRS_D8_S32_ag_pstm_nrm_imm $p2, 32, $cm2, $s0, implicit-def $srsrs_of, implicit $crsat, implicit $crrnd, implicit $crsrssign :: (store (<32 x s8>) into stack - 128)
  ; TAILMERGE-ON-NEXT:   $cm2 = VADD $cm0, $cm1, $r1
  ; TAILMERGE-ON-NEXT:   $p2 = VST_SRS_D8_S32_ag_pstm_nrm_imm $p2, 32, $cm2, $s0, implicit-def $srsrs_of, implicit $crsat, implicit $crrnd, implicit $crsrssign :: (store (<32 x s8>) into stack - 128)
  ; TAILMERGE-ON-NEXT:   PseudoRET implicit $lr

  bb.0.entry:
    liveins: $p0, $p1, $p2, $m0, $s0, $x0, $r0, $r1, $d0_3d

    $r0 = ADD_add_r_ri $r0, -4, implicit-def $srcarry
    $cm0, $p0 = VLDA_UPS_S32_D8_ag_pstm_nrm $s0, $p0, $m0, implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<32 x s8>) from stack - 64)
    $cm1, $p1, $dc0, $dc4 = VLDA_3D_UPS_S32_D8 $s0, $p1, $d0_3d, implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<32 x s8>) from stack - 32)
    PseudoJ_jump_imm %bb.4

  bb.4:
    liveins: $p0, $p1, $p2, $m0, $cm0, $cm1, $s0, $x0, $r0, $r1, $d0_3d
    $cm2 = VADD $cm0, $cm1, $r1
    $r0 = ADD_add_r_ri $r0, -4, implicit-def $srcarry
    $cm0, $p0 = VLDA_UPS_S32_D8_ag_pstm_nrm $s0, $p0, $m0, implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<32 x s8>) from stack - 64)
    $cm1, $p1, $dc0, $dc4 = VLDA_3D_UPS_S32_D8 $s0, $p1, $d0_3d, implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<32 x s8>) from stack - 32)

    PseudoJNZ $r0, %bb.1
    PseudoJ_jump_imm %bb.2

  bb.1:
    liveins: $p0, $p1, $p2, $m0, $cm0, $cm1, $cm2, $s0, $x0, $r0, $r1, $d0_3d
    successors: %bb.2(0x04000000), %bb.1(0x7c000000)

    $p2 = VST_SRS_D8_S32_ag_pstm_nrm_imm $p2, 32, $cm2, $s0, implicit-def $srsrs_of, implicit $crsat, implicit $crrnd, implicit $crsrssign :: (store (<32 x s8>) into stack - 128)
    $cm2 = VADD $cm0, $cm1, $r1
    $r0 = ADD_add_r_ri $r0, -4, implicit-def $srcarry
    $cm0, $p0 = VLDA_UPS_S32_D8_ag_pstm_nrm $s0, $p0, $m0, implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<32 x s8>) from stack - 64)
    $cm1, $p1, $dc0, $dc4 = VLDA_3D_UPS_S32_D8 $s0, $p1, $d0_3d, implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<32 x s8>) from stack - 32)
    PseudoJNZ $r0, %bb.1
    PseudoJ_jump_imm %bb.2

  bb.2:
    liveins: $p2, $cm0, $cm1, $cm2, $s0, $r1
    $p2 = VST_SRS_D8_S32_ag_pstm_nrm_imm $p2, 32, $cm2, $s0, implicit-def $srsrs_of, implicit $crsat, implicit $crrnd, implicit $crsrssign :: (store (<32 x s8>) into stack - 128)
    $cm2 = VADD $cm0, $cm1, $r1

  bb.3:
    liveins: $p2, $cm2, $s0
    $p2 = VST_SRS_D8_S32_ag_pstm_nrm_imm $p2, 32, $cm2, $s0, implicit-def $srsrs_of, implicit $crsat, implicit $crrnd, implicit $crsrssign :: (store (<32 x s8>) into stack - 128)

  bb.5:
    PseudoRET implicit $lr
...
