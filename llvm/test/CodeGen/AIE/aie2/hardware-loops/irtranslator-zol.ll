; NOTE: Assertions have been autogenerated by utils/update_mir_test_checks.py
; RUN: llc -O2 -mtriple=aie2 -stop-after=irtranslator --enable-aie-hardware-loops --enable-aie-zero-overhead-loops \
; RUN:    --aie-force-hl-gen=true %s -o - | FileCheck %s


; This test feeds a normal counted loop in LLVM IR. We check that it is
; recognised as a hardware loop by the llvm shapers and then correctly
; translated to calls to the set up and loop end intrinsics in G_MIR

define void @simple(ptr nocapture %out, ptr nocapture readonly %in, i32 noundef %size) {
  ; CHECK-LABEL: name: simple
  ; CHECK: bb.1.for.body.lr.ph:
  ; CHECK-NEXT:   successors: %bb.3(0x80000000)
  ; CHECK-NEXT:   liveins: $p0, $p1, $r0
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT:   [[COPY:%[0-9]+]]:_(p0) = COPY $p0
  ; CHECK-NEXT:   [[COPY1:%[0-9]+]]:_(p0) = COPY $p1
  ; CHECK-NEXT:   [[COPY2:%[0-9]+]]:_(s32) = COPY $r0
  ; CHECK-NEXT:   [[C:%[0-9]+]]:_(s32) = G_CONSTANT i32 1
  ; CHECK-NEXT:   [[C1:%[0-9]+]]:_(s32) = G_CONSTANT i32 0
  ; CHECK-NEXT:   [[LOAD:%[0-9]+]]:_(s32) = G_LOAD [[COPY]](p0) :: (load (s32) from %ir.out)
  ; CHECK-NEXT:   G_INTRINSIC_W_SIDE_EFFECTS intrinsic(@llvm.set.loop.iterations), [[COPY2]](s32)
  ; CHECK-NEXT:   G_BR %bb.3
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT: bb.2.for.cond.cleanup:
  ; CHECK-NEXT:   PseudoRET implicit $lr
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT: bb.3.for.body:
  ; CHECK-NEXT:   successors: %bb.3(0x7c000000), %bb.2(0x04000000)
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT:   [[PHI:%[0-9]+]]:_(s32) = G_PHI [[LOAD]](s32), %bb.1, %12(s32), %bb.3
  ; CHECK-NEXT:   [[PHI1:%[0-9]+]]:_(s32) = G_PHI [[C1]](s32), %bb.1, %14(s32), %bb.3
  ; CHECK-NEXT:   [[TRUNC:%[0-9]+]]:_(s20) = G_TRUNC [[PHI1]](s32)
  ; CHECK-NEXT:   [[C2:%[0-9]+]]:_(s20) = G_CONSTANT i20 4
  ; CHECK-NEXT:   [[MUL:%[0-9]+]]:_(s20) = G_MUL [[TRUNC]], [[C2]]
  ; CHECK-NEXT:   [[PTR_ADD:%[0-9]+]]:_(p0) = G_PTR_ADD [[COPY1]], [[MUL]](s20)
  ; CHECK-NEXT:   [[COPY3:%[0-9]+]]:_(p0) = COPY [[PTR_ADD]](p0)
  ; CHECK-NEXT:   [[LOAD1:%[0-9]+]]:_(s32) = G_LOAD [[COPY3]](p0) :: (load (s32) from %ir.arrayidx)
  ; CHECK-NEXT:   [[ADD:%[0-9]+]]:_(s32) = nsw G_ADD [[PHI]], [[LOAD1]]
  ; CHECK-NEXT:   G_STORE [[ADD]](s32), [[COPY]](p0) :: (store (s32) into %ir.out)
  ; CHECK-NEXT:   [[ADD1:%[0-9]+]]:_(s32) = nuw nsw G_ADD [[PHI1]], [[C]]
  ; CHECK-NEXT:   [[INT:%[0-9]+]]:_(s1) = G_INTRINSIC_W_SIDE_EFFECTS intrinsic(@llvm.loop.decrement), [[C]](s32)
  ; CHECK-NEXT:   G_BRCOND [[INT]](s1), %bb.3
  ; CHECK-NEXT:   G_BR %bb.2
for.body.lr.ph:
  %out.promoted = load i32, ptr %out, align 4
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body
  ret void

for.body:                                         ; preds = %for.body.lr.ph, %for.body
  %add7 = phi i32 [ %out.promoted, %for.body.lr.ph ], [ %add, %for.body ]
  %i.06 = phi i32 [ 0, %for.body.lr.ph ], [ %inc, %for.body ]
  %0 = trunc i32 %i.06 to i20
  %arrayidx = getelementptr inbounds i32, ptr %in, i20 %0
  %1 = load i32, ptr %arrayidx, align 4
  %add = add nsw i32 %add7, %1
  store i32 %add, ptr %out, align 4
  %inc = add nuw nsw i32 %i.06, 1
  %exitcond.not = icmp eq i32 %inc, %size
  br i1 %exitcond.not, label %for.cond.cleanup, label %for.body
}
