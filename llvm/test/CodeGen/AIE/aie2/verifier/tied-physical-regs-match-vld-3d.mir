#
# This file is licensed under the Apache License v2.0 with LLVM Exceptions.
# See https://llvm.org/LICENSE.txt for license information.
# SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
#
# (c) Copyright 2023-2024 Advanced Micro Devices, Inc. or its affiliates
# RUN: not --crash llc -mtriple=aie2 -run-pass machineverifier -o /dev/null %s 2>&1 | FileCheck %s

# This test ensures that the Machine Verifier detects tied physical registers
# that don't match.

---
name:            tied_ok
alignment:       16
body:             |
  bb.0 (align 16):
    $wl0, $p0, $dc0, $dc4 = VLDA_3D_dmw_lda_w $p0, $d0_3d
    $amll0, $p0, $dc0, $dc4 = VLDA_3D_dmw_lda_am $p0, $d0_3d
    $bmh0, $p0, $dc0, $dc4 = VLDA_3D_UPS_S32_D16 $s0, $p0, $d0_3d, implicit-def $srups_of, implicit $crsat, implicit $crupssign
    $bml2, $p2, $dc1, $dc5 = VLDA_3D_UPS_S32_S16 $s1, $p2, $d1_3d, implicit-def $srups_of, implicit $crsat
    $bmh5, $p3, $dc2, $dc6 = VLDA_3D_UPS_S64_D32 $s2, $p3, $d2_3d, implicit-def $srups_of, implicit $crsat, implicit $crupssign
    $bml7, $p5, $dc3, $dc7 = VLDA_3D_UPS_S64_S32 $s3, $p5, $d3_3d, implicit-def $srups_of, implicit $crsat
    $cm0, $p0, $dc0, $dc4 = VLDA_3D_UPS_S32_D8  $s0, $p0, $d0_3d, implicit-def $srups_of, implicit $crsat, implicit $crupssign
    $cm2, $p2, $dc1, $dc5 = VLDA_3D_UPS_S32_S8  $s1, $p2, $d1_3d, implicit-def $srups_of, implicit $crsat
    $cm5, $p3, $dc2, $dc6 = VLDA_3D_UPS_S64_S16 $s2, $p3, $d2_3d, implicit-def $srups_of, implicit $crsat
    $cm7, $p5, $dc3, $dc7 = VLDA_3D_UPS_S64_D16 $s3, $p5, $d3_3d, implicit-def $srups_of, implicit $crsat, implicit $crupssign
    $wl0, $p0, $dc0, $dc4 = VLDB_3D $p0, $d0_3d
    $bml0, $p0, $dc0, $dc4 = VLDA_3D_CONV_FP32_BF16 $p0, $d0_3d
    $x0, $p0, $dc0, $dc4 = VLDB_3D_UNPACK_S8_S4 $p0, $d0_3d
    $x2, $p2, $dc3, $dc7 = VLDB_3D_UNPACK_S16_S8 $p2, $d3_3d
    $x5, $p3, $dc2, $dc6 = VLDB_3D_UNPACK_D8_D4 $p3, $d2_3d, implicit $crunpacksign
    $x7, $p5, $dc1, $dc5 = VLDB_3D_UNPACK_D16_D8 $p5, $d1_3d, implicit $crunpacksign
...

# Virtual registers are not required to be tied.
---
name:            virtual_ok
alignment:       16
body:             |
  bb.0 (align 16):
    %0:ep = COPY $p0
    %10:eds = COPY $d0_3d
    $wl0, %20:ep, %21:edc, %22:edc = VLDA_3D_dmw_lda_w %0, %10
    $amll0, %30:ep, %31:edc, %32:edc = VLDA_3D_dmw_lda_am %0, %10
    $bmh0, %40:ep, %41:edc, %42:edc = VLDA_3D_UPS_S32_D16 $s0, %0, %10, implicit-def $srups_of, implicit $crsat, implicit $crupssign
    $bml2, %50:ep, %51:edc, %52:edc = VLDA_3D_UPS_S32_S16 $s1, %0, %10, implicit-def $srups_of, implicit $crsat
    $bmh5, %60:ep, %61:edc, %62:edc = VLDA_3D_UPS_S64_D32 $s2, %0, %10, implicit-def $srups_of, implicit $crsat, implicit $crupssign
    $bml7, %70:ep, %71:edc, %72:edc = VLDA_3D_UPS_S64_S32 $s3, %0, %10, implicit-def $srups_of, implicit $crsat
    $cm0, %80:ep, %81:edc, %82:edc = VLDA_3D_UPS_S32_D8  $s0, %0, %10, implicit-def $srups_of, implicit $crsat, implicit $crupssign
    $cm2, %90:ep, %91:edc, %92:edc = VLDA_3D_UPS_S32_S8  $s1, %0, %10, implicit-def $srups_of, implicit $crsat
    $cm5, %100:ep, %101:edc, %102:edc = VLDA_3D_UPS_S64_S16 $s2, %0, %10, implicit-def $srups_of, implicit $crsat
    $cm7, %110:ep, %111:edc, %112:edc = VLDA_3D_UPS_S64_D16 $s3, %0, %10, implicit-def $srups_of, implicit $crsat, implicit $crupssign
    $wl0, %120:ep, %121:edc, %122:edc = VLDB_3D %0, %10
    $bml0, %130:ep, %131:edc, %132:edc = VLDA_3D_CONV_FP32_BF16 %0, %10
    $x0, %140:ep, %141:edc, %142:edc = VLDB_3D_UNPACK_S8_S4 %0, %10
    $x2, %150:ep, %151:edc, %152:edc = VLDB_3D_UNPACK_S16_S8 %0, %10
    $x5, %160:ep, %161:edc, %162:edc = VLDB_3D_UNPACK_D8_D4 %0, %10, implicit $crunpacksign
    $x7, %170:ep, %171:edc, %172:edc = VLDB_3D_UNPACK_D16_D8 %0, %10, implicit $crunpacksign
...

---
name:            tied_nok
alignment:       16
body:             |
  bb.0 (align 16):
    ; CHECK-NOT: Bad machine code
    ; CHECK-COUNT-16: Bad machine code: Tied physical registers must match
    $wl0, $p0, $dc1, $dc3 = VLDA_3D_dmw_lda_w $p0, $d1_3d
    $wl0, $p0, $dc1, $dc3 = VLDA_3D_dmw_lda_am $p0, $d1_3d
    $bmh0, $p0, $dc0, $dc2 = VLDA_3D_UPS_S32_D16 $s0, $p0, $d3_3d, implicit-def $srups_of, implicit $crsat, implicit $crupssign
    $bml2, $p2, $dc1, $dc3 = VLDA_3D_UPS_S32_S16 $s1, $p2, $d2_3d, implicit-def $srups_of, implicit $crsat
    $bmh5, $p3, $dc2, $dc4 = VLDA_3D_UPS_S64_D32 $s2, $p3, $d1_3d, implicit-def $srups_of, implicit $crsat, implicit $crupssign
    $bml7, $p5, $dc3, $dc5 = VLDA_3D_UPS_S64_S32 $s3, $p5, $d0_3d, implicit-def $srups_of, implicit $crsat
    $cm0, $p0, $dc0, $dc2 = VLDA_3D_UPS_S32_D8  $s0, $p0, $d3_3d, implicit-def $srups_of, implicit $crsat, implicit $crupssign
    $cm2, $p2, $dc1, $dc3 = VLDA_3D_UPS_S32_S8  $s1, $p2, $d2_3d, implicit-def $srups_of, implicit $crsat
    $cm5, $p3, $dc2, $dc4 = VLDA_3D_UPS_S64_S16 $s2, $p3, $d1_3d, implicit-def $srups_of, implicit $crsat
    $cm7, $p5, $dc3, $dc5 = VLDA_3D_UPS_S64_D16 $s3, $p5, $d0_3d, implicit-def $srups_of, implicit $crsat, implicit $crupssign
    $wl0, $p0, $dc2, $dc5 = VLDB_3D $p0, $d1_3d
    $bml0, $p0, $dc1, $dc3 = VLDA_3D_CONV_FP32_BF16 $p0, $d1_3d
    $x0, $p0, $dc0, $dc2 = VLDB_3D_UNPACK_S8_S4 $p0, $d0_3d
    $x2, $p2, $dc4, $dc5 = VLDB_3D_UNPACK_S16_S8 $p2, $d3_3d
    $x5, $p3, $dc2, $dc4 = VLDB_3D_UNPACK_D8_D4 $p3, $d2_3d, implicit $crunpacksign
    $x7, $p5, $dc0, $dc5 = VLDB_3D_UNPACK_D16_D8 $p5, $d1_3d, implicit $crunpacksign

    ; Below instructions have hasExtraSrcRegAllocReq and hasExtraDefRegAllocReq attributes
    ; which essentially bypass the register flags. The renamable attributes
    ; below should trigger no verification error.
    ; CHECK-NOT: Bad machine code
    $wh1, $p1, renamable $dc2, renamable $dc6 = VLDA_3D_dmw_lda_w $p1, renamable $d2_3d
    $amll1, $p1, renamable $dc2, renamable $dc6 = VLDA_3D_dmw_lda_am $p1, renamable $d2_3d
    $bmh0, $p0, renamable $dc0, renamable $dc4 = VLDA_3D_UPS_S32_D16 $s0, $p0, renamable $d0_3d, implicit-def $srups_of, implicit $crsat, implicit $crupssign
    $bml2, $p2, renamable $dc1, renamable $dc5 = VLDA_3D_UPS_S32_S16 $s1, $p2, renamable $d1_3d, implicit-def $srups_of, implicit $crsat
    $bmh5, $p3, renamable $dc2, renamable $dc6 = VLDA_3D_UPS_S64_D32 $s2, $p3, renamable $d2_3d, implicit-def $srups_of, implicit $crsat, implicit $crupssign
    $bml7, $p5, renamable $dc3, renamable $dc7 = VLDA_3D_UPS_S64_S32 $s3, $p5, renamable $d3_3d, implicit-def $srups_of, implicit $crsat
    $cm0, $p0, renamable $dc0, renamable $dc4 = VLDA_3D_UPS_S32_D8  $s0, $p0, renamable $d0_3d, implicit-def $srups_of, implicit $crsat, implicit $crupssign
    $cm2, $p2, renamable $dc1, renamable $dc5 = VLDA_3D_UPS_S32_S8  $s1, $p2, renamable $d1_3d, implicit-def $srups_of, implicit $crsat
    $cm5, $p3, renamable $dc2, renamable $dc6 = VLDA_3D_UPS_S64_S16 $s2, $p3, renamable $d2_3d, implicit-def $srups_of, implicit $crsat
    $cm7, $p5, renamable $dc3, renamable $dc7 = VLDA_3D_UPS_S64_D16 $s3, $p5, renamable $d3_3d, implicit-def $srups_of, implicit $crsat, implicit $crupssign
    $wl0, $p1, renamable $dc3, renamable $dc7 = VLDB_3D $p1, $d3_3d
    $bml1, $p1, renamable $dc2, renamable $dc6 = VLDA_3D_CONV_FP32_BF16 $p1, renamable $d2_3d
    $x0, $p0, renamable $dc0, renamable $dc4 = VLDB_3D_UNPACK_S8_S4 $p0, renamable $d0_3d
    $x2, $p2, renamable $dc3, renamable $dc7 = VLDB_3D_UNPACK_S16_S8 $p2, renamable $d3_3d
    $x5, $p3, renamable $dc2, renamable $dc6 = VLDB_3D_UNPACK_D8_D4 $p3, renamable $d2_3d, implicit $crunpacksign
    $x7, $p5, renamable $dc1, renamable $dc5 = VLDB_3D_UNPACK_D16_D8 $p5, renamable $d1_3d, implicit $crunpacksign
...
