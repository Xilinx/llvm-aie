# NOTE: Assertions have been autogenerated by utils/update_mir_test_checks.py
#
# This file is licensed under the Apache License v2.0 with LLVM Exceptions.
# See https://llvm.org/LICENSE.txt for license information.
# SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
#
# (c) Copyright 2024 Advanced Micro Devices, Inc. or its affiliates
# RUN: llc -march=aie2 -run-pass=machine-scheduler %s -o - | FileCheck %s

# This represents the innermost loop of Conv2D after SW pipelining.
# An important point to track is the position of the VMAC instructions. As they
# increase the pressure on our vector reg units, it is better to keep them at
# the top of the BB to give time to VLD instructions to be scheduled and help
# decrease the pressure. After RA, the final scheduler can then interleave
# instructions back again, making use of exact operand latencies.
---
name: conv2d_innermost
tracksRegLiveness: true
body: |
  ; CHECK-LABEL: name: conv2d_innermost
  ; CHECK: bb.0.entry:
  ; CHECK-NEXT:   successors: %bb.1(0x80000000)
  ; CHECK-NEXT:   liveins: $p0, $m0, $cm0, $cm1, $s0, $d1, $x0, $r0, $d0_3d
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT:   [[COPY:%[0-9]+]]:em = COPY $m0
  ; CHECK-NEXT:   [[COPY1:%[0-9]+]]:acc1024 = COPY $cm0
  ; CHECK-NEXT:   [[COPY2:%[0-9]+]]:acc1024 = COPY $cm0
  ; CHECK-NEXT:   [[COPY3:%[0-9]+]]:acc1024 = COPY $cm0
  ; CHECK-NEXT:   [[COPY4:%[0-9]+]]:acc1024 = COPY $cm0
  ; CHECK-NEXT:   [[COPY5:%[0-9]+]]:acc1024 = COPY $cm0
  ; CHECK-NEXT:   [[COPY6:%[0-9]+]]:acc1024 = COPY $cm0
  ; CHECK-NEXT:   [[COPY7:%[0-9]+]]:acc1024 = COPY $cm0
  ; CHECK-NEXT:   [[COPY8:%[0-9]+]]:acc1024 = COPY $cm0
  ; CHECK-NEXT:   [[COPY9:%[0-9]+]]:vec512 = COPY $x0
  ; CHECK-NEXT:   dead [[COPY10:%[0-9]+]]:vec512 = COPY $x0
  ; CHECK-NEXT:   [[COPY11:%[0-9]+]]:vec512 = COPY $x0
  ; CHECK-NEXT:   dead [[COPY12:%[0-9]+]]:vec512 = COPY $x0
  ; CHECK-NEXT:   [[COPY13:%[0-9]+]]:vec512 = COPY $x0
  ; CHECK-NEXT:   [[COPY14:%[0-9]+]]:vec512 = COPY $x0
  ; CHECK-NEXT:   [[COPY15:%[0-9]+]]:vec512 = COPY $x0
  ; CHECK-NEXT:   [[COPY16:%[0-9]+]]:vec512 = COPY $x0
  ; CHECK-NEXT:   [[COPY17:%[0-9]+]]:vec512 = COPY $x0
  ; CHECK-NEXT:   [[COPY18:%[0-9]+]]:vec512 = COPY $x0
  ; CHECK-NEXT:   [[COPY19:%[0-9]+]]:er = COPY $r0
  ; CHECK-NEXT:   [[COPY20:%[0-9]+]]:er = COPY $r0
  ; CHECK-NEXT:   [[COPY21:%[0-9]+]]:er = COPY $r0
  ; CHECK-NEXT:   [[COPY22:%[0-9]+]]:er = COPY $r0
  ; CHECK-NEXT:   [[COPY23:%[0-9]+]]:er = COPY $r0
  ; CHECK-NEXT:   [[COPY24:%[0-9]+]]:er = COPY $r0
  ; CHECK-NEXT:   [[COPY25:%[0-9]+]]:ep_as_32bit = COPY $p0
  ; CHECK-NEXT:   [[COPY26:%[0-9]+]]:ep_as_32bit = COPY $p0
  ; CHECK-NEXT:   [[COPY27:%[0-9]+]]:eds = COPY $d0_3d
  ; CHECK-NEXT:   [[COPY28:%[0-9]+]]:vec512 = COPY $x0
  ; CHECK-NEXT:   [[COPY29:%[0-9]+]]:vec512 = COPY $x0
  ; CHECK-NEXT:   [[COPY30:%[0-9]+]]:vec512 = COPY $x0
  ; CHECK-NEXT:   [[COPY31:%[0-9]+]]:mss = COPY $s0
  ; CHECK-NEXT:   PseudoJ_jump_imm %bb.1
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT: bb.1:
  ; CHECK-NEXT:   successors: %bb.2(0x04000000), %bb.1(0x7c000000)
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT:   [[COPY32:%[0-9]+]]:vec512 = COPY [[COPY13]]
  ; CHECK-NEXT:   [[COPY33:%[0-9]+]]:vec512 = COPY [[COPY11]]
  ; CHECK-NEXT:   [[COPY1:%[0-9]+]]:acc1024 = VMAC_vmac_cm_core_dense [[COPY1]], [[COPY16]], [[COPY33]], [[COPY22]]
  ; CHECK-NEXT:   [[COPY7:%[0-9]+]]:acc1024 = VMAC_vmac_cm_core_dense [[COPY7]], [[COPY16]], [[COPY32]], [[COPY22]]
  ; CHECK-NEXT:   [[VSHUFFLE:%[0-9]+]]:vec512 = VSHUFFLE [[COPY14]], [[COPY15]], [[COPY21]]
  ; CHECK-NEXT:   [[VSHUFFLE1:%[0-9]+]]:vec512 = VSHUFFLE [[VSHUFFLE]], [[COPY9]], [[COPY21]]
  ; CHECK-NEXT:   [[COPY3:%[0-9]+]]:acc1024 = VMAC_vmac_cm_core_dense [[COPY3]], [[COPY17]], [[COPY32]], [[COPY22]]
  ; CHECK-NEXT:   [[COPY5:%[0-9]+]]:acc1024 = VMAC_vmac_cm_core_dense [[COPY5]], [[VSHUFFLE1]], [[COPY32]], [[COPY22]]
  ; CHECK-NEXT:   [[COPY8:%[0-9]+]]:acc1024 = VMAC_vmac_cm_core_dense [[COPY8]], [[VSHUFFLE]], [[COPY32]], [[COPY22]]
  ; CHECK-NEXT:   [[COPY13:%[0-9]+]]:vec512 = COPY [[COPY30]]
  ; CHECK-NEXT:   [[COPY2:%[0-9]+]]:acc1024 = VMAC_vmac_cm_core_dense [[COPY2]], [[COPY17]], [[COPY33]], [[COPY22]]
  ; CHECK-NEXT:   [[COPY4:%[0-9]+]]:acc1024 = VMAC_vmac_cm_core_dense [[COPY4]], [[VSHUFFLE1]], [[COPY33]], [[COPY22]]
  ; CHECK-NEXT:   [[COPY6:%[0-9]+]]:acc1024 = VMAC_vmac_cm_core_dense [[COPY6]], [[VSHUFFLE]], [[COPY33]], [[COPY22]]
  ; CHECK-NEXT:   [[COPY11:%[0-9]+]]:vec512 = COPY [[COPY29]]
  ; CHECK-NEXT:   [[COPY34:%[0-9]+]]:er = COPY [[COPY19]]
  ; CHECK-NEXT:   undef [[COPY29:%[0-9]+]].sub_256_lo:vec512, [[COPY25:%[0-9]+]]:ep_as_32bit = VLDA_dmw_lda_w_ag_pstm_nrm_imm [[COPY25]], 32
  ; CHECK-NEXT:   [[COPY29:%[0-9]+]].sub_256_hi:vec512, [[COPY25:%[0-9]+]]:ep_as_32bit = VLDA_dmw_lda_w_ag_pstm_nrm_imm [[COPY25]], 32
  ; CHECK-NEXT:   undef [[COPY30:%[0-9]+]].sub_256_lo:vec512, [[COPY25:%[0-9]+]]:ep_as_32bit = VLDA_dmw_lda_w_ag_pstm_nrm_imm [[COPY25]], 32
  ; CHECK-NEXT:   [[COPY14:%[0-9]+]]:vec512 = VSHIFT_ALIGN [[COPY14]], [[COPY31]], [[COPY18]], [[COPY34]]
  ; CHECK-NEXT:   undef [[COPY18:%[0-9]+]].sub_256_lo:vec512, [[COPY26:%[0-9]+]]:ep_as_32bit = VLDA_dmw_lda_w_ag_pstm_nrm [[COPY26]], [[COPY]]
  ; CHECK-NEXT:   [[COPY18:%[0-9]+]].sub_256_hi:vec512, [[COPY26:%[0-9]+]]:ep_as_32bit = VLDA_dmw_lda_w_ag_pstm_nrm [[COPY26]], [[COPY]]
  ; CHECK-NEXT:   [[COPY15:%[0-9]+]]:vec512 = VSHIFT_ALIGN [[COPY15]], [[COPY31]], [[COPY28]], [[COPY34]]
  ; CHECK-NEXT:   undef [[COPY28:%[0-9]+]].sub_256_lo:vec512, [[COPY26:%[0-9]+]]:ep_as_32bit = VLDA_dmw_lda_w_ag_pstm_nrm [[COPY26]], [[COPY]]
  ; CHECK-NEXT:   [[COPY28:%[0-9]+]].sub_256_hi:vec512, [[COPY26:%[0-9]+]]:ep_as_32bit, [[COPY27:%[0-9]+]].sub_dim_count:eds, [[COPY27:%[0-9]+]].sub_hi_dim_then_sub_dim_count:eds = VLDA_3D_dmw_lda_w [[COPY26]], [[COPY27]]
  ; CHECK-NEXT:   [[COPY30:%[0-9]+]].sub_256_hi:vec512, [[COPY25:%[0-9]+]]:ep_as_32bit = VLDA_dmw_lda_w_ag_pstm_nrm_imm [[COPY25]], 32
  ; CHECK-NEXT:   [[COPY35:%[0-9]+]]:er = COPY [[COPY26]]
  ; CHECK-NEXT:   [[COPY19:%[0-9]+]]:er = nuw nsw ADD_add_r_ri [[COPY24]], 33, implicit-def dead $srcarry
  ; CHECK-NEXT:   [[COPY16:%[0-9]+]]:vec512 = VSHUFFLE [[COPY14]], [[COPY15]], [[COPY21]]
  ; CHECK-NEXT:   [[COPY23:%[0-9]+]]:er = ADD_add_r_ri [[COPY23]], -1, implicit-def dead $srcarry
  ; CHECK-NEXT:   [[COPY17:%[0-9]+]]:vec512 = VSHUFFLE [[COPY16]], [[COPY9]], [[COPY21]]
  ; CHECK-NEXT:   [[COPY24:%[0-9]+]]:er = AND [[COPY35]], [[COPY20]]
  ; CHECK-NEXT:   PseudoJNZ [[COPY23]], %bb.1
  ; CHECK-NEXT:   PseudoJ_jump_imm %bb.2
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT: bb.2:
  ; CHECK-NEXT:   PseudoRET implicit $lr
  bb.0.entry:
    liveins: $p0, $m0, $cm0, $cm1, $s0, $d1, $x0, $r0, $d0_3d

    %0:vec512 = COPY $x0
    %1:mss = COPY $s0
    %2:vec512 = COPY $x0
    %3:vec512 = COPY $x0
    %4:vec512 = COPY $x0
    %5:vec512 = COPY $x0
    %6:vec512 = COPY $x0
    %7:vec512 = COPY $x0
    %8:vec512 = COPY $x0
    %9:vec512 = COPY $x0
    %10:er = COPY $r0
    %11:er = COPY $r0
    %12:vec512 = COPY $x0
    %13:vec512 = COPY $x0
    %14:vec512 = COPY $x0
    %15:vec512 = COPY $x0
    %16:er = COPY $r0
    %17:er = COPY $r0
    %18:em = COPY $m0
    %19:er = COPY $r0
    %20:er = COPY $r0
    %21:ep_as_32bit = COPY $p0
    %22:ep_as_32bit = COPY $p0
    %23:eds = COPY $d0_3d
    %24:acc1024 = COPY $cm0
    %25:acc1024 = COPY $cm0
    %26:acc1024 = COPY $cm0
    %27:acc1024 = COPY $cm0
    %28:acc1024 = COPY $cm0
    %29:acc1024 = COPY $cm0
    %30:acc1024 = COPY $cm0
    %31:acc1024 = COPY $cm0
    PseudoJ_jump_imm %bb.1

  bb.1:
    successors: %bb.2(0x04000000), %bb.1(0x7c000000)

    %32:vec512 = COPY %5
    %5:vec512 = COPY %15
    %33:vec512 = COPY %3
    %3:vec512 = COPY %14
    %34:er = COPY %10
    %35:vec512 = VSHUFFLE %6, %7, %16
    %24:acc1024 = VMAC_vmac_cm_core_dense %24, %8, %33, %17
    %10:er = nuw nsw ADD_add_r_ri %20, 33, implicit-def dead $srcarry
    undef %14.sub_256_lo:vec512, %21:ep_as_32bit = VLDA_dmw_lda_w_ag_pstm_nrm_imm %21, 32
    %25:acc1024 = VMAC_vmac_cm_core_dense %25, %9, %33, %17
    %36:vec512 = VSHUFFLE %35, %0, %16
    %14.sub_256_hi:vec512, %21:ep_as_32bit = VLDA_dmw_lda_w_ag_pstm_nrm_imm %21, 32
    %19:er = ADD_add_r_ri %19, -1, implicit-def dead $srcarry
    %26:acc1024 = VMAC_vmac_cm_core_dense %26, %9, %32, %17
    undef %15.sub_256_lo:vec512, %21:ep_as_32bit = VLDA_dmw_lda_w_ag_pstm_nrm_imm %21, 32
    %27:acc1024 = VMAC_vmac_cm_core_dense %27, %36, %33, %17
    %6:vec512 = VSHIFT_ALIGN %6, %1, %12, %34
    undef %12.sub_256_lo:vec512, %22:ep_as_32bit = VLDA_dmw_lda_w_ag_pstm_nrm %22, %18
    %28:acc1024 = VMAC_vmac_cm_core_dense %28, %36, %32, %17
    %12.sub_256_hi:vec512, %22:ep_as_32bit = VLDA_dmw_lda_w_ag_pstm_nrm %22, %18
    %29:acc1024 = VMAC_vmac_cm_core_dense %29, %35, %33, %17
    %7:vec512 = VSHIFT_ALIGN %7, %1, %13, %34
    undef %13.sub_256_lo:vec512, %22:ep_as_32bit = VLDA_dmw_lda_w_ag_pstm_nrm %22, %18
    %30:acc1024 = VMAC_vmac_cm_core_dense %30, %8, %32, %17
    %8:vec512 = VSHUFFLE %6, %7, %16
    %13.sub_256_hi:vec512, %22:ep_as_32bit, %23.sub_dim_count:eds, %23.sub_hi_dim_then_sub_dim_count:eds = VLDA_3D_dmw_lda_w %22, %23
    %37:er = COPY %22
    %31:acc1024 = VMAC_vmac_cm_core_dense %31, %35, %32, %17
    %9:vec512 = VSHUFFLE %8, %0, %16
    %15.sub_256_hi:vec512, %21:ep_as_32bit = VLDA_dmw_lda_w_ag_pstm_nrm_imm %21, 32
    %20:er = AND %37, %11
    PseudoJNZ %19, %bb.1
    PseudoJ_jump_imm %bb.2

  bb.2:
    PseudoRET implicit $lr
...
