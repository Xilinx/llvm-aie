; NOTE: Assertions have been autogenerated by utils/update_mir_test_checks.py
;
; This file is licensed under the Apache License v2.0 with LLVM Exceptions.
; See https://llvm.org/LICENSE.txt for license information.
; SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
;
; (c) Copyright 2024 Advanced Micro Devices, Inc. or its affiliates

; RUN: llc -mtriple=aie2 -O0 -stop-after=irtranslator -global-isel -verify-machineinstrs %s -o - 2>&1 | FileCheck %s

%struct.v128int8_sparse = type <{ <64 x i8>, i128 }>
%struct.v128uint8_sparse = type <{ <64 x i8>, i128 }>
%struct.v64int16_sparse = type <{ <32 x i16>, i128 }>
%struct.v64uint16_sparse = type <{ <32 x i16>, i128 }>
%struct.v256int4_sparse = type <{ <64 x i8>, i128 }>
%struct.v256uint4_sparse = type <{ <64 x i8>, i128 }>
%struct.v64bfloat16_sparse = type <{ <32 x bfloat>, i128 }>

declare void @callee_sparse(%struct.v128int8_sparse alignstack(32) %a, %struct.v64int16_sparse alignstack(32) %b, %struct.v64bfloat16_sparse alignstack(32) %c, %struct.v256uint4_sparse alignstack(32) %d, %struct.v256int4_sparse alignstack(32) %e)
define void @call_sparse() {
  ; CHECK-LABEL: name: call_sparse
  ; CHECK: bb.1 (%ir-block.0):
  ; CHECK-NEXT:   [[C:%[0-9]+]]:_(s8) = G_CONSTANT i8 0
  ; CHECK-NEXT:   [[BUILD_VECTOR:%[0-9]+]]:_(<64 x s8>) = G_BUILD_VECTOR [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8)
  ; CHECK-NEXT:   [[C1:%[0-9]+]]:_(s128) = G_CONSTANT i128 0
  ; CHECK-NEXT:   [[C2:%[0-9]+]]:_(s16) = G_CONSTANT i16 0
  ; CHECK-NEXT:   [[BUILD_VECTOR1:%[0-9]+]]:_(<32 x s16>) = G_BUILD_VECTOR [[C2]](s16), [[C2]](s16), [[C2]](s16), [[C2]](s16), [[C2]](s16), [[C2]](s16), [[C2]](s16), [[C2]](s16), [[C2]](s16), [[C2]](s16), [[C2]](s16), [[C2]](s16), [[C2]](s16), [[C2]](s16), [[C2]](s16), [[C2]](s16), [[C2]](s16), [[C2]](s16), [[C2]](s16), [[C2]](s16), [[C2]](s16), [[C2]](s16), [[C2]](s16), [[C2]](s16), [[C2]](s16), [[C2]](s16), [[C2]](s16), [[C2]](s16), [[C2]](s16), [[C2]](s16), [[C2]](s16), [[C2]](s16)
  ; CHECK-NEXT:   [[C3:%[0-9]+]]:_(s16) = G_FCONSTANT bfloat 0xR0000
  ; CHECK-NEXT:   [[BUILD_VECTOR2:%[0-9]+]]:_(<32 x s16>) = G_BUILD_VECTOR [[C3]](s16), [[C3]](s16), [[C3]](s16), [[C3]](s16), [[C3]](s16), [[C3]](s16), [[C3]](s16), [[C3]](s16), [[C3]](s16), [[C3]](s16), [[C3]](s16), [[C3]](s16), [[C3]](s16), [[C3]](s16), [[C3]](s16), [[C3]](s16), [[C3]](s16), [[C3]](s16), [[C3]](s16), [[C3]](s16), [[C3]](s16), [[C3]](s16), [[C3]](s16), [[C3]](s16), [[C3]](s16), [[C3]](s16), [[C3]](s16), [[C3]](s16), [[C3]](s16), [[C3]](s16), [[C3]](s16), [[C3]](s16)
  ; CHECK-NEXT:   ADJCALLSTACKUP 80, 0, implicit-def $sp, implicit $sp
  ; CHECK-NEXT:   [[COPY:%[0-9]+]]:_(p0) = COPY $sp
  ; CHECK-NEXT:   [[C4:%[0-9]+]]:_(s32) = G_CONSTANT i32 -64
  ; CHECK-NEXT:   [[PTR_ADD:%[0-9]+]]:_(p0) = G_PTR_ADD [[COPY]], [[C4]](s32)
  ; CHECK-NEXT:   G_STORE [[BUILD_VECTOR]](<64 x s8>), [[PTR_ADD]](p0) :: (store (<64 x s8>) into stack - 64, align 32)
  ; CHECK-NEXT:   [[C5:%[0-9]+]]:_(s32) = G_CONSTANT i32 -96
  ; CHECK-NEXT:   [[PTR_ADD1:%[0-9]+]]:_(p0) = G_PTR_ADD [[COPY]], [[C5]](s32)
  ; CHECK-NEXT:   G_STORE [[C1]](s128), [[PTR_ADD1]](p0) :: (store (s128) into stack - 96, align 32)
  ; CHECK-NEXT:   $x0 = COPY [[BUILD_VECTOR]](<64 x s8>)
  ; CHECK-NEXT:   $q0 = COPY [[C1]](s128)
  ; CHECK-NEXT:   $x2 = COPY [[BUILD_VECTOR1]](<32 x s16>)
  ; CHECK-NEXT:   $q2 = COPY [[C1]](s128)
  ; CHECK-NEXT:   $x1 = COPY [[BUILD_VECTOR2]](<32 x s16>)
  ; CHECK-NEXT:   $q1 = COPY [[C1]](s128)
  ; CHECK-NEXT:   $x3 = COPY [[BUILD_VECTOR]](<64 x s8>)
  ; CHECK-NEXT:   $q3 = COPY [[C1]](s128)
  ; CHECK-NEXT:   PseudoJL @callee_sparse, csr_aie2, implicit-def $lr, implicit $x0, implicit $q0, implicit $x2, implicit $q2, implicit $x1, implicit $q1, implicit $x3, implicit $q3
  ; CHECK-NEXT:   ADJCALLSTACKDOWN 80, 0, implicit-def $sp, implicit $sp
  ; CHECK-NEXT:   PseudoRET implicit $lr
  call void @callee_sparse(%struct.v128int8_sparse alignstack(32) zeroinitializer, %struct.v64int16_sparse alignstack(32) zeroinitializer, %struct.v64bfloat16_sparse alignstack(32) zeroinitializer, %struct.v256uint4_sparse alignstack(32) zeroinitializer, %struct.v256int4_sparse alignstack(32) zeroinitializer)
  ret void
}
