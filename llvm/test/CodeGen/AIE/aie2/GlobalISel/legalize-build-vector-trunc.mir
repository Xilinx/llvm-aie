# NOTE: Assertions have been autogenerated by utils/update_mir_test_checks.py
#
# This file is licensed under the Apache License v2.0 with LLVM Exceptions.
# See https://llvm.org/LICENSE.txt for license information.
# SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
#
# (c) Copyright 2024 Advanced Micro Devices, Inc. or its affiliates
# RUN: llc -mtriple aie2 -run-pass=legalizer %s -verify-machineinstrs -o - | FileCheck %s

---
name: test_build_vector_trunc_8bit_128
stack:
  - {id: 0, name: "", type: default, offset: 0, size: 128, alignment: 32}
body:           |
  bb.1.entry:
    ; CHECK-LABEL: name: test_build_vector_trunc_8bit_128
    ; CHECK: [[C:%[0-9]+]]:_(s32) = G_CONSTANT i32 42
    ; CHECK-NEXT: [[C1:%[0-9]+]]:_(s32) = G_CONSTANT i32 19
    ; CHECK-NEXT: [[C2:%[0-9]+]]:_(s32) = G_CONSTANT i32 32
    ; CHECK-NEXT: [[C3:%[0-9]+]]:_(s32) = G_CONSTANT i32 12
    ; CHECK-NEXT: [[DEF:%[0-9]+]]:_(<64 x s8>) = G_IMPLICIT_DEF
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI:%[0-9]+]]:_(<64 x s8>) = G_AIE_ADD_VECTOR_ELT_HI [[DEF]], [[C]](s32)
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI1:%[0-9]+]]:_(<64 x s8>) = G_AIE_ADD_VECTOR_ELT_HI [[AIE_ADD_VECTOR_ELT_HI]], [[C1]](s32)
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI2:%[0-9]+]]:_(<64 x s8>) = G_AIE_ADD_VECTOR_ELT_HI [[AIE_ADD_VECTOR_ELT_HI1]], [[C2]](s32)
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI3:%[0-9]+]]:_(<64 x s8>) = G_AIE_ADD_VECTOR_ELT_HI [[AIE_ADD_VECTOR_ELT_HI2]], [[C3]](s32)
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI4:%[0-9]+]]:_(<64 x s8>) = G_AIE_ADD_VECTOR_ELT_HI [[AIE_ADD_VECTOR_ELT_HI3]], [[C]](s32)
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI5:%[0-9]+]]:_(<64 x s8>) = G_AIE_ADD_VECTOR_ELT_HI [[AIE_ADD_VECTOR_ELT_HI4]], [[C1]](s32)
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI6:%[0-9]+]]:_(<64 x s8>) = G_AIE_ADD_VECTOR_ELT_HI [[AIE_ADD_VECTOR_ELT_HI5]], [[C2]](s32)
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI7:%[0-9]+]]:_(<64 x s8>) = G_AIE_ADD_VECTOR_ELT_HI [[AIE_ADD_VECTOR_ELT_HI6]], [[C3]](s32)
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI8:%[0-9]+]]:_(<64 x s8>) = G_AIE_ADD_VECTOR_ELT_HI [[AIE_ADD_VECTOR_ELT_HI7]], [[C]](s32)
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI9:%[0-9]+]]:_(<64 x s8>) = G_AIE_ADD_VECTOR_ELT_HI [[AIE_ADD_VECTOR_ELT_HI8]], [[C1]](s32)
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI10:%[0-9]+]]:_(<64 x s8>) = G_AIE_ADD_VECTOR_ELT_HI [[AIE_ADD_VECTOR_ELT_HI9]], [[C2]](s32)
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI11:%[0-9]+]]:_(<64 x s8>) = G_AIE_ADD_VECTOR_ELT_HI [[AIE_ADD_VECTOR_ELT_HI10]], [[C3]](s32)
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI12:%[0-9]+]]:_(<64 x s8>) = G_AIE_ADD_VECTOR_ELT_HI [[AIE_ADD_VECTOR_ELT_HI11]], [[C]](s32)
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI13:%[0-9]+]]:_(<64 x s8>) = G_AIE_ADD_VECTOR_ELT_HI [[AIE_ADD_VECTOR_ELT_HI12]], [[C1]](s32)
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI14:%[0-9]+]]:_(<64 x s8>) = G_AIE_ADD_VECTOR_ELT_HI [[AIE_ADD_VECTOR_ELT_HI13]], [[C2]](s32)
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI15:%[0-9]+]]:_(<64 x s8>) = G_AIE_ADD_VECTOR_ELT_HI [[AIE_ADD_VECTOR_ELT_HI14]], [[C3]](s32)
    ; CHECK-NEXT: [[C4:%[0-9]+]]:_(s32) = G_CONSTANT i32 0
    ; CHECK-NEXT: [[C5:%[0-9]+]]:_(s32) = G_CONSTANT i32 48
    ; CHECK-NEXT: [[BITCAST:%[0-9]+]]:_(<16 x s32>) = G_BITCAST [[AIE_ADD_VECTOR_ELT_HI15]](<64 x s8>)
    ; CHECK-NEXT: [[INT:%[0-9]+]]:_(<16 x s32>) = G_INTRINSIC intrinsic(@llvm.aie2.vshift.I512.I512), [[BITCAST]](<16 x s32>), [[BITCAST]](<16 x s32>), [[C4]](s32), [[C5]](s32)
    ; CHECK-NEXT: [[BITCAST1:%[0-9]+]]:_(<64 x s8>) = G_BITCAST [[INT]](<16 x s32>)
    ; CHECK-NEXT: [[AIE_UNPAD_VECTOR:%[0-9]+]]:_(<16 x s8>) = G_AIE_UNPAD_VECTOR [[BITCAST1]](<64 x s8>)
    ; CHECK-NEXT: [[FRAME_INDEX:%[0-9]+]]:_(p0) = G_FRAME_INDEX %stack.0
    ; CHECK-NEXT: G_STORE [[AIE_UNPAD_VECTOR]](<16 x s8>), [[FRAME_INDEX]](p0) :: (store (<16 x s8>))
    ; CHECK-NEXT: PseudoRET implicit $lr
    %2:_(s32) = G_CONSTANT i32 42
    %3:_(s32) = G_CONSTANT i32 19
    %4:_(s32) = G_CONSTANT i32 32
    %5:_(s32) = G_CONSTANT i32 12
    %1:_(<16 x s8>) = G_BUILD_VECTOR_TRUNC %2(s32), %3(s32), %4(s32), %5(s32), %2(s32), %3(s32), %4(s32), %5(s32), %2(s32), %3(s32), %4(s32), %5(s32), %2(s32), %3(s32), %4(s32), %5(s32)
    %0:_(p0) = G_FRAME_INDEX %stack.0
    G_STORE %1(<16 x s8>), %0(p0) :: (store (<16 x s8>))
    PseudoRET implicit $lr
...

---
name:            test_build_vector_trunc_8bit_256
stack:
  - {id: 0, name: "", type: default, offset: 0, size: 32, alignment: 32}
body:             |
  bb.1.entry:
    ; CHECK-LABEL: name: test_build_vector_trunc_8bit_256
    ; CHECK: [[C:%[0-9]+]]:_(s32) = G_CONSTANT i32 4
    ; CHECK-NEXT: [[C1:%[0-9]+]]:_(s32) = G_CONSTANT i32 12
    ; CHECK-NEXT: [[C2:%[0-9]+]]:_(s32) = G_CONSTANT i32 9
    ; CHECK-NEXT: [[C3:%[0-9]+]]:_(s32) = G_CONSTANT i32 0
    ; CHECK-NEXT: [[DEF:%[0-9]+]]:_(<64 x s8>) = G_IMPLICIT_DEF
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI:%[0-9]+]]:_(<64 x s8>) = G_AIE_ADD_VECTOR_ELT_HI [[DEF]], [[C]](s32)
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI1:%[0-9]+]]:_(<64 x s8>) = G_AIE_ADD_VECTOR_ELT_HI [[AIE_ADD_VECTOR_ELT_HI]], [[C1]](s32)
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI2:%[0-9]+]]:_(<64 x s8>) = G_AIE_ADD_VECTOR_ELT_HI [[AIE_ADD_VECTOR_ELT_HI1]], [[C2]](s32)
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI3:%[0-9]+]]:_(<64 x s8>) = G_AIE_ADD_VECTOR_ELT_HI [[AIE_ADD_VECTOR_ELT_HI2]], [[C3]](s32)
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI4:%[0-9]+]]:_(<64 x s8>) = G_AIE_ADD_VECTOR_ELT_HI [[AIE_ADD_VECTOR_ELT_HI3]], [[C3]](s32)
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI5:%[0-9]+]]:_(<64 x s8>) = G_AIE_ADD_VECTOR_ELT_HI [[AIE_ADD_VECTOR_ELT_HI4]], [[C3]](s32)
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI6:%[0-9]+]]:_(<64 x s8>) = G_AIE_ADD_VECTOR_ELT_HI [[AIE_ADD_VECTOR_ELT_HI5]], [[C3]](s32)
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI7:%[0-9]+]]:_(<64 x s8>) = G_AIE_ADD_VECTOR_ELT_HI [[AIE_ADD_VECTOR_ELT_HI6]], [[C3]](s32)
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI8:%[0-9]+]]:_(<64 x s8>) = G_AIE_ADD_VECTOR_ELT_HI [[AIE_ADD_VECTOR_ELT_HI7]], [[C3]](s32)
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI9:%[0-9]+]]:_(<64 x s8>) = G_AIE_ADD_VECTOR_ELT_HI [[AIE_ADD_VECTOR_ELT_HI8]], [[C3]](s32)
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI10:%[0-9]+]]:_(<64 x s8>) = G_AIE_ADD_VECTOR_ELT_HI [[AIE_ADD_VECTOR_ELT_HI9]], [[C3]](s32)
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI11:%[0-9]+]]:_(<64 x s8>) = G_AIE_ADD_VECTOR_ELT_HI [[AIE_ADD_VECTOR_ELT_HI10]], [[C3]](s32)
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI12:%[0-9]+]]:_(<64 x s8>) = G_AIE_ADD_VECTOR_ELT_HI [[AIE_ADD_VECTOR_ELT_HI11]], [[C3]](s32)
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI13:%[0-9]+]]:_(<64 x s8>) = G_AIE_ADD_VECTOR_ELT_HI [[AIE_ADD_VECTOR_ELT_HI12]], [[C3]](s32)
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI14:%[0-9]+]]:_(<64 x s8>) = G_AIE_ADD_VECTOR_ELT_HI [[AIE_ADD_VECTOR_ELT_HI13]], [[C3]](s32)
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI15:%[0-9]+]]:_(<64 x s8>) = G_AIE_ADD_VECTOR_ELT_HI [[AIE_ADD_VECTOR_ELT_HI14]], [[C3]](s32)
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI16:%[0-9]+]]:_(<64 x s8>) = G_AIE_ADD_VECTOR_ELT_HI [[AIE_ADD_VECTOR_ELT_HI15]], [[C]](s32)
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI17:%[0-9]+]]:_(<64 x s8>) = G_AIE_ADD_VECTOR_ELT_HI [[AIE_ADD_VECTOR_ELT_HI16]], [[C1]](s32)
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI18:%[0-9]+]]:_(<64 x s8>) = G_AIE_ADD_VECTOR_ELT_HI [[AIE_ADD_VECTOR_ELT_HI17]], [[C2]](s32)
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI19:%[0-9]+]]:_(<64 x s8>) = G_AIE_ADD_VECTOR_ELT_HI [[AIE_ADD_VECTOR_ELT_HI18]], [[C3]](s32)
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI20:%[0-9]+]]:_(<64 x s8>) = G_AIE_ADD_VECTOR_ELT_HI [[AIE_ADD_VECTOR_ELT_HI19]], [[C3]](s32)
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI21:%[0-9]+]]:_(<64 x s8>) = G_AIE_ADD_VECTOR_ELT_HI [[AIE_ADD_VECTOR_ELT_HI20]], [[C3]](s32)
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI22:%[0-9]+]]:_(<64 x s8>) = G_AIE_ADD_VECTOR_ELT_HI [[AIE_ADD_VECTOR_ELT_HI21]], [[C3]](s32)
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI23:%[0-9]+]]:_(<64 x s8>) = G_AIE_ADD_VECTOR_ELT_HI [[AIE_ADD_VECTOR_ELT_HI22]], [[C3]](s32)
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI24:%[0-9]+]]:_(<64 x s8>) = G_AIE_ADD_VECTOR_ELT_HI [[AIE_ADD_VECTOR_ELT_HI23]], [[C3]](s32)
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI25:%[0-9]+]]:_(<64 x s8>) = G_AIE_ADD_VECTOR_ELT_HI [[AIE_ADD_VECTOR_ELT_HI24]], [[C3]](s32)
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI26:%[0-9]+]]:_(<64 x s8>) = G_AIE_ADD_VECTOR_ELT_HI [[AIE_ADD_VECTOR_ELT_HI25]], [[C3]](s32)
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI27:%[0-9]+]]:_(<64 x s8>) = G_AIE_ADD_VECTOR_ELT_HI [[AIE_ADD_VECTOR_ELT_HI26]], [[C3]](s32)
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI28:%[0-9]+]]:_(<64 x s8>) = G_AIE_ADD_VECTOR_ELT_HI [[AIE_ADD_VECTOR_ELT_HI27]], [[C3]](s32)
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI29:%[0-9]+]]:_(<64 x s8>) = G_AIE_ADD_VECTOR_ELT_HI [[AIE_ADD_VECTOR_ELT_HI28]], [[C3]](s32)
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI30:%[0-9]+]]:_(<64 x s8>) = G_AIE_ADD_VECTOR_ELT_HI [[AIE_ADD_VECTOR_ELT_HI29]], [[C3]](s32)
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI31:%[0-9]+]]:_(<64 x s8>) = G_AIE_ADD_VECTOR_ELT_HI [[AIE_ADD_VECTOR_ELT_HI30]], [[C3]](s32)
    ; CHECK-NEXT: [[UV:%[0-9]+]]:_(<32 x s8>), [[UV1:%[0-9]+]]:_(<32 x s8>) = G_UNMERGE_VALUES [[AIE_ADD_VECTOR_ELT_HI31]](<64 x s8>)
    ; CHECK-NEXT: [[FRAME_INDEX:%[0-9]+]]:_(p0) = G_FRAME_INDEX %stack.0
    ; CHECK-NEXT: G_STORE [[UV1]](<32 x s8>), [[FRAME_INDEX]](p0) :: (store (<32 x s8>))
     %2:_(s32) = G_CONSTANT i32 4
    %3:_(s32) = G_CONSTANT i32 12
    %4:_(s32) = G_CONSTANT i32 9
    %5:_(s32) = G_CONSTANT i32 0
    %1:_(<32 x s8>) = G_BUILD_VECTOR_TRUNC %2(s32), %3(s32), %4(s32), %5(s32), %5(s32), %5(s32), %5(s32), %5(s32), %5(s32), %5(s32), %5(s32), %5(s32), %5(s32), %5(s32), %5(s32), %5(s32), %2(s32), %3(s32), %4(s32), %5(s32), %5(s32), %5(s32), %5(s32), %5(s32), %5(s32), %5(s32), %5(s32), %5(s32), %5(s32), %5(s32), %5(s32), %5(s32)
    %0:_(p0) = G_FRAME_INDEX %stack.0
    G_STORE %1(<32 x s8>), %0(p0) :: (store (<32 x s8>))
...

---
name:            test_build_vector_trunc_16bit_256
stack:
  - {id: 0, name: "", type: default, offset: 0, size: 32, alignment: 32}
body:             |
  bb.1.entry:
    ; CHECK-LABEL: name: test_build_vector_trunc_16bit_256
    ; CHECK: [[C:%[0-9]+]]:_(s32) = G_CONSTANT i32 9
    ; CHECK-NEXT: [[C1:%[0-9]+]]:_(s32) = G_CONSTANT i32 12
    ; CHECK-NEXT: [[C2:%[0-9]+]]:_(s32) = G_CONSTANT i32 13
    ; CHECK-NEXT: [[C3:%[0-9]+]]:_(s32) = G_CONSTANT i32 0
    ; CHECK-NEXT: [[DEF:%[0-9]+]]:_(<32 x s16>) = G_IMPLICIT_DEF
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI:%[0-9]+]]:_(<32 x s16>) = G_AIE_ADD_VECTOR_ELT_HI [[DEF]], [[C]](s32)
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI1:%[0-9]+]]:_(<32 x s16>) = G_AIE_ADD_VECTOR_ELT_HI [[AIE_ADD_VECTOR_ELT_HI]], [[C1]](s32)
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI2:%[0-9]+]]:_(<32 x s16>) = G_AIE_ADD_VECTOR_ELT_HI [[AIE_ADD_VECTOR_ELT_HI1]], [[C2]](s32)
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI3:%[0-9]+]]:_(<32 x s16>) = G_AIE_ADD_VECTOR_ELT_HI [[AIE_ADD_VECTOR_ELT_HI2]], [[C3]](s32)
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI4:%[0-9]+]]:_(<32 x s16>) = G_AIE_ADD_VECTOR_ELT_HI [[AIE_ADD_VECTOR_ELT_HI3]], [[C3]](s32)
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI5:%[0-9]+]]:_(<32 x s16>) = G_AIE_ADD_VECTOR_ELT_HI [[AIE_ADD_VECTOR_ELT_HI4]], [[C3]](s32)
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI6:%[0-9]+]]:_(<32 x s16>) = G_AIE_ADD_VECTOR_ELT_HI [[AIE_ADD_VECTOR_ELT_HI5]], [[C3]](s32)
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI7:%[0-9]+]]:_(<32 x s16>) = G_AIE_ADD_VECTOR_ELT_HI [[AIE_ADD_VECTOR_ELT_HI6]], [[C3]](s32)
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI8:%[0-9]+]]:_(<32 x s16>) = G_AIE_ADD_VECTOR_ELT_HI [[AIE_ADD_VECTOR_ELT_HI7]], [[C]](s32)
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI9:%[0-9]+]]:_(<32 x s16>) = G_AIE_ADD_VECTOR_ELT_HI [[AIE_ADD_VECTOR_ELT_HI8]], [[C1]](s32)
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI10:%[0-9]+]]:_(<32 x s16>) = G_AIE_ADD_VECTOR_ELT_HI [[AIE_ADD_VECTOR_ELT_HI9]], [[C2]](s32)
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI11:%[0-9]+]]:_(<32 x s16>) = G_AIE_ADD_VECTOR_ELT_HI [[AIE_ADD_VECTOR_ELT_HI10]], [[C3]](s32)
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI12:%[0-9]+]]:_(<32 x s16>) = G_AIE_ADD_VECTOR_ELT_HI [[AIE_ADD_VECTOR_ELT_HI11]], [[C3]](s32)
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI13:%[0-9]+]]:_(<32 x s16>) = G_AIE_ADD_VECTOR_ELT_HI [[AIE_ADD_VECTOR_ELT_HI12]], [[C3]](s32)
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI14:%[0-9]+]]:_(<32 x s16>) = G_AIE_ADD_VECTOR_ELT_HI [[AIE_ADD_VECTOR_ELT_HI13]], [[C3]](s32)
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI15:%[0-9]+]]:_(<32 x s16>) = G_AIE_ADD_VECTOR_ELT_HI [[AIE_ADD_VECTOR_ELT_HI14]], [[C3]](s32)
    ; CHECK-NEXT: [[UV:%[0-9]+]]:_(<16 x s16>), [[UV1:%[0-9]+]]:_(<16 x s16>) = G_UNMERGE_VALUES [[AIE_ADD_VECTOR_ELT_HI15]](<32 x s16>)
    ; CHECK-NEXT: [[FRAME_INDEX:%[0-9]+]]:_(p0) = G_FRAME_INDEX %stack.0
    ; CHECK-NEXT: G_STORE [[UV1]](<16 x s16>), [[FRAME_INDEX]](p0) :: (store (<16 x s16>))
    %2:_(s32) = G_CONSTANT i32 9
    %3:_(s32) = G_CONSTANT i32 12
    %4:_(s32) = G_CONSTANT i32 13
    %5:_(s32) = G_CONSTANT i32 0
    %1:_(<16 x s16>) = G_BUILD_VECTOR_TRUNC %2(s32), %3(s32), %4(s32), %5(s32), %5(s32), %5(s32), %5(s32), %5(s32), %2(s32), %3(s32), %4(s32), %5(s32), %5(s32), %5(s32), %5(s32), %5(s32)
    %0:_(p0) = G_FRAME_INDEX %stack.0
    G_STORE %1(<16 x s16>), %0(p0) :: (store (<16 x s16>))
...

---
name:            test_build_vector_trunc_16bit_512
stack:
  - {id: 0, name: "", type: default, offset: 0, size: 64, alignment: 32}
body:             |
  bb.1.entry:
    ; CHECK-LABEL: name: test_build_vector_trunc_16bit_512
    ; CHECK: [[C:%[0-9]+]]:_(s32) = G_CONSTANT i32 4
    ; CHECK-NEXT: [[C1:%[0-9]+]]:_(s32) = G_CONSTANT i32 12
    ; CHECK-NEXT: [[C2:%[0-9]+]]:_(s32) = G_CONSTANT i32 9
    ; CHECK-NEXT: [[C3:%[0-9]+]]:_(s32) = G_CONSTANT i32 0
    ; CHECK-NEXT: [[DEF:%[0-9]+]]:_(<32 x s16>) = G_IMPLICIT_DEF
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI:%[0-9]+]]:_(<32 x s16>) = G_AIE_ADD_VECTOR_ELT_HI [[DEF]], [[C]](s32)
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI1:%[0-9]+]]:_(<32 x s16>) = G_AIE_ADD_VECTOR_ELT_HI [[AIE_ADD_VECTOR_ELT_HI]], [[C1]](s32)
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI2:%[0-9]+]]:_(<32 x s16>) = G_AIE_ADD_VECTOR_ELT_HI [[AIE_ADD_VECTOR_ELT_HI1]], [[C2]](s32)
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI3:%[0-9]+]]:_(<32 x s16>) = G_AIE_ADD_VECTOR_ELT_HI [[AIE_ADD_VECTOR_ELT_HI2]], [[C3]](s32)
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI4:%[0-9]+]]:_(<32 x s16>) = G_AIE_ADD_VECTOR_ELT_HI [[AIE_ADD_VECTOR_ELT_HI3]], [[C3]](s32)
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI5:%[0-9]+]]:_(<32 x s16>) = G_AIE_ADD_VECTOR_ELT_HI [[AIE_ADD_VECTOR_ELT_HI4]], [[C3]](s32)
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI6:%[0-9]+]]:_(<32 x s16>) = G_AIE_ADD_VECTOR_ELT_HI [[AIE_ADD_VECTOR_ELT_HI5]], [[C3]](s32)
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI7:%[0-9]+]]:_(<32 x s16>) = G_AIE_ADD_VECTOR_ELT_HI [[AIE_ADD_VECTOR_ELT_HI6]], [[C3]](s32)
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI8:%[0-9]+]]:_(<32 x s16>) = G_AIE_ADD_VECTOR_ELT_HI [[AIE_ADD_VECTOR_ELT_HI7]], [[C3]](s32)
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI9:%[0-9]+]]:_(<32 x s16>) = G_AIE_ADD_VECTOR_ELT_HI [[AIE_ADD_VECTOR_ELT_HI8]], [[C3]](s32)
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI10:%[0-9]+]]:_(<32 x s16>) = G_AIE_ADD_VECTOR_ELT_HI [[AIE_ADD_VECTOR_ELT_HI9]], [[C3]](s32)
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI11:%[0-9]+]]:_(<32 x s16>) = G_AIE_ADD_VECTOR_ELT_HI [[AIE_ADD_VECTOR_ELT_HI10]], [[C3]](s32)
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI12:%[0-9]+]]:_(<32 x s16>) = G_AIE_ADD_VECTOR_ELT_HI [[AIE_ADD_VECTOR_ELT_HI11]], [[C3]](s32)
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI13:%[0-9]+]]:_(<32 x s16>) = G_AIE_ADD_VECTOR_ELT_HI [[AIE_ADD_VECTOR_ELT_HI12]], [[C3]](s32)
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI14:%[0-9]+]]:_(<32 x s16>) = G_AIE_ADD_VECTOR_ELT_HI [[AIE_ADD_VECTOR_ELT_HI13]], [[C3]](s32)
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI15:%[0-9]+]]:_(<32 x s16>) = G_AIE_ADD_VECTOR_ELT_HI [[AIE_ADD_VECTOR_ELT_HI14]], [[C3]](s32)
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI16:%[0-9]+]]:_(<32 x s16>) = G_AIE_ADD_VECTOR_ELT_HI [[AIE_ADD_VECTOR_ELT_HI15]], [[C]](s32)
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI17:%[0-9]+]]:_(<32 x s16>) = G_AIE_ADD_VECTOR_ELT_HI [[AIE_ADD_VECTOR_ELT_HI16]], [[C1]](s32)
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI18:%[0-9]+]]:_(<32 x s16>) = G_AIE_ADD_VECTOR_ELT_HI [[AIE_ADD_VECTOR_ELT_HI17]], [[C2]](s32)
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI19:%[0-9]+]]:_(<32 x s16>) = G_AIE_ADD_VECTOR_ELT_HI [[AIE_ADD_VECTOR_ELT_HI18]], [[C3]](s32)
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI20:%[0-9]+]]:_(<32 x s16>) = G_AIE_ADD_VECTOR_ELT_HI [[AIE_ADD_VECTOR_ELT_HI19]], [[C3]](s32)
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI21:%[0-9]+]]:_(<32 x s16>) = G_AIE_ADD_VECTOR_ELT_HI [[AIE_ADD_VECTOR_ELT_HI20]], [[C3]](s32)
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI22:%[0-9]+]]:_(<32 x s16>) = G_AIE_ADD_VECTOR_ELT_HI [[AIE_ADD_VECTOR_ELT_HI21]], [[C3]](s32)
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI23:%[0-9]+]]:_(<32 x s16>) = G_AIE_ADD_VECTOR_ELT_HI [[AIE_ADD_VECTOR_ELT_HI22]], [[C3]](s32)
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI24:%[0-9]+]]:_(<32 x s16>) = G_AIE_ADD_VECTOR_ELT_HI [[AIE_ADD_VECTOR_ELT_HI23]], [[C3]](s32)
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI25:%[0-9]+]]:_(<32 x s16>) = G_AIE_ADD_VECTOR_ELT_HI [[AIE_ADD_VECTOR_ELT_HI24]], [[C3]](s32)
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI26:%[0-9]+]]:_(<32 x s16>) = G_AIE_ADD_VECTOR_ELT_HI [[AIE_ADD_VECTOR_ELT_HI25]], [[C3]](s32)
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI27:%[0-9]+]]:_(<32 x s16>) = G_AIE_ADD_VECTOR_ELT_HI [[AIE_ADD_VECTOR_ELT_HI26]], [[C3]](s32)
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI28:%[0-9]+]]:_(<32 x s16>) = G_AIE_ADD_VECTOR_ELT_HI [[AIE_ADD_VECTOR_ELT_HI27]], [[C3]](s32)
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI29:%[0-9]+]]:_(<32 x s16>) = G_AIE_ADD_VECTOR_ELT_HI [[AIE_ADD_VECTOR_ELT_HI28]], [[C3]](s32)
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI30:%[0-9]+]]:_(<32 x s16>) = G_AIE_ADD_VECTOR_ELT_HI [[AIE_ADD_VECTOR_ELT_HI29]], [[C3]](s32)
    ; CHECK-NEXT: [[AIE_ADD_VECTOR_ELT_HI31:%[0-9]+]]:_(<32 x s16>) = G_AIE_ADD_VECTOR_ELT_HI [[AIE_ADD_VECTOR_ELT_HI30]], [[C3]](s32)
    ; CHECK-NEXT: [[FRAME_INDEX:%[0-9]+]]:_(p0) = G_FRAME_INDEX %stack.0
    ; CHECK-NEXT: G_STORE [[AIE_ADD_VECTOR_ELT_HI]](<32 x s16>), [[FRAME_INDEX]](p0) :: (store (<32 x s16>), align 32)
    %2:_(s32) = G_CONSTANT i32 4
    %3:_(s32) = G_CONSTANT i32 12
    %4:_(s32) = G_CONSTANT i32 9
    %5:_(s32) = G_CONSTANT i32 0
    %1:_(<32 x s16>) = G_BUILD_VECTOR_TRUNC %2(s32), %3(s32), %4(s32), %5(s32), %5(s32), %5(s32), %5(s32), %5(s32), %5(s32), %5(s32), %5(s32), %5(s32), %5(s32), %5(s32), %5(s32), %5(s32), %2(s32), %3(s32), %4(s32), %5(s32), %5(s32), %5(s32), %5(s32), %5(s32), %5(s32), %5(s32), %5(s32), %5(s32), %5(s32), %5(s32), %5(s32), %5(s32)
    %0:_(p0) = G_FRAME_INDEX %stack.0
    G_STORE %1(<32 x s16>), %0(p0) :: (store (<32 x s16>), align 32)
...

---
name:            test_build_vector_32_16
body:             |
  bb.1.entry:
    ; CHECK-LABEL: name: test_build_vector_32_16
    ; CHECK: [[C:%[0-9]+]]:_(s32) = G_CONSTANT i32 1
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(s32) = COPY [[C]](s32)
    ; CHECK-NEXT: [[C1:%[0-9]+]]:_(s32) = G_CONSTANT i32 131072
    ; CHECK-NEXT: [[OR:%[0-9]+]]:_(s32) = G_OR [[COPY]], [[C1]]
    ; CHECK-NEXT: [[BITCAST:%[0-9]+]]:_(<2 x s16>) = G_BITCAST [[OR]](s32)
    ; CHECK-NEXT: PseudoRET implicit $lr, implicit [[BITCAST]](<2 x s16>)
    %0:_(s32) = G_CONSTANT i32 1
    %1:_(s32) = G_CONSTANT i32 2
    %2:_(<2 x s16>) = G_BUILD_VECTOR_TRUNC %0(s32), %1(s32)
    PseudoRET implicit $lr, implicit %2
...

---
name:            test_build_vector_32_8
body:             |
  bb.1.entry:
    ; CHECK-LABEL: name: test_build_vector_32_8
    ; CHECK: [[C:%[0-9]+]]:_(s32) = G_CONSTANT i32 1
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(s32) = COPY [[C]](s32)
    ; CHECK-NEXT: [[C1:%[0-9]+]]:_(s32) = G_CONSTANT i32 512
    ; CHECK-NEXT: [[OR:%[0-9]+]]:_(s32) = G_OR [[COPY]], [[C1]]
    ; CHECK-NEXT: [[C2:%[0-9]+]]:_(s32) = G_CONSTANT i32 196608
    ; CHECK-NEXT: [[OR1:%[0-9]+]]:_(s32) = G_OR [[OR]], [[C2]]
    ; CHECK-NEXT: [[C3:%[0-9]+]]:_(s32) = G_CONSTANT i32 67108864
    ; CHECK-NEXT: [[OR2:%[0-9]+]]:_(s32) = G_OR [[OR1]], [[C3]]
    ; CHECK-NEXT: [[BITCAST:%[0-9]+]]:_(<4 x s8>) = G_BITCAST [[OR2]](s32)
    ; CHECK-NEXT: PseudoRET implicit $lr, implicit [[BITCAST]](<4 x s8>)
    %0:_(s32) = G_CONSTANT i32 1
    %1:_(s32) = G_CONSTANT i32 2
    %2:_(s32) = G_CONSTANT i32 3
    %3:_(s32) = G_CONSTANT i32 4
    %4:_(<4 x s8>) = G_BUILD_VECTOR_TRUNC %0(s32), %1(s32), %2(s32), %3(s32)
    PseudoRET implicit $lr, implicit %4
...

---
name:            test_build_vector_32_8_negative
body:             |
  bb.1.entry:
    ; CHECK-LABEL: name: test_build_vector_32_8_negative
    ; CHECK: [[C:%[0-9]+]]:_(s32) = G_CONSTANT i32 -1
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(s32) = COPY [[C]](s32)
    ; CHECK-NEXT: [[C1:%[0-9]+]]:_(s32) = G_CONSTANT i32 -512
    ; CHECK-NEXT: [[OR:%[0-9]+]]:_(s32) = G_OR [[COPY]], [[C1]]
    ; CHECK-NEXT: [[C2:%[0-9]+]]:_(s32) = G_CONSTANT i32 -196608
    ; CHECK-NEXT: [[OR1:%[0-9]+]]:_(s32) = G_OR [[OR]], [[C2]]
    ; CHECK-NEXT: [[C3:%[0-9]+]]:_(s32) = G_CONSTANT i32 -67108864
    ; CHECK-NEXT: [[OR2:%[0-9]+]]:_(s32) = G_OR [[OR1]], [[C3]]
    ; CHECK-NEXT: [[BITCAST:%[0-9]+]]:_(<4 x s8>) = G_BITCAST [[OR2]](s32)
    ; CHECK-NEXT: PseudoRET implicit $lr, implicit [[BITCAST]](<4 x s8>)
    %0:_(s32) = G_CONSTANT i32 -1
    %1:_(s32) = G_CONSTANT i32 -2
    %2:_(s32) = G_CONSTANT i32 -3
    %3:_(s32) = G_CONSTANT i32 -4
    %4:_(<4 x s8>) = G_BUILD_VECTOR_TRUNC %0(s32), %1(s32), %2(s32), %3(s32)
    PseudoRET implicit $lr, implicit %4
...

---
name:            test_build_vector_32_8_mixed
body:             |
  bb.1.entry:
    ; CHECK-LABEL: name: test_build_vector_32_8_mixed
    ; CHECK: [[C:%[0-9]+]]:_(s32) = G_CONSTANT i32 19
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(s32) = COPY [[C]](s32)
    ; CHECK-NEXT: [[C1:%[0-9]+]]:_(s32) = G_CONSTANT i32 -6144
    ; CHECK-NEXT: [[OR:%[0-9]+]]:_(s32) = G_OR [[COPY]], [[C1]]
    ; CHECK-NEXT: [[C2:%[0-9]+]]:_(s32) = G_CONSTANT i32 2162688
    ; CHECK-NEXT: [[OR1:%[0-9]+]]:_(s32) = G_OR [[OR]], [[C2]]
    ; CHECK-NEXT: [[C3:%[0-9]+]]:_(s32) = G_CONSTANT i32 -1543503872
    ; CHECK-NEXT: [[OR2:%[0-9]+]]:_(s32) = G_OR [[OR1]], [[C3]]
    ; CHECK-NEXT: [[BITCAST:%[0-9]+]]:_(<4 x s8>) = G_BITCAST [[OR2]](s32)
    ; CHECK-NEXT: PseudoRET implicit $lr, implicit [[BITCAST]](<4 x s8>)
    %0:_(s32) = G_CONSTANT i32 19
    %1:_(s32) = G_CONSTANT i32 -24
    %2:_(s32) = G_CONSTANT i32 33
    %3:_(s32) = G_CONSTANT i32 -92
    %4:_(<4 x s8>) = G_BUILD_VECTOR_TRUNC %0(s32), %1(s32), %2(s32), %3(s32)
    PseudoRET implicit $lr, implicit %4
...

---
name:            test_build_vector_32_8_from_registers
body:             |
  bb.1.entry:
    liveins: $r0, $r1, $r2, $r3
    ; CHECK-LABEL: name: test_build_vector_32_8_from_registers
    ; CHECK: liveins: $r0, $r1, $r2, $r3
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(s32) = COPY $r0
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(s32) = COPY $r1
    ; CHECK-NEXT: [[COPY2:%[0-9]+]]:_(s32) = COPY $r2
    ; CHECK-NEXT: [[COPY3:%[0-9]+]]:_(s32) = COPY $r3
    ; CHECK-NEXT: [[C:%[0-9]+]]:_(s32) = G_CONSTANT i32 0
    ; CHECK-NEXT: [[OR:%[0-9]+]]:_(s32) = G_OR [[C]], [[COPY]]
    ; CHECK-NEXT: [[C1:%[0-9]+]]:_(s32) = G_CONSTANT i32 8
    ; CHECK-NEXT: [[SHL:%[0-9]+]]:_(s32) = G_SHL [[COPY1]], [[C1]](s32)
    ; CHECK-NEXT: [[OR1:%[0-9]+]]:_(s32) = G_OR [[OR]], [[SHL]]
    ; CHECK-NEXT: [[C2:%[0-9]+]]:_(s32) = G_CONSTANT i32 16
    ; CHECK-NEXT: [[SHL1:%[0-9]+]]:_(s32) = G_SHL [[COPY2]], [[C2]](s32)
    ; CHECK-NEXT: [[OR2:%[0-9]+]]:_(s32) = G_OR [[OR1]], [[SHL1]]
    ; CHECK-NEXT: [[C3:%[0-9]+]]:_(s32) = G_CONSTANT i32 24
    ; CHECK-NEXT: [[SHL2:%[0-9]+]]:_(s32) = G_SHL [[COPY3]], [[C3]](s32)
    ; CHECK-NEXT: [[OR3:%[0-9]+]]:_(s32) = G_OR [[OR2]], [[SHL2]]
    ; CHECK-NEXT: [[BITCAST:%[0-9]+]]:_(<4 x s8>) = G_BITCAST [[OR3]](s32)
    ; CHECK-NEXT: PseudoRET implicit $lr, implicit [[BITCAST]](<4 x s8>)
    %0:_(s32) = COPY $r0
    %1:_(s32) = COPY $r1
    %2:_(s32) = COPY $r2
    %3:_(s32) = COPY $r3
    %8:_(<4 x s8>) = G_BUILD_VECTOR_TRUNC  %0(s32), %1(s32), %2(s32), %3(s32)
    PseudoRET implicit $lr, implicit %8
...

---
name:            test_build_vector_32_8_register_constant
body:             |
  bb.1.entry:
    liveins: $r0, $r1
    ; CHECK-LABEL: name: test_build_vector_32_8_register_constant
    ; CHECK: liveins: $r0, $r1
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(s32) = COPY $r0
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(s32) = COPY $r1
    ; CHECK-NEXT: [[C:%[0-9]+]]:_(s32) = G_CONSTANT i32 0
    ; CHECK-NEXT: [[OR:%[0-9]+]]:_(s32) = G_OR [[C]], [[COPY]]
    ; CHECK-NEXT: [[C1:%[0-9]+]]:_(s32) = G_CONSTANT i32 8
    ; CHECK-NEXT: [[SHL:%[0-9]+]]:_(s32) = G_SHL [[COPY1]], [[C1]](s32)
    ; CHECK-NEXT: [[OR1:%[0-9]+]]:_(s32) = G_OR [[OR]], [[SHL]]
    ; CHECK-NEXT: [[C2:%[0-9]+]]:_(s32) = G_CONSTANT i32 1245184
    ; CHECK-NEXT: [[OR2:%[0-9]+]]:_(s32) = G_OR [[OR1]], [[C2]]
    ; CHECK-NEXT: [[C3:%[0-9]+]]:_(s32) = G_CONSTANT i32 553648128
    ; CHECK-NEXT: [[OR3:%[0-9]+]]:_(s32) = G_OR [[OR2]], [[C3]]
    ; CHECK-NEXT: [[BITCAST:%[0-9]+]]:_(<4 x s8>) = G_BITCAST [[OR3]](s32)
    ; CHECK-NEXT: PseudoRET implicit $lr, implicit [[BITCAST]](<4 x s8>)
    %0:_(s32) = COPY $r0
    %1:_(s32) = COPY $r1
    %2:_(s32) = G_CONSTANT i32 19
    %3:_(s32) = G_CONSTANT i32 33
    %4:_(<4 x s8>) = G_BUILD_VECTOR_TRUNC  %0(s32), %1(s32), %2(s32), %3(s32)
    PseudoRET implicit $lr, implicit %4
...
