; NOTE: Assertions have been autogenerated by utils/update_mir_test_checks.py
;
; This file is licensed under the Apache License v2.0 with LLVM Exceptions.
; See https://llvm.org/LICENSE.txt for license information.
; SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
;
; (c) Copyright 2023-2024 Advanced Micro Devices, Inc. or its affiliates
; RUN: llc -mtriple=aie2 -O0 -stop-after=irtranslator -global-isel -verify-machineinstrs %s -o - 2>&1 | FileCheck %s

%class.bfloat16 = type { bfloat }
define dso_local void @_Z17test_get_bfloat16v() local_unnamed_addr #0 {
  ; CHECK-LABEL: name: _Z17test_get_bfloat16v
  ; CHECK: bb.1.entry:
  ; CHECK-NEXT:   [[FRAME_INDEX:%[0-9]+]]:_(p0) = G_FRAME_INDEX %stack.0.call.sroa.0
  ; CHECK-NEXT:   ADJCALLSTACKUP 0, 0, implicit-def $sp, implicit $sp
  ; CHECK-NEXT:   PseudoJL @_Z12ret_vfloat16v, csr_aie2, implicit-def $lr, implicit-def $r0
  ; CHECK-NEXT:   [[COPY:%[0-9]+]]:_(s32) = COPY $r0
  ; CHECK-NEXT:   [[TRUNC:%[0-9]+]]:_(s16) = G_TRUNC [[COPY]](s32)
  ; CHECK-NEXT:   ADJCALLSTACKDOWN 0, 0, implicit-def $sp, implicit $sp
  ; CHECK-NEXT:   G_STORE [[TRUNC]](s16), [[FRAME_INDEX]](p0) :: (volatile store (s16) into %ir.call.sroa.0)
  ; CHECK-NEXT:   PseudoRET implicit $lr
entry:
  %call.sroa.0 = alloca bfloat, align 2
  %call1 = tail call %class.bfloat16 @_Z12ret_vfloat16v()
  %0 = extractvalue %class.bfloat16 %call1, 0
  store volatile bfloat %0, ptr %call.sroa.0, align 2
  ret void
}
declare dso_local %class.bfloat16 @_Z12ret_vfloat16v() local_unnamed_addr #2

define dso_local void @_Z19test_get_v2bfloat16v() local_unnamed_addr #0 {
  ; CHECK-LABEL: name: _Z19test_get_v2bfloat16v
  ; CHECK: bb.1.entry:
  ; CHECK-NEXT:   [[FRAME_INDEX:%[0-9]+]]:_(p0) = G_FRAME_INDEX %stack.0.ret
  ; CHECK-NEXT:   ADJCALLSTACKUP 0, 0, implicit-def $sp, implicit $sp
  ; CHECK-NEXT:   PseudoJL @_Z15test_v2bfloat16v, csr_aie2, implicit-def $lr, implicit-def $r0
  ; CHECK-NEXT:   [[COPY:%[0-9]+]]:_(<2 x s16>) = COPY $r0
  ; CHECK-NEXT:   ADJCALLSTACKDOWN 0, 0, implicit-def $sp, implicit $sp
  ; CHECK-NEXT:   G_STORE [[COPY]](<2 x s16>), [[FRAME_INDEX]](p0) :: (volatile store (<2 x s16>) into %ir.ret)
  ; CHECK-NEXT:   PseudoRET implicit $lr
entry:
  %ret = alloca <2 x bfloat>, align 4
  %call = tail call noundef <2 x bfloat> @_Z15test_v2bfloat16v()
  store volatile <2 x bfloat> %call, ptr %ret, align 4
  ret void
}
declare dso_local noundef <2 x bfloat> @_Z15test_v2bfloat16v() local_unnamed_addr #2

; Function Attrs: mustprogress
define dso_local void @_Z19test_get_v4bfloat16v() local_unnamed_addr #0 {
  ; CHECK-LABEL: name: _Z19test_get_v4bfloat16v
  ; CHECK: bb.1.entry:
  ; CHECK-NEXT:   [[FRAME_INDEX:%[0-9]+]]:_(p0) = G_FRAME_INDEX %stack.0.ret
  ; CHECK-NEXT:   ADJCALLSTACKUP 0, 0, implicit-def $sp, implicit $sp
  ; CHECK-NEXT:   PseudoJL @_Z15test_v4bfloat16v, CustomRegMask($lr,$l1,$l2,$l3,$p6,$p7,$r18,$r19,$r20,$r21,$r22,$r23), implicit-def $lr, implicit-def $l0
  ; CHECK-NEXT:   [[COPY:%[0-9]+]]:_(<4 x s16>) = COPY $l0
  ; CHECK-NEXT:   ADJCALLSTACKDOWN 0, 0, implicit-def $sp, implicit $sp
  ; CHECK-NEXT:   G_STORE [[COPY]](<4 x s16>), [[FRAME_INDEX]](p0) :: (volatile store (<4 x s16>) into %ir.ret)
  ; CHECK-NEXT:   PseudoRET implicit $lr
entry:
  %ret = alloca <4 x bfloat>, align 8
  %call = tail call noundef <4 x bfloat> @_Z15test_v4bfloat16v()
  store volatile <4 x bfloat> %call, ptr %ret, align 8
  ret void
}
declare dso_local noundef <4 x bfloat> @_Z15test_v4bfloat16v() local_unnamed_addr #2

define void @_Z23test_call_retv8bfloat16v() #0 {
  ; CHECK-LABEL: name: _Z23test_call_retv8bfloat16v
  ; CHECK: bb.1.entry:
  ; CHECK-NEXT:   [[FRAME_INDEX:%[0-9]+]]:_(p0) = G_FRAME_INDEX %stack.0.call
  ; CHECK-NEXT:   ADJCALLSTACKUP 0, 0, implicit-def $sp, implicit $sp
  ; CHECK-NEXT:   PseudoJL @_Z14ret_v8bfloat16v, csr_aie2, implicit-def $lr, implicit-def $wl0
  ; CHECK-NEXT:   [[COPY:%[0-9]+]]:_(<16 x s16>) = COPY $wl0
  ; CHECK-NEXT:   [[UV:%[0-9]+]]:_(<8 x s16>), [[UV1:%[0-9]+]]:_(<8 x s16>) = G_UNMERGE_VALUES [[COPY]](<16 x s16>)
  ; CHECK-NEXT:   ADJCALLSTACKDOWN 0, 0, implicit-def $sp, implicit $sp
  ; CHECK-NEXT:   G_STORE [[UV]](<8 x s16>), [[FRAME_INDEX]](p0) :: (volatile store (<8 x s16>) into %ir.call)
  ; CHECK-NEXT:   PseudoRET implicit $lr
entry:
  %call = alloca <8 x bfloat>, align 16
  %call1 = call <8 x bfloat> @_Z14ret_v8bfloat16v()
  store volatile <8 x bfloat> %call1, ptr %call, align 16
  ret void
}

declare <8 x bfloat> @_Z14ret_v8bfloat16v() #1

define void @_Z24test_call_retv16bfloat16v() #0 {
  ; CHECK-LABEL: name: _Z24test_call_retv16bfloat16v
  ; CHECK: bb.1.entry:
  ; CHECK-NEXT:   [[FRAME_INDEX:%[0-9]+]]:_(p0) = G_FRAME_INDEX %stack.0.call
  ; CHECK-NEXT:   ADJCALLSTACKUP 0, 0, implicit-def $sp, implicit $sp
  ; CHECK-NEXT:   PseudoJL @_Z15ret_v16bfloat16v, csr_aie2, implicit-def $lr, implicit-def $wl0
  ; CHECK-NEXT:   [[COPY:%[0-9]+]]:_(<16 x s16>) = COPY $wl0
  ; CHECK-NEXT:   ADJCALLSTACKDOWN 0, 0, implicit-def $sp, implicit $sp
  ; CHECK-NEXT:   G_STORE [[COPY]](<16 x s16>), [[FRAME_INDEX]](p0) :: (volatile store (<16 x s16>) into %ir.call)
  ; CHECK-NEXT:   PseudoRET implicit $lr
entry:
  %call = alloca <16 x bfloat>, align 32
  %call1 = call <16 x bfloat> @_Z15ret_v16bfloat16v()
  store volatile <16 x bfloat> %call1, ptr %call, align 32
  ret void
}

declare <16 x bfloat> @_Z15ret_v16bfloat16v() #1

define void @_Z24test_call_retv32bfloat16v() #0 {
  ; CHECK-LABEL: name: _Z24test_call_retv32bfloat16v
  ; CHECK: bb.1.entry:
  ; CHECK-NEXT:   [[FRAME_INDEX:%[0-9]+]]:_(p0) = G_FRAME_INDEX %stack.0.call
  ; CHECK-NEXT:   ADJCALLSTACKUP 0, 0, implicit-def $sp, implicit $sp
  ; CHECK-NEXT:   PseudoJL @_Z15ret_v32bfloat16v, csr_aie2, implicit-def $lr, implicit-def $x0
  ; CHECK-NEXT:   [[COPY:%[0-9]+]]:_(<32 x s16>) = COPY $x0
  ; CHECK-NEXT:   ADJCALLSTACKDOWN 0, 0, implicit-def $sp, implicit $sp
  ; CHECK-NEXT:   G_STORE [[COPY]](<32 x s16>), [[FRAME_INDEX]](p0) :: (volatile store (<32 x s16>) into %ir.call)
  ; CHECK-NEXT:   PseudoRET implicit $lr
entry:
  %call = alloca <32 x bfloat>, align 64
  %call1 = call <32 x bfloat> @_Z15ret_v32bfloat16v()
  store volatile <32 x bfloat> %call1, ptr %call, align 64
  ret void
}

declare <32 x bfloat> @_Z15ret_v32bfloat16v() #1

define void @_Z24test_call_retv64bfloat16v() #0 {
  ; CHECK-LABEL: name: _Z24test_call_retv64bfloat16v
  ; CHECK: bb.1.entry:
  ; CHECK-NEXT:   [[FRAME_INDEX:%[0-9]+]]:_(p0) = G_FRAME_INDEX %stack.0.call
  ; CHECK-NEXT:   ADJCALLSTACKUP 0, 0, implicit-def $sp, implicit $sp
  ; CHECK-NEXT:   PseudoJL @_Z15ret_v64bfloat16v, csr_aie2, implicit-def $lr, implicit-def $y2
  ; CHECK-NEXT:   [[COPY:%[0-9]+]]:_(<64 x s16>) = COPY $y2
  ; CHECK-NEXT:   ADJCALLSTACKDOWN 0, 0, implicit-def $sp, implicit $sp
  ; CHECK-NEXT:   G_STORE [[COPY]](<64 x s16>), [[FRAME_INDEX]](p0) :: (volatile store (<64 x s16>) into %ir.call)
  ; CHECK-NEXT:   PseudoRET implicit $lr
entry:
  %call = alloca <64 x bfloat>, align 128
  %call1 = call <64 x bfloat> @_Z15ret_v64bfloat16v()
  store volatile <64 x bfloat> %call1, ptr %call, align 128
  ret void
}

declare <64 x bfloat> @_Z15ret_v64bfloat16v() #1
