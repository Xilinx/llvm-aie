# NOTE: Assertions have been autogenerated by utils/update_mir_test_checks.py
#
# This file is licensed under the Apache License v2.0 with LLVM Exceptions.
# See https://llvm.org/LICENSE.txt for license information.
# SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
#
# (c) Copyright 2023-2024 Advanced Micro Devices, Inc. or its affiliates
# RUN: llc -mtriple aie2 -run-pass=instruction-select %s -verify-machineinstrs -o - | FileCheck %s

---
name:            VLDA_UPS_S32_S16
legalized:       true
regBankSelected: true
tracksRegLiveness: true
body: |
  bb.0:
    liveins: $p0, $r0, $r1, $amll0
    ; CHECK-LABEL: name: VLDA_UPS_S32_S16
    ; CHECK: liveins: $p0, $r0, $r1, $amll0
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:ep = COPY $p0
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:er = COPY $r0
    ; CHECK-NEXT: [[COPY2:%[0-9]+]]:em = COPY [[COPY1]]
    ; CHECK-NEXT: [[MOV_PD_imm10_pseudo:%[0-9]+]]:em = MOV_PD_imm10_pseudo 16
    ; CHECK-NEXT: [[MOV_PD_imm10_pseudo1:%[0-9]+]]:em = MOV_PD_imm10_pseudo 256
    ; CHECK-NEXT: [[COPY3:%[0-9]+]]:er = COPY $r1
    ; CHECK-NEXT: [[COPY4:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S32_S16_ag_pstm_nrm:%[0-9]+]]:acc512, [[VLDA_UPS_S32_S16_ag_pstm_nrm1:%[0-9]+]]:ep = VLDA_UPS_S32_S16_ag_pstm_nrm [[COPY4]], [[COPY]], [[COPY2]], implicit-def $srups_of, implicit $crsat :: (load (<16 x s16>))
    ; CHECK-NEXT: [[COPY5:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S32_S16_ag_pstm_nrm_imm:%[0-9]+]]:acc512, [[VLDA_UPS_S32_S16_ag_pstm_nrm_imm1:%[0-9]+]]:ep = VLDA_UPS_S32_S16_ag_pstm_nrm_imm [[COPY5]], [[VLDA_UPS_S32_S16_ag_pstm_nrm1]], 0, implicit-def $srups_of, implicit $crsat :: (load (<16 x s16>))
    ; CHECK-NEXT: [[COPY6:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S32_S16_ag_pstm_nrm2:%[0-9]+]]:acc512, [[VLDA_UPS_S32_S16_ag_pstm_nrm3:%[0-9]+]]:ep = VLDA_UPS_S32_S16_ag_pstm_nrm [[COPY6]], [[VLDA_UPS_S32_S16_ag_pstm_nrm_imm1]], [[MOV_PD_imm10_pseudo]], implicit-def $srups_of, implicit $crsat :: (load (<16 x s16>))
    ; CHECK-NEXT: [[COPY7:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S32_S16_ag_pstm_nrm_imm2:%[0-9]+]]:acc512, [[VLDA_UPS_S32_S16_ag_pstm_nrm_imm3:%[0-9]+]]:ep = VLDA_UPS_S32_S16_ag_pstm_nrm_imm [[COPY7]], [[VLDA_UPS_S32_S16_ag_pstm_nrm3]], -256, implicit-def $srups_of, implicit $crsat :: (load (<16 x s16>))
    ; CHECK-NEXT: [[COPY8:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S32_S16_ag_pstm_nrm_imm4:%[0-9]+]]:acc512, [[VLDA_UPS_S32_S16_ag_pstm_nrm_imm5:%[0-9]+]]:ep = VLDA_UPS_S32_S16_ag_pstm_nrm_imm [[COPY8]], [[VLDA_UPS_S32_S16_ag_pstm_nrm_imm3]], 224, implicit-def $srups_of, implicit $crsat :: (load (<16 x s16>))
    ; CHECK-NEXT: [[COPY9:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S32_S16_ag_pstm_nrm4:%[0-9]+]]:acc512, [[VLDA_UPS_S32_S16_ag_pstm_nrm5:%[0-9]+]]:ep = VLDA_UPS_S32_S16_ag_pstm_nrm [[COPY9]], [[VLDA_UPS_S32_S16_ag_pstm_nrm_imm5]], [[MOV_PD_imm10_pseudo1]], implicit-def $srups_of, implicit $crsat :: (load (<16 x s16>))
    ; CHECK-NEXT: PseudoRET implicit $lr, implicit [[VLDA_UPS_S32_S16_ag_pstm_nrm]], implicit [[VLDA_UPS_S32_S16_ag_pstm_nrm_imm]], implicit [[VLDA_UPS_S32_S16_ag_pstm_nrm2]], implicit [[VLDA_UPS_S32_S16_ag_pstm_nrm_imm2]], implicit [[VLDA_UPS_S32_S16_ag_pstm_nrm_imm4]], implicit [[VLDA_UPS_S32_S16_ag_pstm_nrm4]]
    %0:ptrregbank(p0) = COPY $p0
    %1:gprregbank(s32) = COPY $r0
    %7:modregbank(s20) = G_TRUNC %1
    %8:modregbank(s20) = G_CONSTANT i20 0
    %9:modregbank(s20) = G_CONSTANT i20 16
    %10:modregbank(s20) = G_CONSTANT i20 -256
    %11:modregbank(s20) = G_CONSTANT i20 224
    %12:modregbank(s20) = G_CONSTANT i20 256
    %25:vregbank(<16 x s16>), %19:ptrregbank(p0) = G_AIE_POSTINC_LOAD %0, %7 :: (load (<16 x s16>))
    %26:vregbank(<16 x s16>), %20:ptrregbank(p0) = G_AIE_POSTINC_LOAD %19, %8 :: (load (<16 x s16>))
    %27:vregbank(<16 x s16>), %21:ptrregbank(p0) = G_AIE_POSTINC_LOAD %20, %9 :: (load (<16 x s16>))
    %28:vregbank(<16 x s16>), %22:ptrregbank(p0) = G_AIE_POSTINC_LOAD %21, %10 :: (load (<16 x s16>))
    %29:vregbank(<16 x s16>), %23:ptrregbank(p0) = G_AIE_POSTINC_LOAD %22, %11 :: (load (<16 x s16>))
    %30:vregbank(<16 x s16>), %24:ptrregbank(p0) = G_AIE_POSTINC_LOAD %23, %12 :: (load (<16 x s16>))
    %101:gprregbank(s32) = COPY $r1
    %102:gprregbank(s32) = G_CONSTANT i32 1
    %103:accregbank(<8 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc32.v16.I256.ups), %25:vregbank(<16 x s16>), %101:gprregbank(s32), %102:gprregbank(s32)
    %104:accregbank(<8 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc32.v16.I256.ups), %26:vregbank(<16 x s16>), %101:gprregbank(s32), %102:gprregbank(s32)
    %105:accregbank(<8 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc32.v16.I256.ups), %27:vregbank(<16 x s16>), %101:gprregbank(s32), %102:gprregbank(s32)
    %106:accregbank(<8 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc32.v16.I256.ups), %28:vregbank(<16 x s16>), %101:gprregbank(s32), %102:gprregbank(s32)
    %107:accregbank(<8 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc32.v16.I256.ups), %29:vregbank(<16 x s16>), %101:gprregbank(s32), %102:gprregbank(s32)
    %108:accregbank(<8 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc32.v16.I256.ups), %30:vregbank(<16 x s16>), %101:gprregbank(s32), %102:gprregbank(s32)
    PseudoRET implicit $lr, implicit %103, implicit %104, implicit %105, implicit %106, implicit %107, implicit %108
...

---
name:            VLDA_UPS_S64_S16
legalized:       true
regBankSelected: true
tracksRegLiveness: true
body: |
  bb.0:
    liveins: $p0, $r0, $r1, $amll0
    ; CHECK-LABEL: name: VLDA_UPS_S64_S16
    ; CHECK: liveins: $p0, $r0, $r1, $amll0
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:ep = COPY $p0
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:er = COPY $r0
    ; CHECK-NEXT: [[COPY2:%[0-9]+]]:em = COPY [[COPY1]]
    ; CHECK-NEXT: [[MOV_PD_imm10_pseudo:%[0-9]+]]:em = MOV_PD_imm10_pseudo 16
    ; CHECK-NEXT: [[MOV_PD_imm10_pseudo1:%[0-9]+]]:em = MOV_PD_imm10_pseudo 256
    ; CHECK-NEXT: [[COPY3:%[0-9]+]]:er = COPY $r1
    ; CHECK-NEXT: [[COPY4:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S64_S16_ag_pstm_nrm:%[0-9]+]]:acc1024, [[VLDA_UPS_S64_S16_ag_pstm_nrm1:%[0-9]+]]:ep = VLDA_UPS_S64_S16_ag_pstm_nrm [[COPY4]], [[COPY]], [[COPY2]], implicit-def $srups_of, implicit $crsat :: (load (<16 x s16>))
    ; CHECK-NEXT: [[COPY5:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S64_S16_ag_pstm_nrm_imm:%[0-9]+]]:acc1024, [[VLDA_UPS_S64_S16_ag_pstm_nrm_imm1:%[0-9]+]]:ep = VLDA_UPS_S64_S16_ag_pstm_nrm_imm [[COPY5]], [[VLDA_UPS_S64_S16_ag_pstm_nrm1]], 0, implicit-def $srups_of, implicit $crsat :: (load (<16 x s16>))
    ; CHECK-NEXT: [[COPY6:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S64_S16_ag_pstm_nrm2:%[0-9]+]]:acc1024, [[VLDA_UPS_S64_S16_ag_pstm_nrm3:%[0-9]+]]:ep = VLDA_UPS_S64_S16_ag_pstm_nrm [[COPY6]], [[VLDA_UPS_S64_S16_ag_pstm_nrm_imm1]], [[MOV_PD_imm10_pseudo]], implicit-def $srups_of, implicit $crsat :: (load (<16 x s16>))
    ; CHECK-NEXT: [[COPY7:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S64_S16_ag_pstm_nrm_imm2:%[0-9]+]]:acc1024, [[VLDA_UPS_S64_S16_ag_pstm_nrm_imm3:%[0-9]+]]:ep = VLDA_UPS_S64_S16_ag_pstm_nrm_imm [[COPY7]], [[VLDA_UPS_S64_S16_ag_pstm_nrm3]], -256, implicit-def $srups_of, implicit $crsat :: (load (<16 x s16>))
    ; CHECK-NEXT: [[COPY8:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S64_S16_ag_pstm_nrm_imm4:%[0-9]+]]:acc1024, [[VLDA_UPS_S64_S16_ag_pstm_nrm_imm5:%[0-9]+]]:ep = VLDA_UPS_S64_S16_ag_pstm_nrm_imm [[COPY8]], [[VLDA_UPS_S64_S16_ag_pstm_nrm_imm3]], 224, implicit-def $srups_of, implicit $crsat :: (load (<16 x s16>))
    ; CHECK-NEXT: [[COPY9:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S64_S16_ag_pstm_nrm4:%[0-9]+]]:acc1024, [[VLDA_UPS_S64_S16_ag_pstm_nrm5:%[0-9]+]]:ep = VLDA_UPS_S64_S16_ag_pstm_nrm [[COPY9]], [[VLDA_UPS_S64_S16_ag_pstm_nrm_imm5]], [[MOV_PD_imm10_pseudo1]], implicit-def $srups_of, implicit $crsat :: (load (<16 x s16>))
    ; CHECK-NEXT: PseudoRET implicit $lr, implicit [[VLDA_UPS_S64_S16_ag_pstm_nrm]], implicit [[VLDA_UPS_S64_S16_ag_pstm_nrm_imm]], implicit [[VLDA_UPS_S64_S16_ag_pstm_nrm2]], implicit [[VLDA_UPS_S64_S16_ag_pstm_nrm_imm2]], implicit [[VLDA_UPS_S64_S16_ag_pstm_nrm_imm4]], implicit [[VLDA_UPS_S64_S16_ag_pstm_nrm4]]
    %0:ptrregbank(p0) = COPY $p0
    %1:gprregbank(s32) = COPY $r0
    %7:modregbank(s20) = G_TRUNC %1
    %8:modregbank(s20) = G_CONSTANT i20 0
    %9:modregbank(s20) = G_CONSTANT i20 16
    %10:modregbank(s20) = G_CONSTANT i20 -256
    %11:modregbank(s20) = G_CONSTANT i20 224
    %12:modregbank(s20) = G_CONSTANT i20 256
    %25:vregbank(<16 x s16>), %19:ptrregbank(p0) = G_AIE_POSTINC_LOAD %0, %7 :: (load (<16 x s16>))
    %26:vregbank(<16 x s16>), %20:ptrregbank(p0) = G_AIE_POSTINC_LOAD %19, %8 :: (load (<16 x s16>))
    %27:vregbank(<16 x s16>), %21:ptrregbank(p0) = G_AIE_POSTINC_LOAD %20, %9 :: (load (<16 x s16>))
    %28:vregbank(<16 x s16>), %22:ptrregbank(p0) = G_AIE_POSTINC_LOAD %21, %10 :: (load (<16 x s16>))
    %29:vregbank(<16 x s16>), %23:ptrregbank(p0) = G_AIE_POSTINC_LOAD %22, %11 :: (load (<16 x s16>))
    %30:vregbank(<16 x s16>), %24:ptrregbank(p0) = G_AIE_POSTINC_LOAD %23, %12 :: (load (<16 x s16>))
    %101:gprregbank(s32) = COPY $r1
    %102:gprregbank(s32) = G_CONSTANT i32 1
    %103:accregbank(<16 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc64.v16.I256.ups), %25:vregbank(<16 x s16>), %101:gprregbank(s32), %102:gprregbank(s32)
    %104:accregbank(<16 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc64.v16.I256.ups), %26:vregbank(<16 x s16>), %101:gprregbank(s32), %102:gprregbank(s32)
    %105:accregbank(<16 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc64.v16.I256.ups), %27:vregbank(<16 x s16>), %101:gprregbank(s32), %102:gprregbank(s32)
    %106:accregbank(<16 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc64.v16.I256.ups), %28:vregbank(<16 x s16>), %101:gprregbank(s32), %102:gprregbank(s32)
    %107:accregbank(<16 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc64.v16.I256.ups), %29:vregbank(<16 x s16>), %101:gprregbank(s32), %102:gprregbank(s32)
    %108:accregbank(<16 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc64.v16.I256.ups), %30:vregbank(<16 x s16>), %101:gprregbank(s32), %102:gprregbank(s32)
    PseudoRET implicit $lr, implicit %103, implicit %104, implicit %105, implicit %106, implicit %107, implicit %108
...

---
name:            VLDA_UPS_S32_S8
legalized:       true
regBankSelected: true
tracksRegLiveness: true
body: |
  bb.0:
    liveins: $p0, $r0, $r1, $amll0
    ; CHECK-LABEL: name: VLDA_UPS_S32_S8
    ; CHECK: liveins: $p0, $r0, $r1, $amll0
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:ep = COPY $p0
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:er = COPY $r0
    ; CHECK-NEXT: [[COPY2:%[0-9]+]]:em = COPY [[COPY1]]
    ; CHECK-NEXT: [[MOV_PD_imm10_pseudo:%[0-9]+]]:em = MOV_PD_imm10_pseudo 16
    ; CHECK-NEXT: [[MOV_PD_imm10_pseudo1:%[0-9]+]]:em = MOV_PD_imm10_pseudo 256
    ; CHECK-NEXT: [[COPY3:%[0-9]+]]:er = COPY $r1
    ; CHECK-NEXT: [[COPY4:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S32_S8_ag_pstm_nrm:%[0-9]+]]:acc1024, [[VLDA_UPS_S32_S8_ag_pstm_nrm1:%[0-9]+]]:ep = VLDA_UPS_S32_S8_ag_pstm_nrm [[COPY4]], [[COPY]], [[COPY2]], implicit-def $srups_of, implicit $crsat :: (load (<8 x s32>))
    ; CHECK-NEXT: [[COPY5:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S32_S8_ag_pstm_nrm_imm:%[0-9]+]]:acc1024, [[VLDA_UPS_S32_S8_ag_pstm_nrm_imm1:%[0-9]+]]:ep = VLDA_UPS_S32_S8_ag_pstm_nrm_imm [[COPY5]], [[VLDA_UPS_S32_S8_ag_pstm_nrm1]], 0, implicit-def $srups_of, implicit $crsat :: (load (<8 x s32>))
    ; CHECK-NEXT: [[COPY6:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S32_S8_ag_pstm_nrm2:%[0-9]+]]:acc1024, [[VLDA_UPS_S32_S8_ag_pstm_nrm3:%[0-9]+]]:ep = VLDA_UPS_S32_S8_ag_pstm_nrm [[COPY6]], [[VLDA_UPS_S32_S8_ag_pstm_nrm_imm1]], [[MOV_PD_imm10_pseudo]], implicit-def $srups_of, implicit $crsat :: (load (<8 x s32>))
    ; CHECK-NEXT: [[COPY7:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S32_S8_ag_pstm_nrm_imm2:%[0-9]+]]:acc1024, [[VLDA_UPS_S32_S8_ag_pstm_nrm_imm3:%[0-9]+]]:ep = VLDA_UPS_S32_S8_ag_pstm_nrm_imm [[COPY7]], [[VLDA_UPS_S32_S8_ag_pstm_nrm3]], -256, implicit-def $srups_of, implicit $crsat :: (load (<8 x s32>))
    ; CHECK-NEXT: [[COPY8:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S32_S8_ag_pstm_nrm_imm4:%[0-9]+]]:acc1024, [[VLDA_UPS_S32_S8_ag_pstm_nrm_imm5:%[0-9]+]]:ep = VLDA_UPS_S32_S8_ag_pstm_nrm_imm [[COPY8]], [[VLDA_UPS_S32_S8_ag_pstm_nrm_imm3]], 224, implicit-def $srups_of, implicit $crsat :: (load (<8 x s32>))
    ; CHECK-NEXT: [[COPY9:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S32_S8_ag_pstm_nrm4:%[0-9]+]]:acc1024, [[VLDA_UPS_S32_S8_ag_pstm_nrm5:%[0-9]+]]:ep = VLDA_UPS_S32_S8_ag_pstm_nrm [[COPY9]], [[VLDA_UPS_S32_S8_ag_pstm_nrm_imm5]], [[MOV_PD_imm10_pseudo1]], implicit-def $srups_of, implicit $crsat :: (load (<8 x s32>))
    ; CHECK-NEXT: PseudoRET implicit $lr, implicit [[VLDA_UPS_S32_S8_ag_pstm_nrm]], implicit [[VLDA_UPS_S32_S8_ag_pstm_nrm_imm]], implicit [[VLDA_UPS_S32_S8_ag_pstm_nrm2]], implicit [[VLDA_UPS_S32_S8_ag_pstm_nrm_imm2]], implicit [[VLDA_UPS_S32_S8_ag_pstm_nrm_imm4]], implicit [[VLDA_UPS_S32_S8_ag_pstm_nrm4]]
    %0:ptrregbank(p0) = COPY $p0
    %1:gprregbank(s32) = COPY $r0
    %7:modregbank(s20) = G_TRUNC %1
    %8:modregbank(s20) = G_CONSTANT i20 0
    %9:modregbank(s20) = G_CONSTANT i20 16
    %10:modregbank(s20) = G_CONSTANT i20 -256
    %11:modregbank(s20) = G_CONSTANT i20 224
    %12:modregbank(s20) = G_CONSTANT i20 256
    %25:vregbank(<8 x s32>), %19:ptrregbank(p0) = G_AIE_POSTINC_LOAD %0, %7 :: (load (<8 x s32>))
    %26:vregbank(<8 x s32>), %20:ptrregbank(p0) = G_AIE_POSTINC_LOAD %19, %8 :: (load (<8 x s32>))
    %27:vregbank(<8 x s32>), %21:ptrregbank(p0) = G_AIE_POSTINC_LOAD %20, %9 :: (load (<8 x s32>))
    %28:vregbank(<8 x s32>), %22:ptrregbank(p0) = G_AIE_POSTINC_LOAD %21, %10 :: (load (<8 x s32>))
    %29:vregbank(<8 x s32>), %23:ptrregbank(p0) = G_AIE_POSTINC_LOAD %22, %11 :: (load (<8 x s32>))
    %30:vregbank(<8 x s32>), %24:ptrregbank(p0) = G_AIE_POSTINC_LOAD %23, %12 :: (load (<8 x s32>))
    %101:gprregbank(s32) = COPY $r1
    %102:gprregbank(s32) = G_CONSTANT i32 1
    %103:accregbank(<16 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc32.v32.I256.ups), %25:vregbank(<8 x s32>), %101:gprregbank(s32), %102:gprregbank(s32)
    %104:accregbank(<16 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc32.v32.I256.ups), %26:vregbank(<8 x s32>), %101:gprregbank(s32), %102:gprregbank(s32)
    %105:accregbank(<16 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc32.v32.I256.ups), %27:vregbank(<8 x s32>), %101:gprregbank(s32), %102:gprregbank(s32)
    %106:accregbank(<16 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc32.v32.I256.ups), %28:vregbank(<8 x s32>), %101:gprregbank(s32), %102:gprregbank(s32)
    %107:accregbank(<16 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc32.v32.I256.ups), %29:vregbank(<8 x s32>), %101:gprregbank(s32), %102:gprregbank(s32)
    %108:accregbank(<16 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc32.v32.I256.ups), %30:vregbank(<8 x s32>), %101:gprregbank(s32), %102:gprregbank(s32)
    PseudoRET implicit $lr, implicit %103, implicit %104, implicit %105, implicit %106, implicit %107, implicit %108
...

---
name:            VLDA_UPS_S64_S32
legalized:       true
regBankSelected: true
tracksRegLiveness: true
body: |
  bb.0:
    liveins: $p0, $r0, $r1, $amll0
    ; CHECK-LABEL: name: VLDA_UPS_S64_S32
    ; CHECK: liveins: $p0, $r0, $r1, $amll0
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:ep = COPY $p0
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:er = COPY $r0
    ; CHECK-NEXT: [[COPY2:%[0-9]+]]:em = COPY [[COPY1]]
    ; CHECK-NEXT: [[MOV_PD_imm10_pseudo:%[0-9]+]]:em = MOV_PD_imm10_pseudo 16
    ; CHECK-NEXT: [[MOV_PD_imm10_pseudo1:%[0-9]+]]:em = MOV_PD_imm10_pseudo 256
    ; CHECK-NEXT: [[COPY3:%[0-9]+]]:er = COPY $r1
    ; CHECK-NEXT: [[COPY4:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S64_S32_ag_pstm_nrm:%[0-9]+]]:acc512, [[VLDA_UPS_S64_S32_ag_pstm_nrm1:%[0-9]+]]:ep = VLDA_UPS_S64_S32_ag_pstm_nrm [[COPY4]], [[COPY]], [[COPY2]], implicit-def $srups_of, implicit $crsat :: (load (<8 x s32>))
    ; CHECK-NEXT: [[COPY5:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S64_S32_ag_pstm_nrm_imm:%[0-9]+]]:acc512, [[VLDA_UPS_S64_S32_ag_pstm_nrm_imm1:%[0-9]+]]:ep = VLDA_UPS_S64_S32_ag_pstm_nrm_imm [[COPY5]], [[VLDA_UPS_S64_S32_ag_pstm_nrm1]], 0, implicit-def $srups_of, implicit $crsat :: (load (<8 x s32>))
    ; CHECK-NEXT: [[COPY6:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S64_S32_ag_pstm_nrm2:%[0-9]+]]:acc512, [[VLDA_UPS_S64_S32_ag_pstm_nrm3:%[0-9]+]]:ep = VLDA_UPS_S64_S32_ag_pstm_nrm [[COPY6]], [[VLDA_UPS_S64_S32_ag_pstm_nrm_imm1]], [[MOV_PD_imm10_pseudo]], implicit-def $srups_of, implicit $crsat :: (load (<8 x s32>))
    ; CHECK-NEXT: [[COPY7:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S64_S32_ag_pstm_nrm_imm2:%[0-9]+]]:acc512, [[VLDA_UPS_S64_S32_ag_pstm_nrm_imm3:%[0-9]+]]:ep = VLDA_UPS_S64_S32_ag_pstm_nrm_imm [[COPY7]], [[VLDA_UPS_S64_S32_ag_pstm_nrm3]], -256, implicit-def $srups_of, implicit $crsat :: (load (<8 x s32>))
    ; CHECK-NEXT: [[COPY8:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S64_S32_ag_pstm_nrm_imm4:%[0-9]+]]:acc512, [[VLDA_UPS_S64_S32_ag_pstm_nrm_imm5:%[0-9]+]]:ep = VLDA_UPS_S64_S32_ag_pstm_nrm_imm [[COPY8]], [[VLDA_UPS_S64_S32_ag_pstm_nrm_imm3]], 224, implicit-def $srups_of, implicit $crsat :: (load (<8 x s32>))
    ; CHECK-NEXT: [[COPY9:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S64_S32_ag_pstm_nrm4:%[0-9]+]]:acc512, [[VLDA_UPS_S64_S32_ag_pstm_nrm5:%[0-9]+]]:ep = VLDA_UPS_S64_S32_ag_pstm_nrm [[COPY9]], [[VLDA_UPS_S64_S32_ag_pstm_nrm_imm5]], [[MOV_PD_imm10_pseudo1]], implicit-def $srups_of, implicit $crsat :: (load (<8 x s32>))
    ; CHECK-NEXT: PseudoRET implicit $lr, implicit [[VLDA_UPS_S64_S32_ag_pstm_nrm]], implicit [[VLDA_UPS_S64_S32_ag_pstm_nrm_imm]], implicit [[VLDA_UPS_S64_S32_ag_pstm_nrm2]], implicit [[VLDA_UPS_S64_S32_ag_pstm_nrm_imm2]], implicit [[VLDA_UPS_S64_S32_ag_pstm_nrm_imm4]], implicit [[VLDA_UPS_S64_S32_ag_pstm_nrm4]]
    %0:ptrregbank(p0) = COPY $p0
    %1:gprregbank(s32) = COPY $r0
    %7:modregbank(s20) = G_TRUNC %1
    %8:modregbank(s20) = G_CONSTANT i20 0
    %9:modregbank(s20) = G_CONSTANT i20 16
    %10:modregbank(s20) = G_CONSTANT i20 -256
    %11:modregbank(s20) = G_CONSTANT i20 224
    %12:modregbank(s20) = G_CONSTANT i20 256
    %25:vregbank(<8 x s32>), %19:ptrregbank(p0) = G_AIE_POSTINC_LOAD %0, %7 :: (load (<8 x s32>))
    %26:vregbank(<8 x s32>), %20:ptrregbank(p0) = G_AIE_POSTINC_LOAD %19, %8 :: (load (<8 x s32>))
    %27:vregbank(<8 x s32>), %21:ptrregbank(p0) = G_AIE_POSTINC_LOAD %20, %9 :: (load (<8 x s32>))
    %28:vregbank(<8 x s32>), %22:ptrregbank(p0) = G_AIE_POSTINC_LOAD %21, %10 :: (load (<8 x s32>))
    %29:vregbank(<8 x s32>), %23:ptrregbank(p0) = G_AIE_POSTINC_LOAD %22, %11 :: (load (<8 x s32>))
    %30:vregbank(<8 x s32>), %24:ptrregbank(p0) = G_AIE_POSTINC_LOAD %23, %12 :: (load (<8 x s32>))
    %101:gprregbank(s32) = COPY $r1
    %102:gprregbank(s32) = G_CONSTANT i32 1
    %103:accregbank(<8 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc64.v8.I256.ups), %25:vregbank(<8 x s32>), %101:gprregbank(s32), %102:gprregbank(s32)
    %104:accregbank(<8 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc64.v8.I256.ups), %26:vregbank(<8 x s32>), %101:gprregbank(s32), %102:gprregbank(s32)
    %105:accregbank(<8 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc64.v8.I256.ups), %27:vregbank(<8 x s32>), %101:gprregbank(s32), %102:gprregbank(s32)
    %106:accregbank(<8 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc64.v8.I256.ups), %28:vregbank(<8 x s32>), %101:gprregbank(s32), %102:gprregbank(s32)
    %107:accregbank(<8 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc64.v8.I256.ups), %29:vregbank(<8 x s32>), %101:gprregbank(s32), %102:gprregbank(s32)
    %108:accregbank(<8 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc64.v8.I256.ups), %30:vregbank(<8 x s32>), %101:gprregbank(s32), %102:gprregbank(s32)
    PseudoRET implicit $lr, implicit %103, implicit %104, implicit %105, implicit %106, implicit %107, implicit %108
...

---
name:            VLDA_UPS_S32_D16
legalized:       true
regBankSelected: true
tracksRegLiveness: true
body: |
  bb.0:
    liveins: $p0, $r0, $r1, $amll0
    ; CHECK-LABEL: name: VLDA_UPS_S32_D16
    ; CHECK: liveins: $p0, $r0, $r1, $amll0
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:ep = COPY $p0
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:er = COPY $r0
    ; CHECK-NEXT: [[COPY2:%[0-9]+]]:em = COPY [[COPY1]]
    ; CHECK-NEXT: [[MOV_PD_imm10_pseudo:%[0-9]+]]:em = MOV_PD_imm10_pseudo 16
    ; CHECK-NEXT: [[MOV_PD_imm10_pseudo1:%[0-9]+]]:em = MOV_PD_imm10_pseudo 256
    ; CHECK-NEXT: [[COPY3:%[0-9]+]]:er = COPY $r1
    ; CHECK-NEXT: [[COPY4:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S32_D16_ag_pstm_nrm:%[0-9]+]]:acc512, [[VLDA_UPS_S32_D16_ag_pstm_nrm1:%[0-9]+]]:ep = VLDA_UPS_S32_D16_ag_pstm_nrm [[COPY4]], [[COPY]], [[COPY2]], implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<16 x s16>))
    ; CHECK-NEXT: [[COPY5:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S32_D16_ag_pstm_nrm_imm:%[0-9]+]]:acc512, [[VLDA_UPS_S32_D16_ag_pstm_nrm_imm1:%[0-9]+]]:ep = VLDA_UPS_S32_D16_ag_pstm_nrm_imm [[COPY5]], [[VLDA_UPS_S32_D16_ag_pstm_nrm1]], 0, implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<16 x s16>))
    ; CHECK-NEXT: [[COPY6:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S32_D16_ag_pstm_nrm2:%[0-9]+]]:acc512, [[VLDA_UPS_S32_D16_ag_pstm_nrm3:%[0-9]+]]:ep = VLDA_UPS_S32_D16_ag_pstm_nrm [[COPY6]], [[VLDA_UPS_S32_D16_ag_pstm_nrm_imm1]], [[MOV_PD_imm10_pseudo]], implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<16 x s16>))
    ; CHECK-NEXT: [[COPY7:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S32_D16_ag_pstm_nrm_imm2:%[0-9]+]]:acc512, [[VLDA_UPS_S32_D16_ag_pstm_nrm_imm3:%[0-9]+]]:ep = VLDA_UPS_S32_D16_ag_pstm_nrm_imm [[COPY7]], [[VLDA_UPS_S32_D16_ag_pstm_nrm3]], -256, implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<16 x s16>))
    ; CHECK-NEXT: [[COPY8:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S32_D16_ag_pstm_nrm_imm4:%[0-9]+]]:acc512, [[VLDA_UPS_S32_D16_ag_pstm_nrm_imm5:%[0-9]+]]:ep = VLDA_UPS_S32_D16_ag_pstm_nrm_imm [[COPY8]], [[VLDA_UPS_S32_D16_ag_pstm_nrm_imm3]], 224, implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<16 x s16>))
    ; CHECK-NEXT: [[COPY9:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S32_D16_ag_pstm_nrm4:%[0-9]+]]:acc512, [[VLDA_UPS_S32_D16_ag_pstm_nrm5:%[0-9]+]]:ep = VLDA_UPS_S32_D16_ag_pstm_nrm [[COPY9]], [[VLDA_UPS_S32_D16_ag_pstm_nrm_imm5]], [[MOV_PD_imm10_pseudo1]], implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<16 x s16>))
    ; CHECK-NEXT: PseudoRET implicit $lr, implicit [[VLDA_UPS_S32_D16_ag_pstm_nrm]], implicit [[VLDA_UPS_S32_D16_ag_pstm_nrm_imm]], implicit [[VLDA_UPS_S32_D16_ag_pstm_nrm2]], implicit [[VLDA_UPS_S32_D16_ag_pstm_nrm_imm2]], implicit [[VLDA_UPS_S32_D16_ag_pstm_nrm_imm4]], implicit [[VLDA_UPS_S32_D16_ag_pstm_nrm4]]
    %0:ptrregbank(p0) = COPY $p0
    %1:gprregbank(s32) = COPY $r0
    %7:modregbank(s20) = G_TRUNC %1
    %8:modregbank(s20) = G_CONSTANT i20 0
    %9:modregbank(s20) = G_CONSTANT i20 16
    %10:modregbank(s20) = G_CONSTANT i20 -256
    %11:modregbank(s20) = G_CONSTANT i20 224
    %12:modregbank(s20) = G_CONSTANT i20 256
    %25:vregbank(<16 x s16>), %19:ptrregbank(p0) = G_AIE_POSTINC_LOAD %0, %7 :: (load (<16 x s16>))
    %26:vregbank(<16 x s16>), %20:ptrregbank(p0) = G_AIE_POSTINC_LOAD %19, %8 :: (load (<16 x s16>))
    %27:vregbank(<16 x s16>), %21:ptrregbank(p0) = G_AIE_POSTINC_LOAD %20, %9 :: (load (<16 x s16>))
    %28:vregbank(<16 x s16>), %22:ptrregbank(p0) = G_AIE_POSTINC_LOAD %21, %10 :: (load (<16 x s16>))
    %29:vregbank(<16 x s16>), %23:ptrregbank(p0) = G_AIE_POSTINC_LOAD %22, %11 :: (load (<16 x s16>))
    %30:vregbank(<16 x s16>), %24:ptrregbank(p0) = G_AIE_POSTINC_LOAD %23, %12 :: (load (<16 x s16>))
    %101:gprregbank(s32) = COPY $r1
    %102:gprregbank(s32) = G_CONSTANT i32 0
    %103:accregbank(<8 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc32.v16.I256.ups), %25:vregbank(<16 x s16>), %101:gprregbank(s32), %102:gprregbank(s32)
    %104:accregbank(<8 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc32.v16.I256.ups), %26:vregbank(<16 x s16>), %101:gprregbank(s32), %102:gprregbank(s32)
    %105:accregbank(<8 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc32.v16.I256.ups), %27:vregbank(<16 x s16>), %101:gprregbank(s32), %102:gprregbank(s32)
    %106:accregbank(<8 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc32.v16.I256.ups), %28:vregbank(<16 x s16>), %101:gprregbank(s32), %102:gprregbank(s32)
    %107:accregbank(<8 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc32.v16.I256.ups), %29:vregbank(<16 x s16>), %101:gprregbank(s32), %102:gprregbank(s32)
    %108:accregbank(<8 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc32.v16.I256.ups), %30:vregbank(<16 x s16>), %101:gprregbank(s32), %102:gprregbank(s32)
    PseudoRET implicit $lr, implicit %103, implicit %104, implicit %105, implicit %106, implicit %107, implicit %108
...

---
name:            VLDA_UPS_S64_D16
legalized:       true
regBankSelected: true
tracksRegLiveness: true
body: |
  bb.0:
    liveins: $p0, $r0, $r1, $amll0
    ; CHECK-LABEL: name: VLDA_UPS_S64_D16
    ; CHECK: liveins: $p0, $r0, $r1, $amll0
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:ep = COPY $p0
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:er = COPY $r0
    ; CHECK-NEXT: [[COPY2:%[0-9]+]]:em = COPY [[COPY1]]
    ; CHECK-NEXT: [[MOV_PD_imm10_pseudo:%[0-9]+]]:em = MOV_PD_imm10_pseudo 16
    ; CHECK-NEXT: [[MOV_PD_imm10_pseudo1:%[0-9]+]]:em = MOV_PD_imm10_pseudo 256
    ; CHECK-NEXT: [[COPY3:%[0-9]+]]:er = COPY $r1
    ; CHECK-NEXT: [[COPY4:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S64_D16_ag_pstm_nrm:%[0-9]+]]:acc1024, [[VLDA_UPS_S64_D16_ag_pstm_nrm1:%[0-9]+]]:ep = VLDA_UPS_S64_D16_ag_pstm_nrm [[COPY4]], [[COPY]], [[COPY2]], implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<16 x s16>))
    ; CHECK-NEXT: [[COPY5:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S64_D16_ag_pstm_nrm_imm:%[0-9]+]]:acc1024, [[VLDA_UPS_S64_D16_ag_pstm_nrm_imm1:%[0-9]+]]:ep = VLDA_UPS_S64_D16_ag_pstm_nrm_imm [[COPY5]], [[VLDA_UPS_S64_D16_ag_pstm_nrm1]], 0, implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<16 x s16>))
    ; CHECK-NEXT: [[COPY6:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S64_D16_ag_pstm_nrm2:%[0-9]+]]:acc1024, [[VLDA_UPS_S64_D16_ag_pstm_nrm3:%[0-9]+]]:ep = VLDA_UPS_S64_D16_ag_pstm_nrm [[COPY6]], [[VLDA_UPS_S64_D16_ag_pstm_nrm_imm1]], [[MOV_PD_imm10_pseudo]], implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<16 x s16>))
    ; CHECK-NEXT: [[COPY7:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S64_D16_ag_pstm_nrm_imm2:%[0-9]+]]:acc1024, [[VLDA_UPS_S64_D16_ag_pstm_nrm_imm3:%[0-9]+]]:ep = VLDA_UPS_S64_D16_ag_pstm_nrm_imm [[COPY7]], [[VLDA_UPS_S64_D16_ag_pstm_nrm3]], -256, implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<16 x s16>))
    ; CHECK-NEXT: [[COPY8:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S64_D16_ag_pstm_nrm_imm4:%[0-9]+]]:acc1024, [[VLDA_UPS_S64_D16_ag_pstm_nrm_imm5:%[0-9]+]]:ep = VLDA_UPS_S64_D16_ag_pstm_nrm_imm [[COPY8]], [[VLDA_UPS_S64_D16_ag_pstm_nrm_imm3]], 224, implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<16 x s16>))
    ; CHECK-NEXT: [[COPY9:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S64_D16_ag_pstm_nrm4:%[0-9]+]]:acc1024, [[VLDA_UPS_S64_D16_ag_pstm_nrm5:%[0-9]+]]:ep = VLDA_UPS_S64_D16_ag_pstm_nrm [[COPY9]], [[VLDA_UPS_S64_D16_ag_pstm_nrm_imm5]], [[MOV_PD_imm10_pseudo1]], implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<16 x s16>))
    ; CHECK-NEXT: PseudoRET implicit $lr, implicit [[VLDA_UPS_S64_D16_ag_pstm_nrm]], implicit [[VLDA_UPS_S64_D16_ag_pstm_nrm_imm]], implicit [[VLDA_UPS_S64_D16_ag_pstm_nrm2]], implicit [[VLDA_UPS_S64_D16_ag_pstm_nrm_imm2]], implicit [[VLDA_UPS_S64_D16_ag_pstm_nrm_imm4]], implicit [[VLDA_UPS_S64_D16_ag_pstm_nrm4]]
    %0:ptrregbank(p0) = COPY $p0
    %1:gprregbank(s32) = COPY $r0
    %7:modregbank(s20) = G_TRUNC %1
    %8:modregbank(s20) = G_CONSTANT i20 0
    %9:modregbank(s20) = G_CONSTANT i20 16
    %10:modregbank(s20) = G_CONSTANT i20 -256
    %11:modregbank(s20) = G_CONSTANT i20 224
    %12:modregbank(s20) = G_CONSTANT i20 256
    %25:vregbank(<16 x s16>), %19:ptrregbank(p0) = G_AIE_POSTINC_LOAD %0, %7 :: (load (<16 x s16>))
    %26:vregbank(<16 x s16>), %20:ptrregbank(p0) = G_AIE_POSTINC_LOAD %19, %8 :: (load (<16 x s16>))
    %27:vregbank(<16 x s16>), %21:ptrregbank(p0) = G_AIE_POSTINC_LOAD %20, %9 :: (load (<16 x s16>))
    %28:vregbank(<16 x s16>), %22:ptrregbank(p0) = G_AIE_POSTINC_LOAD %21, %10 :: (load (<16 x s16>))
    %29:vregbank(<16 x s16>), %23:ptrregbank(p0) = G_AIE_POSTINC_LOAD %22, %11 :: (load (<16 x s16>))
    %30:vregbank(<16 x s16>), %24:ptrregbank(p0) = G_AIE_POSTINC_LOAD %23, %12 :: (load (<16 x s16>))
    %101:gprregbank(s32) = COPY $r1
    %102:gprregbank(s32) = G_CONSTANT i32 0
    %103:accregbank(<16 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc64.v16.I256.ups), %25:vregbank(<16 x s16>), %101:gprregbank(s32), %102:gprregbank(s32)
    %104:accregbank(<16 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc64.v16.I256.ups), %26:vregbank(<16 x s16>), %101:gprregbank(s32), %102:gprregbank(s32)
    %105:accregbank(<16 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc64.v16.I256.ups), %27:vregbank(<16 x s16>), %101:gprregbank(s32), %102:gprregbank(s32)
    %106:accregbank(<16 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc64.v16.I256.ups), %28:vregbank(<16 x s16>), %101:gprregbank(s32), %102:gprregbank(s32)
    %107:accregbank(<16 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc64.v16.I256.ups), %29:vregbank(<16 x s16>), %101:gprregbank(s32), %102:gprregbank(s32)
    %108:accregbank(<16 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc64.v16.I256.ups), %30:vregbank(<16 x s16>), %101:gprregbank(s32), %102:gprregbank(s32)
    PseudoRET implicit $lr, implicit %103, implicit %104, implicit %105, implicit %106, implicit %107, implicit %108
...

---
name:            VLDA_UPS_S32_D8
legalized:       true
regBankSelected: true
tracksRegLiveness: true
body: |
  bb.0:
    liveins: $p0, $r0, $r1, $amll0
    ; CHECK-LABEL: name: VLDA_UPS_S32_D8
    ; CHECK: liveins: $p0, $r0, $r1, $amll0
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:ep = COPY $p0
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:er = COPY $r0
    ; CHECK-NEXT: [[COPY2:%[0-9]+]]:em = COPY [[COPY1]]
    ; CHECK-NEXT: [[MOV_PD_imm10_pseudo:%[0-9]+]]:em = MOV_PD_imm10_pseudo 16
    ; CHECK-NEXT: [[MOV_PD_imm10_pseudo1:%[0-9]+]]:em = MOV_PD_imm10_pseudo 256
    ; CHECK-NEXT: [[COPY3:%[0-9]+]]:er = COPY $r1
    ; CHECK-NEXT: [[COPY4:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S32_D8_ag_pstm_nrm:%[0-9]+]]:acc1024, [[VLDA_UPS_S32_D8_ag_pstm_nrm1:%[0-9]+]]:ep = VLDA_UPS_S32_D8_ag_pstm_nrm [[COPY4]], [[COPY]], [[COPY2]], implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<8 x s32>))
    ; CHECK-NEXT: [[COPY5:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S32_D8_ag_pstm_nrm_imm:%[0-9]+]]:acc1024, [[VLDA_UPS_S32_D8_ag_pstm_nrm_imm1:%[0-9]+]]:ep = VLDA_UPS_S32_D8_ag_pstm_nrm_imm [[COPY5]], [[VLDA_UPS_S32_D8_ag_pstm_nrm1]], 0, implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<8 x s32>))
    ; CHECK-NEXT: [[COPY6:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S32_D8_ag_pstm_nrm2:%[0-9]+]]:acc1024, [[VLDA_UPS_S32_D8_ag_pstm_nrm3:%[0-9]+]]:ep = VLDA_UPS_S32_D8_ag_pstm_nrm [[COPY6]], [[VLDA_UPS_S32_D8_ag_pstm_nrm_imm1]], [[MOV_PD_imm10_pseudo]], implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<8 x s32>))
    ; CHECK-NEXT: [[COPY7:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S32_D8_ag_pstm_nrm_imm2:%[0-9]+]]:acc1024, [[VLDA_UPS_S32_D8_ag_pstm_nrm_imm3:%[0-9]+]]:ep = VLDA_UPS_S32_D8_ag_pstm_nrm_imm [[COPY7]], [[VLDA_UPS_S32_D8_ag_pstm_nrm3]], -256, implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<8 x s32>))
    ; CHECK-NEXT: [[COPY8:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S32_D8_ag_pstm_nrm_imm4:%[0-9]+]]:acc1024, [[VLDA_UPS_S32_D8_ag_pstm_nrm_imm5:%[0-9]+]]:ep = VLDA_UPS_S32_D8_ag_pstm_nrm_imm [[COPY8]], [[VLDA_UPS_S32_D8_ag_pstm_nrm_imm3]], 224, implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<8 x s32>))
    ; CHECK-NEXT: [[COPY9:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S32_D8_ag_pstm_nrm4:%[0-9]+]]:acc1024, [[VLDA_UPS_S32_D8_ag_pstm_nrm5:%[0-9]+]]:ep = VLDA_UPS_S32_D8_ag_pstm_nrm [[COPY9]], [[VLDA_UPS_S32_D8_ag_pstm_nrm_imm5]], [[MOV_PD_imm10_pseudo1]], implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<8 x s32>))
    ; CHECK-NEXT: PseudoRET implicit $lr, implicit [[VLDA_UPS_S32_D8_ag_pstm_nrm]], implicit [[VLDA_UPS_S32_D8_ag_pstm_nrm_imm]], implicit [[VLDA_UPS_S32_D8_ag_pstm_nrm2]], implicit [[VLDA_UPS_S32_D8_ag_pstm_nrm_imm2]], implicit [[VLDA_UPS_S32_D8_ag_pstm_nrm_imm4]], implicit [[VLDA_UPS_S32_D8_ag_pstm_nrm4]]
    %0:ptrregbank(p0) = COPY $p0
    %1:gprregbank(s32) = COPY $r0
    %7:modregbank(s20) = G_TRUNC %1
    %8:modregbank(s20) = G_CONSTANT i20 0
    %9:modregbank(s20) = G_CONSTANT i20 16
    %10:modregbank(s20) = G_CONSTANT i20 -256
    %11:modregbank(s20) = G_CONSTANT i20 224
    %12:modregbank(s20) = G_CONSTANT i20 256
    %25:vregbank(<8 x s32>), %19:ptrregbank(p0) = G_AIE_POSTINC_LOAD %0, %7 :: (load (<8 x s32>))
    %26:vregbank(<8 x s32>), %20:ptrregbank(p0) = G_AIE_POSTINC_LOAD %19, %8 :: (load (<8 x s32>))
    %27:vregbank(<8 x s32>), %21:ptrregbank(p0) = G_AIE_POSTINC_LOAD %20, %9 :: (load (<8 x s32>))
    %28:vregbank(<8 x s32>), %22:ptrregbank(p0) = G_AIE_POSTINC_LOAD %21, %10 :: (load (<8 x s32>))
    %29:vregbank(<8 x s32>), %23:ptrregbank(p0) = G_AIE_POSTINC_LOAD %22, %11 :: (load (<8 x s32>))
    %30:vregbank(<8 x s32>), %24:ptrregbank(p0) = G_AIE_POSTINC_LOAD %23, %12 :: (load (<8 x s32>))
    %101:gprregbank(s32) = COPY $r1
    %102:gprregbank(s32) = G_CONSTANT i32 0
    %103:accregbank(<16 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc32.v32.I256.ups), %25:vregbank(<8 x s32>), %101:gprregbank(s32), %102:gprregbank(s32)
    %104:accregbank(<16 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc32.v32.I256.ups), %26:vregbank(<8 x s32>), %101:gprregbank(s32), %102:gprregbank(s32)
    %105:accregbank(<16 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc32.v32.I256.ups), %27:vregbank(<8 x s32>), %101:gprregbank(s32), %102:gprregbank(s32)
    %106:accregbank(<16 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc32.v32.I256.ups), %28:vregbank(<8 x s32>), %101:gprregbank(s32), %102:gprregbank(s32)
    %107:accregbank(<16 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc32.v32.I256.ups), %29:vregbank(<8 x s32>), %101:gprregbank(s32), %102:gprregbank(s32)
    %108:accregbank(<16 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc32.v32.I256.ups), %30:vregbank(<8 x s32>), %101:gprregbank(s32), %102:gprregbank(s32)
    PseudoRET implicit $lr, implicit %103, implicit %104, implicit %105, implicit %106, implicit %107, implicit %108
...

---
name:            VLDA_UPS_S64_D32
legalized:       true
regBankSelected: true
tracksRegLiveness: true
body: |
  bb.0:
    liveins: $p0, $r0, $r1, $amll0
    ; CHECK-LABEL: name: VLDA_UPS_S64_D32
    ; CHECK: liveins: $p0, $r0, $r1, $amll0
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:ep = COPY $p0
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:er = COPY $r0
    ; CHECK-NEXT: [[COPY2:%[0-9]+]]:em = COPY [[COPY1]]
    ; CHECK-NEXT: [[MOV_PD_imm10_pseudo:%[0-9]+]]:em = MOV_PD_imm10_pseudo 16
    ; CHECK-NEXT: [[MOV_PD_imm10_pseudo1:%[0-9]+]]:em = MOV_PD_imm10_pseudo 256
    ; CHECK-NEXT: [[COPY3:%[0-9]+]]:er = COPY $r1
    ; CHECK-NEXT: [[COPY4:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S64_D32_ag_pstm_nrm:%[0-9]+]]:acc512, [[VLDA_UPS_S64_D32_ag_pstm_nrm1:%[0-9]+]]:ep = VLDA_UPS_S64_D32_ag_pstm_nrm [[COPY4]], [[COPY]], [[COPY2]], implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<8 x s32>))
    ; CHECK-NEXT: [[COPY5:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S64_D32_ag_pstm_nrm_imm:%[0-9]+]]:acc512, [[VLDA_UPS_S64_D32_ag_pstm_nrm_imm1:%[0-9]+]]:ep = VLDA_UPS_S64_D32_ag_pstm_nrm_imm [[COPY5]], [[VLDA_UPS_S64_D32_ag_pstm_nrm1]], 0, implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<8 x s32>))
    ; CHECK-NEXT: [[COPY6:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S64_D32_ag_pstm_nrm2:%[0-9]+]]:acc512, [[VLDA_UPS_S64_D32_ag_pstm_nrm3:%[0-9]+]]:ep = VLDA_UPS_S64_D32_ag_pstm_nrm [[COPY6]], [[VLDA_UPS_S64_D32_ag_pstm_nrm_imm1]], [[MOV_PD_imm10_pseudo]], implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<8 x s32>))
    ; CHECK-NEXT: [[COPY7:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S64_D32_ag_pstm_nrm_imm2:%[0-9]+]]:acc512, [[VLDA_UPS_S64_D32_ag_pstm_nrm_imm3:%[0-9]+]]:ep = VLDA_UPS_S64_D32_ag_pstm_nrm_imm [[COPY7]], [[VLDA_UPS_S64_D32_ag_pstm_nrm3]], -256, implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<8 x s32>))
    ; CHECK-NEXT: [[COPY8:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S64_D32_ag_pstm_nrm_imm4:%[0-9]+]]:acc512, [[VLDA_UPS_S64_D32_ag_pstm_nrm_imm5:%[0-9]+]]:ep = VLDA_UPS_S64_D32_ag_pstm_nrm_imm [[COPY8]], [[VLDA_UPS_S64_D32_ag_pstm_nrm_imm3]], 224, implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<8 x s32>))
    ; CHECK-NEXT: [[COPY9:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S64_D32_ag_pstm_nrm4:%[0-9]+]]:acc512, [[VLDA_UPS_S64_D32_ag_pstm_nrm5:%[0-9]+]]:ep = VLDA_UPS_S64_D32_ag_pstm_nrm [[COPY9]], [[VLDA_UPS_S64_D32_ag_pstm_nrm_imm5]], [[MOV_PD_imm10_pseudo1]], implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<8 x s32>))
    ; CHECK-NEXT: PseudoRET implicit $lr, implicit [[VLDA_UPS_S64_D32_ag_pstm_nrm]], implicit [[VLDA_UPS_S64_D32_ag_pstm_nrm_imm]], implicit [[VLDA_UPS_S64_D32_ag_pstm_nrm2]], implicit [[VLDA_UPS_S64_D32_ag_pstm_nrm_imm2]], implicit [[VLDA_UPS_S64_D32_ag_pstm_nrm_imm4]], implicit [[VLDA_UPS_S64_D32_ag_pstm_nrm4]]
    %0:ptrregbank(p0) = COPY $p0
    %1:gprregbank(s32) = COPY $r0
    %7:modregbank(s20) = G_TRUNC %1
    %8:modregbank(s20) = G_CONSTANT i20 0
    %9:modregbank(s20) = G_CONSTANT i20 16
    %10:modregbank(s20) = G_CONSTANT i20 -256
    %11:modregbank(s20) = G_CONSTANT i20 224
    %12:modregbank(s20) = G_CONSTANT i20 256
    %25:vregbank(<8 x s32>), %19:ptrregbank(p0) = G_AIE_POSTINC_LOAD %0, %7 :: (load (<8 x s32>))
    %26:vregbank(<8 x s32>), %20:ptrregbank(p0) = G_AIE_POSTINC_LOAD %19, %8 :: (load (<8 x s32>))
    %27:vregbank(<8 x s32>), %21:ptrregbank(p0) = G_AIE_POSTINC_LOAD %20, %9 :: (load (<8 x s32>))
    %28:vregbank(<8 x s32>), %22:ptrregbank(p0) = G_AIE_POSTINC_LOAD %21, %10 :: (load (<8 x s32>))
    %29:vregbank(<8 x s32>), %23:ptrregbank(p0) = G_AIE_POSTINC_LOAD %22, %11 :: (load (<8 x s32>))
    %30:vregbank(<8 x s32>), %24:ptrregbank(p0) = G_AIE_POSTINC_LOAD %23, %12 :: (load (<8 x s32>))
    %101:gprregbank(s32) = COPY $r1
    %102:gprregbank(s32) = G_CONSTANT i32 0
    %103:accregbank(<8 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc64.v8.I256.ups), %25:vregbank(<8 x s32>), %101:gprregbank(s32), %102:gprregbank(s32)
    %104:accregbank(<8 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc64.v8.I256.ups), %26:vregbank(<8 x s32>), %101:gprregbank(s32), %102:gprregbank(s32)
    %105:accregbank(<8 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc64.v8.I256.ups), %27:vregbank(<8 x s32>), %101:gprregbank(s32), %102:gprregbank(s32)
    %106:accregbank(<8 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc64.v8.I256.ups), %28:vregbank(<8 x s32>), %101:gprregbank(s32), %102:gprregbank(s32)
    %107:accregbank(<8 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc64.v8.I256.ups), %29:vregbank(<8 x s32>), %101:gprregbank(s32), %102:gprregbank(s32)
    %108:accregbank(<8 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc64.v8.I256.ups), %30:vregbank(<8 x s32>), %101:gprregbank(s32), %102:gprregbank(s32)
    PseudoRET implicit $lr, implicit %103, implicit %104, implicit %105, implicit %106, implicit %107, implicit %108
...

---
name:            VLDA_UPS_S32_D16_dyn
legalized:       true
regBankSelected: true
tracksRegLiveness: true
body: |
  bb.0:
    liveins: $p0, $r0, $r1, $amll0
    ; CHECK-LABEL: name: VLDA_UPS_S32_D16_dyn
    ; CHECK: liveins: $p0, $r0, $r1, $amll0
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:ep = COPY $p0
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:er = COPY $r0
    ; CHECK-NEXT: [[COPY2:%[0-9]+]]:em = COPY [[COPY1]]
    ; CHECK-NEXT: [[MOV_PD_imm10_pseudo:%[0-9]+]]:em = MOV_PD_imm10_pseudo 16
    ; CHECK-NEXT: [[MOV_PD_imm10_pseudo1:%[0-9]+]]:em = MOV_PD_imm10_pseudo 256
    ; CHECK-NEXT: [[COPY3:%[0-9]+]]:er = COPY $r1
    ; CHECK-NEXT: [[COPY4:%[0-9]+]]:er = COPY $r1
    ; CHECK-NEXT: $crupssign = COPY [[COPY4]]
    ; CHECK-NEXT: [[COPY5:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S32_D16_ag_pstm_nrm:%[0-9]+]]:acc512, [[VLDA_UPS_S32_D16_ag_pstm_nrm1:%[0-9]+]]:ep = VLDA_UPS_S32_D16_ag_pstm_nrm [[COPY5]], [[COPY]], [[COPY2]], implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<16 x s16>))
    ; CHECK-NEXT: $crupssign = MOV_scalar_imm10_pseudo 0
    ; CHECK-NEXT: $crupssign = COPY [[COPY4]]
    ; CHECK-NEXT: [[COPY6:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S32_D16_ag_pstm_nrm_imm:%[0-9]+]]:acc512, [[VLDA_UPS_S32_D16_ag_pstm_nrm_imm1:%[0-9]+]]:ep = VLDA_UPS_S32_D16_ag_pstm_nrm_imm [[COPY6]], [[VLDA_UPS_S32_D16_ag_pstm_nrm1]], 0, implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<16 x s16>))
    ; CHECK-NEXT: $crupssign = MOV_scalar_imm10_pseudo 0
    ; CHECK-NEXT: $crupssign = COPY [[COPY4]]
    ; CHECK-NEXT: [[COPY7:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S32_D16_ag_pstm_nrm2:%[0-9]+]]:acc512, [[VLDA_UPS_S32_D16_ag_pstm_nrm3:%[0-9]+]]:ep = VLDA_UPS_S32_D16_ag_pstm_nrm [[COPY7]], [[VLDA_UPS_S32_D16_ag_pstm_nrm_imm1]], [[MOV_PD_imm10_pseudo]], implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<16 x s16>))
    ; CHECK-NEXT: $crupssign = MOV_scalar_imm10_pseudo 0
    ; CHECK-NEXT: $crupssign = COPY [[COPY4]]
    ; CHECK-NEXT: [[COPY8:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S32_D16_ag_pstm_nrm_imm2:%[0-9]+]]:acc512, [[VLDA_UPS_S32_D16_ag_pstm_nrm_imm3:%[0-9]+]]:ep = VLDA_UPS_S32_D16_ag_pstm_nrm_imm [[COPY8]], [[VLDA_UPS_S32_D16_ag_pstm_nrm3]], -256, implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<16 x s16>))
    ; CHECK-NEXT: $crupssign = MOV_scalar_imm10_pseudo 0
    ; CHECK-NEXT: $crupssign = COPY [[COPY4]]
    ; CHECK-NEXT: [[COPY9:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S32_D16_ag_pstm_nrm_imm4:%[0-9]+]]:acc512, [[VLDA_UPS_S32_D16_ag_pstm_nrm_imm5:%[0-9]+]]:ep = VLDA_UPS_S32_D16_ag_pstm_nrm_imm [[COPY9]], [[VLDA_UPS_S32_D16_ag_pstm_nrm_imm3]], 224, implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<16 x s16>))
    ; CHECK-NEXT: $crupssign = MOV_scalar_imm10_pseudo 0
    ; CHECK-NEXT: $crupssign = COPY [[COPY4]]
    ; CHECK-NEXT: [[COPY10:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S32_D16_ag_pstm_nrm4:%[0-9]+]]:acc512, [[VLDA_UPS_S32_D16_ag_pstm_nrm5:%[0-9]+]]:ep = VLDA_UPS_S32_D16_ag_pstm_nrm [[COPY10]], [[VLDA_UPS_S32_D16_ag_pstm_nrm_imm5]], [[MOV_PD_imm10_pseudo1]], implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<16 x s16>))
    ; CHECK-NEXT: $crupssign = MOV_scalar_imm10_pseudo 0
    ; CHECK-NEXT: PseudoRET implicit $lr, implicit [[VLDA_UPS_S32_D16_ag_pstm_nrm]], implicit [[VLDA_UPS_S32_D16_ag_pstm_nrm_imm]], implicit [[VLDA_UPS_S32_D16_ag_pstm_nrm2]], implicit [[VLDA_UPS_S32_D16_ag_pstm_nrm_imm2]], implicit [[VLDA_UPS_S32_D16_ag_pstm_nrm_imm4]], implicit [[VLDA_UPS_S32_D16_ag_pstm_nrm4]]
    %0:ptrregbank(p0) = COPY $p0
    %1:gprregbank(s32) = COPY $r0
    %7:modregbank(s20) = G_TRUNC %1
    %8:modregbank(s20) = G_CONSTANT i20 0
    %9:modregbank(s20) = G_CONSTANT i20 16
    %10:modregbank(s20) = G_CONSTANT i20 -256
    %11:modregbank(s20) = G_CONSTANT i20 224
    %12:modregbank(s20) = G_CONSTANT i20 256
    %25:vregbank(<16 x s16>), %19:ptrregbank(p0) = G_AIE_POSTINC_LOAD %0, %7 :: (load (<16 x s16>))
    %26:vregbank(<16 x s16>), %20:ptrregbank(p0) = G_AIE_POSTINC_LOAD %19, %8 :: (load (<16 x s16>))
    %27:vregbank(<16 x s16>), %21:ptrregbank(p0) = G_AIE_POSTINC_LOAD %20, %9 :: (load (<16 x s16>))
    %28:vregbank(<16 x s16>), %22:ptrregbank(p0) = G_AIE_POSTINC_LOAD %21, %10 :: (load (<16 x s16>))
    %29:vregbank(<16 x s16>), %23:ptrregbank(p0) = G_AIE_POSTINC_LOAD %22, %11 :: (load (<16 x s16>))
    %30:vregbank(<16 x s16>), %24:ptrregbank(p0) = G_AIE_POSTINC_LOAD %23, %12 :: (load (<16 x s16>))
    %101:gprregbank(s32) = COPY $r1
    %102:gprregbank(s32) = COPY $r1
    %103:accregbank(<8 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc32.v16.I256.ups), %25:vregbank(<16 x s16>), %101:gprregbank(s32), %102:gprregbank(s32)
    %104:accregbank(<8 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc32.v16.I256.ups), %26:vregbank(<16 x s16>), %101:gprregbank(s32), %102:gprregbank(s32)
    %105:accregbank(<8 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc32.v16.I256.ups), %27:vregbank(<16 x s16>), %101:gprregbank(s32), %102:gprregbank(s32)
    %106:accregbank(<8 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc32.v16.I256.ups), %28:vregbank(<16 x s16>), %101:gprregbank(s32), %102:gprregbank(s32)
    %107:accregbank(<8 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc32.v16.I256.ups), %29:vregbank(<16 x s16>), %101:gprregbank(s32), %102:gprregbank(s32)
    %108:accregbank(<8 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc32.v16.I256.ups), %30:vregbank(<16 x s16>), %101:gprregbank(s32), %102:gprregbank(s32)
    PseudoRET implicit $lr, implicit %103, implicit %104, implicit %105, implicit %106, implicit %107, implicit %108
...

---
name:            VLDA_UPS_S64_D16_dyn
legalized:       true
regBankSelected: true
tracksRegLiveness: true
body: |
  bb.0:
    liveins: $p0, $r0, $r1, $amll0
    ; CHECK-LABEL: name: VLDA_UPS_S64_D16_dyn
    ; CHECK: liveins: $p0, $r0, $r1, $amll0
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:ep = COPY $p0
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:er = COPY $r0
    ; CHECK-NEXT: [[COPY2:%[0-9]+]]:em = COPY [[COPY1]]
    ; CHECK-NEXT: [[MOV_PD_imm10_pseudo:%[0-9]+]]:em = MOV_PD_imm10_pseudo 16
    ; CHECK-NEXT: [[MOV_PD_imm10_pseudo1:%[0-9]+]]:em = MOV_PD_imm10_pseudo 256
    ; CHECK-NEXT: [[COPY3:%[0-9]+]]:er = COPY $r1
    ; CHECK-NEXT: [[COPY4:%[0-9]+]]:er = COPY $r1
    ; CHECK-NEXT: $crupssign = COPY [[COPY4]]
    ; CHECK-NEXT: [[COPY5:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S64_D16_ag_pstm_nrm:%[0-9]+]]:acc1024, [[VLDA_UPS_S64_D16_ag_pstm_nrm1:%[0-9]+]]:ep = VLDA_UPS_S64_D16_ag_pstm_nrm [[COPY5]], [[COPY]], [[COPY2]], implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<16 x s16>))
    ; CHECK-NEXT: $crupssign = MOV_scalar_imm10_pseudo 0
    ; CHECK-NEXT: $crupssign = COPY [[COPY4]]
    ; CHECK-NEXT: [[COPY6:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S64_D16_ag_pstm_nrm_imm:%[0-9]+]]:acc1024, [[VLDA_UPS_S64_D16_ag_pstm_nrm_imm1:%[0-9]+]]:ep = VLDA_UPS_S64_D16_ag_pstm_nrm_imm [[COPY6]], [[VLDA_UPS_S64_D16_ag_pstm_nrm1]], 0, implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<16 x s16>))
    ; CHECK-NEXT: $crupssign = MOV_scalar_imm10_pseudo 0
    ; CHECK-NEXT: $crupssign = COPY [[COPY4]]
    ; CHECK-NEXT: [[COPY7:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S64_D16_ag_pstm_nrm2:%[0-9]+]]:acc1024, [[VLDA_UPS_S64_D16_ag_pstm_nrm3:%[0-9]+]]:ep = VLDA_UPS_S64_D16_ag_pstm_nrm [[COPY7]], [[VLDA_UPS_S64_D16_ag_pstm_nrm_imm1]], [[MOV_PD_imm10_pseudo]], implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<16 x s16>))
    ; CHECK-NEXT: $crupssign = MOV_scalar_imm10_pseudo 0
    ; CHECK-NEXT: $crupssign = COPY [[COPY4]]
    ; CHECK-NEXT: [[COPY8:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S64_D16_ag_pstm_nrm_imm2:%[0-9]+]]:acc1024, [[VLDA_UPS_S64_D16_ag_pstm_nrm_imm3:%[0-9]+]]:ep = VLDA_UPS_S64_D16_ag_pstm_nrm_imm [[COPY8]], [[VLDA_UPS_S64_D16_ag_pstm_nrm3]], -256, implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<16 x s16>))
    ; CHECK-NEXT: $crupssign = MOV_scalar_imm10_pseudo 0
    ; CHECK-NEXT: $crupssign = COPY [[COPY4]]
    ; CHECK-NEXT: [[COPY9:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S64_D16_ag_pstm_nrm_imm4:%[0-9]+]]:acc1024, [[VLDA_UPS_S64_D16_ag_pstm_nrm_imm5:%[0-9]+]]:ep = VLDA_UPS_S64_D16_ag_pstm_nrm_imm [[COPY9]], [[VLDA_UPS_S64_D16_ag_pstm_nrm_imm3]], 224, implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<16 x s16>))
    ; CHECK-NEXT: $crupssign = MOV_scalar_imm10_pseudo 0
    ; CHECK-NEXT: $crupssign = COPY [[COPY4]]
    ; CHECK-NEXT: [[COPY10:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S64_D16_ag_pstm_nrm4:%[0-9]+]]:acc1024, [[VLDA_UPS_S64_D16_ag_pstm_nrm5:%[0-9]+]]:ep = VLDA_UPS_S64_D16_ag_pstm_nrm [[COPY10]], [[VLDA_UPS_S64_D16_ag_pstm_nrm_imm5]], [[MOV_PD_imm10_pseudo1]], implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<16 x s16>))
    ; CHECK-NEXT: $crupssign = MOV_scalar_imm10_pseudo 0
    ; CHECK-NEXT: PseudoRET implicit $lr, implicit [[VLDA_UPS_S64_D16_ag_pstm_nrm]], implicit [[VLDA_UPS_S64_D16_ag_pstm_nrm_imm]], implicit [[VLDA_UPS_S64_D16_ag_pstm_nrm2]], implicit [[VLDA_UPS_S64_D16_ag_pstm_nrm_imm2]], implicit [[VLDA_UPS_S64_D16_ag_pstm_nrm_imm4]], implicit [[VLDA_UPS_S64_D16_ag_pstm_nrm4]]
    %0:ptrregbank(p0) = COPY $p0
    %1:gprregbank(s32) = COPY $r0
    %7:modregbank(s20) = G_TRUNC %1
    %8:modregbank(s20) = G_CONSTANT i20 0
    %9:modregbank(s20) = G_CONSTANT i20 16
    %10:modregbank(s20) = G_CONSTANT i20 -256
    %11:modregbank(s20) = G_CONSTANT i20 224
    %12:modregbank(s20) = G_CONSTANT i20 256
    %25:vregbank(<16 x s16>), %19:ptrregbank(p0) = G_AIE_POSTINC_LOAD %0, %7 :: (load (<16 x s16>))
    %26:vregbank(<16 x s16>), %20:ptrregbank(p0) = G_AIE_POSTINC_LOAD %19, %8 :: (load (<16 x s16>))
    %27:vregbank(<16 x s16>), %21:ptrregbank(p0) = G_AIE_POSTINC_LOAD %20, %9 :: (load (<16 x s16>))
    %28:vregbank(<16 x s16>), %22:ptrregbank(p0) = G_AIE_POSTINC_LOAD %21, %10 :: (load (<16 x s16>))
    %29:vregbank(<16 x s16>), %23:ptrregbank(p0) = G_AIE_POSTINC_LOAD %22, %11 :: (load (<16 x s16>))
    %30:vregbank(<16 x s16>), %24:ptrregbank(p0) = G_AIE_POSTINC_LOAD %23, %12 :: (load (<16 x s16>))
    %101:gprregbank(s32) = COPY $r1
    %102:gprregbank(s32) = COPY $r1
    %103:accregbank(<16 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc64.v16.I256.ups), %25:vregbank(<16 x s16>), %101:gprregbank(s32), %102:gprregbank(s32)
    %104:accregbank(<16 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc64.v16.I256.ups), %26:vregbank(<16 x s16>), %101:gprregbank(s32), %102:gprregbank(s32)
    %105:accregbank(<16 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc64.v16.I256.ups), %27:vregbank(<16 x s16>), %101:gprregbank(s32), %102:gprregbank(s32)
    %106:accregbank(<16 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc64.v16.I256.ups), %28:vregbank(<16 x s16>), %101:gprregbank(s32), %102:gprregbank(s32)
    %107:accregbank(<16 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc64.v16.I256.ups), %29:vregbank(<16 x s16>), %101:gprregbank(s32), %102:gprregbank(s32)
    %108:accregbank(<16 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc64.v16.I256.ups), %30:vregbank(<16 x s16>), %101:gprregbank(s32), %102:gprregbank(s32)
    PseudoRET implicit $lr, implicit %103, implicit %104, implicit %105, implicit %106, implicit %107, implicit %108
...

---
name:            VLDA_UPS_S32_D8_dyn
legalized:       true
regBankSelected: true
tracksRegLiveness: true
body: |
  bb.0:
    liveins: $p0, $r0, $r1, $amll0
    ; CHECK-LABEL: name: VLDA_UPS_S32_D8_dyn
    ; CHECK: liveins: $p0, $r0, $r1, $amll0
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:ep = COPY $p0
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:er = COPY $r0
    ; CHECK-NEXT: [[COPY2:%[0-9]+]]:em = COPY [[COPY1]]
    ; CHECK-NEXT: [[MOV_PD_imm10_pseudo:%[0-9]+]]:em = MOV_PD_imm10_pseudo 16
    ; CHECK-NEXT: [[MOV_PD_imm10_pseudo1:%[0-9]+]]:em = MOV_PD_imm10_pseudo 256
    ; CHECK-NEXT: [[COPY3:%[0-9]+]]:er = COPY $r1
    ; CHECK-NEXT: [[COPY4:%[0-9]+]]:er = COPY $r1
    ; CHECK-NEXT: $crupssign = COPY [[COPY4]]
    ; CHECK-NEXT: [[COPY5:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S32_D8_ag_pstm_nrm:%[0-9]+]]:acc1024, [[VLDA_UPS_S32_D8_ag_pstm_nrm1:%[0-9]+]]:ep = VLDA_UPS_S32_D8_ag_pstm_nrm [[COPY5]], [[COPY]], [[COPY2]], implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<8 x s32>))
    ; CHECK-NEXT: $crupssign = MOV_scalar_imm10_pseudo 0
    ; CHECK-NEXT: $crupssign = COPY [[COPY4]]
    ; CHECK-NEXT: [[COPY6:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S32_D8_ag_pstm_nrm_imm:%[0-9]+]]:acc1024, [[VLDA_UPS_S32_D8_ag_pstm_nrm_imm1:%[0-9]+]]:ep = VLDA_UPS_S32_D8_ag_pstm_nrm_imm [[COPY6]], [[VLDA_UPS_S32_D8_ag_pstm_nrm1]], 0, implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<8 x s32>))
    ; CHECK-NEXT: $crupssign = MOV_scalar_imm10_pseudo 0
    ; CHECK-NEXT: $crupssign = COPY [[COPY4]]
    ; CHECK-NEXT: [[COPY7:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S32_D8_ag_pstm_nrm2:%[0-9]+]]:acc1024, [[VLDA_UPS_S32_D8_ag_pstm_nrm3:%[0-9]+]]:ep = VLDA_UPS_S32_D8_ag_pstm_nrm [[COPY7]], [[VLDA_UPS_S32_D8_ag_pstm_nrm_imm1]], [[MOV_PD_imm10_pseudo]], implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<8 x s32>))
    ; CHECK-NEXT: $crupssign = MOV_scalar_imm10_pseudo 0
    ; CHECK-NEXT: $crupssign = COPY [[COPY4]]
    ; CHECK-NEXT: [[COPY8:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S32_D8_ag_pstm_nrm_imm2:%[0-9]+]]:acc1024, [[VLDA_UPS_S32_D8_ag_pstm_nrm_imm3:%[0-9]+]]:ep = VLDA_UPS_S32_D8_ag_pstm_nrm_imm [[COPY8]], [[VLDA_UPS_S32_D8_ag_pstm_nrm3]], -256, implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<8 x s32>))
    ; CHECK-NEXT: $crupssign = MOV_scalar_imm10_pseudo 0
    ; CHECK-NEXT: $crupssign = COPY [[COPY4]]
    ; CHECK-NEXT: [[COPY9:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S32_D8_ag_pstm_nrm_imm4:%[0-9]+]]:acc1024, [[VLDA_UPS_S32_D8_ag_pstm_nrm_imm5:%[0-9]+]]:ep = VLDA_UPS_S32_D8_ag_pstm_nrm_imm [[COPY9]], [[VLDA_UPS_S32_D8_ag_pstm_nrm_imm3]], 224, implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<8 x s32>))
    ; CHECK-NEXT: $crupssign = MOV_scalar_imm10_pseudo 0
    ; CHECK-NEXT: $crupssign = COPY [[COPY4]]
    ; CHECK-NEXT: [[COPY10:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S32_D8_ag_pstm_nrm4:%[0-9]+]]:acc1024, [[VLDA_UPS_S32_D8_ag_pstm_nrm5:%[0-9]+]]:ep = VLDA_UPS_S32_D8_ag_pstm_nrm [[COPY10]], [[VLDA_UPS_S32_D8_ag_pstm_nrm_imm5]], [[MOV_PD_imm10_pseudo1]], implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<8 x s32>))
    ; CHECK-NEXT: $crupssign = MOV_scalar_imm10_pseudo 0
    ; CHECK-NEXT: PseudoRET implicit $lr, implicit [[VLDA_UPS_S32_D8_ag_pstm_nrm]], implicit [[VLDA_UPS_S32_D8_ag_pstm_nrm_imm]], implicit [[VLDA_UPS_S32_D8_ag_pstm_nrm2]], implicit [[VLDA_UPS_S32_D8_ag_pstm_nrm_imm2]], implicit [[VLDA_UPS_S32_D8_ag_pstm_nrm_imm4]], implicit [[VLDA_UPS_S32_D8_ag_pstm_nrm4]]
    %0:ptrregbank(p0) = COPY $p0
    %1:gprregbank(s32) = COPY $r0
    %7:modregbank(s20) = G_TRUNC %1
    %8:modregbank(s20) = G_CONSTANT i20 0
    %9:modregbank(s20) = G_CONSTANT i20 16
    %10:modregbank(s20) = G_CONSTANT i20 -256
    %11:modregbank(s20) = G_CONSTANT i20 224
    %12:modregbank(s20) = G_CONSTANT i20 256
    %25:vregbank(<8 x s32>), %19:ptrregbank(p0) = G_AIE_POSTINC_LOAD %0, %7 :: (load (<8 x s32>))
    %26:vregbank(<8 x s32>), %20:ptrregbank(p0) = G_AIE_POSTINC_LOAD %19, %8 :: (load (<8 x s32>))
    %27:vregbank(<8 x s32>), %21:ptrregbank(p0) = G_AIE_POSTINC_LOAD %20, %9 :: (load (<8 x s32>))
    %28:vregbank(<8 x s32>), %22:ptrregbank(p0) = G_AIE_POSTINC_LOAD %21, %10 :: (load (<8 x s32>))
    %29:vregbank(<8 x s32>), %23:ptrregbank(p0) = G_AIE_POSTINC_LOAD %22, %11 :: (load (<8 x s32>))
    %30:vregbank(<8 x s32>), %24:ptrregbank(p0) = G_AIE_POSTINC_LOAD %23, %12 :: (load (<8 x s32>))
    %101:gprregbank(s32) = COPY $r1
    %102:gprregbank(s32) = COPY $r1
    %103:accregbank(<16 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc32.v32.I256.ups), %25:vregbank(<8 x s32>), %101:gprregbank(s32), %102:gprregbank(s32)
    %104:accregbank(<16 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc32.v32.I256.ups), %26:vregbank(<8 x s32>), %101:gprregbank(s32), %102:gprregbank(s32)
    %105:accregbank(<16 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc32.v32.I256.ups), %27:vregbank(<8 x s32>), %101:gprregbank(s32), %102:gprregbank(s32)
    %106:accregbank(<16 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc32.v32.I256.ups), %28:vregbank(<8 x s32>), %101:gprregbank(s32), %102:gprregbank(s32)
    %107:accregbank(<16 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc32.v32.I256.ups), %29:vregbank(<8 x s32>), %101:gprregbank(s32), %102:gprregbank(s32)
    %108:accregbank(<16 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc32.v32.I256.ups), %30:vregbank(<8 x s32>), %101:gprregbank(s32), %102:gprregbank(s32)
    PseudoRET implicit $lr, implicit %103, implicit %104, implicit %105, implicit %106, implicit %107, implicit %108
...

---
name:            VLDA_UPS_S64_D32_dyn
legalized:       true
regBankSelected: true
tracksRegLiveness: true
body: |
  bb.0:
    liveins: $p0, $r0, $r1, $amll0
    ; CHECK-LABEL: name: VLDA_UPS_S64_D32_dyn
    ; CHECK: liveins: $p0, $r0, $r1, $amll0
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:ep = COPY $p0
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:er = COPY $r0
    ; CHECK-NEXT: [[COPY2:%[0-9]+]]:em = COPY [[COPY1]]
    ; CHECK-NEXT: [[MOV_PD_imm10_pseudo:%[0-9]+]]:em = MOV_PD_imm10_pseudo 16
    ; CHECK-NEXT: [[MOV_PD_imm10_pseudo1:%[0-9]+]]:em = MOV_PD_imm10_pseudo 256
    ; CHECK-NEXT: [[COPY3:%[0-9]+]]:er = COPY $r1
    ; CHECK-NEXT: [[COPY4:%[0-9]+]]:er = COPY $r1
    ; CHECK-NEXT: $crupssign = COPY [[COPY4]]
    ; CHECK-NEXT: [[COPY5:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S64_D32_ag_pstm_nrm:%[0-9]+]]:acc512, [[VLDA_UPS_S64_D32_ag_pstm_nrm1:%[0-9]+]]:ep = VLDA_UPS_S64_D32_ag_pstm_nrm [[COPY5]], [[COPY]], [[COPY2]], implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<8 x s32>))
    ; CHECK-NEXT: $crupssign = MOV_scalar_imm10_pseudo 0
    ; CHECK-NEXT: $crupssign = COPY [[COPY4]]
    ; CHECK-NEXT: [[COPY6:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S64_D32_ag_pstm_nrm_imm:%[0-9]+]]:acc512, [[VLDA_UPS_S64_D32_ag_pstm_nrm_imm1:%[0-9]+]]:ep = VLDA_UPS_S64_D32_ag_pstm_nrm_imm [[COPY6]], [[VLDA_UPS_S64_D32_ag_pstm_nrm1]], 0, implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<8 x s32>))
    ; CHECK-NEXT: $crupssign = MOV_scalar_imm10_pseudo 0
    ; CHECK-NEXT: $crupssign = COPY [[COPY4]]
    ; CHECK-NEXT: [[COPY7:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S64_D32_ag_pstm_nrm2:%[0-9]+]]:acc512, [[VLDA_UPS_S64_D32_ag_pstm_nrm3:%[0-9]+]]:ep = VLDA_UPS_S64_D32_ag_pstm_nrm [[COPY7]], [[VLDA_UPS_S64_D32_ag_pstm_nrm_imm1]], [[MOV_PD_imm10_pseudo]], implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<8 x s32>))
    ; CHECK-NEXT: $crupssign = MOV_scalar_imm10_pseudo 0
    ; CHECK-NEXT: $crupssign = COPY [[COPY4]]
    ; CHECK-NEXT: [[COPY8:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S64_D32_ag_pstm_nrm_imm2:%[0-9]+]]:acc512, [[VLDA_UPS_S64_D32_ag_pstm_nrm_imm3:%[0-9]+]]:ep = VLDA_UPS_S64_D32_ag_pstm_nrm_imm [[COPY8]], [[VLDA_UPS_S64_D32_ag_pstm_nrm3]], -256, implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<8 x s32>))
    ; CHECK-NEXT: $crupssign = MOV_scalar_imm10_pseudo 0
    ; CHECK-NEXT: $crupssign = COPY [[COPY4]]
    ; CHECK-NEXT: [[COPY9:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S64_D32_ag_pstm_nrm_imm4:%[0-9]+]]:acc512, [[VLDA_UPS_S64_D32_ag_pstm_nrm_imm5:%[0-9]+]]:ep = VLDA_UPS_S64_D32_ag_pstm_nrm_imm [[COPY9]], [[VLDA_UPS_S64_D32_ag_pstm_nrm_imm3]], 224, implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<8 x s32>))
    ; CHECK-NEXT: $crupssign = MOV_scalar_imm10_pseudo 0
    ; CHECK-NEXT: $crupssign = COPY [[COPY4]]
    ; CHECK-NEXT: [[COPY10:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S64_D32_ag_pstm_nrm4:%[0-9]+]]:acc512, [[VLDA_UPS_S64_D32_ag_pstm_nrm5:%[0-9]+]]:ep = VLDA_UPS_S64_D32_ag_pstm_nrm [[COPY10]], [[VLDA_UPS_S64_D32_ag_pstm_nrm_imm5]], [[MOV_PD_imm10_pseudo1]], implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<8 x s32>))
    ; CHECK-NEXT: $crupssign = MOV_scalar_imm10_pseudo 0
    ; CHECK-NEXT: PseudoRET implicit $lr, implicit [[VLDA_UPS_S64_D32_ag_pstm_nrm]], implicit [[VLDA_UPS_S64_D32_ag_pstm_nrm_imm]], implicit [[VLDA_UPS_S64_D32_ag_pstm_nrm2]], implicit [[VLDA_UPS_S64_D32_ag_pstm_nrm_imm2]], implicit [[VLDA_UPS_S64_D32_ag_pstm_nrm_imm4]], implicit [[VLDA_UPS_S64_D32_ag_pstm_nrm4]]
    %0:ptrregbank(p0) = COPY $p0
    %1:gprregbank(s32) = COPY $r0
    %7:modregbank(s20) = G_TRUNC %1
    %8:modregbank(s20) = G_CONSTANT i20 0
    %9:modregbank(s20) = G_CONSTANT i20 16
    %10:modregbank(s20) = G_CONSTANT i20 -256
    %11:modregbank(s20) = G_CONSTANT i20 224
    %12:modregbank(s20) = G_CONSTANT i20 256
    %25:vregbank(<8 x s32>), %19:ptrregbank(p0) = G_AIE_POSTINC_LOAD %0, %7 :: (load (<8 x s32>))
    %26:vregbank(<8 x s32>), %20:ptrregbank(p0) = G_AIE_POSTINC_LOAD %19, %8 :: (load (<8 x s32>))
    %27:vregbank(<8 x s32>), %21:ptrregbank(p0) = G_AIE_POSTINC_LOAD %20, %9 :: (load (<8 x s32>))
    %28:vregbank(<8 x s32>), %22:ptrregbank(p0) = G_AIE_POSTINC_LOAD %21, %10 :: (load (<8 x s32>))
    %29:vregbank(<8 x s32>), %23:ptrregbank(p0) = G_AIE_POSTINC_LOAD %22, %11 :: (load (<8 x s32>))
    %30:vregbank(<8 x s32>), %24:ptrregbank(p0) = G_AIE_POSTINC_LOAD %23, %12 :: (load (<8 x s32>))
    %101:gprregbank(s32) = COPY $r1
    %102:gprregbank(s32) = COPY $r1
    %103:accregbank(<8 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc64.v8.I256.ups), %25:vregbank(<8 x s32>), %101:gprregbank(s32), %102:gprregbank(s32)
    %104:accregbank(<8 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc64.v8.I256.ups), %26:vregbank(<8 x s32>), %101:gprregbank(s32), %102:gprregbank(s32)
    %105:accregbank(<8 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc64.v8.I256.ups), %27:vregbank(<8 x s32>), %101:gprregbank(s32), %102:gprregbank(s32)
    %106:accregbank(<8 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc64.v8.I256.ups), %28:vregbank(<8 x s32>), %101:gprregbank(s32), %102:gprregbank(s32)
    %107:accregbank(<8 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc64.v8.I256.ups), %29:vregbank(<8 x s32>), %101:gprregbank(s32), %102:gprregbank(s32)
    %108:accregbank(<8 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc64.v8.I256.ups), %30:vregbank(<8 x s32>), %101:gprregbank(s32), %102:gprregbank(s32)
    PseudoRET implicit $lr, implicit %103, implicit %104, implicit %105, implicit %106, implicit %107, implicit %108
...

---
name:            VLDA_UPS_S32_S16_512_bits
legalized:       true
regBankSelected: true
tracksRegLiveness: true
body: |
  bb.0:
    liveins: $p0, $r0, $r1, $amll0
    ; CHECK-LABEL: name: VLDA_UPS_S32_S16_512_bits
    ; CHECK: liveins: $p0, $r0, $r1, $amll0
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:ep = COPY $p0
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:er = COPY $r0
    ; CHECK-NEXT: [[COPY2:%[0-9]+]]:em = COPY [[COPY1]]
    ; CHECK-NEXT: [[MOV_PD_imm10_pseudo:%[0-9]+]]:em = MOV_PD_imm10_pseudo 16
    ; CHECK-NEXT: [[MOV_PD_imm10_pseudo1:%[0-9]+]]:em = MOV_PD_imm10_pseudo 256
    ; CHECK-NEXT: [[COPY3:%[0-9]+]]:er = COPY $r1
    ; CHECK-NEXT: [[COPY4:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S32_S16_ag_idx_imm:%[0-9]+]]:acc512 = VLDA_UPS_S32_S16_ag_idx_imm [[COPY4]], [[COPY]], 32, implicit-def $srups_of, implicit $crsat :: (load (<16 x s16>) from stack - 32, basealign 64)
    ; CHECK-NEXT: [[COPY5:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S32_S16_ag_pstm_nrm:%[0-9]+]]:acc512, [[VLDA_UPS_S32_S16_ag_pstm_nrm1:%[0-9]+]]:ep = VLDA_UPS_S32_S16_ag_pstm_nrm [[COPY5]], [[COPY]], [[COPY2]], implicit-def $srups_of, implicit $crsat :: (load (<16 x s16>) from stack - 64, align 64)
    ; CHECK-NEXT: [[REG_SEQUENCE:%[0-9]+]]:acc1024 = REG_SEQUENCE [[VLDA_UPS_S32_S16_ag_pstm_nrm]], %subreg.sub_512_lo, [[VLDA_UPS_S32_S16_ag_idx_imm]], %subreg.sub_512_hi
    ; CHECK-NEXT: [[COPY6:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S32_S16_ag_idx_imm1:%[0-9]+]]:acc512 = VLDA_UPS_S32_S16_ag_idx_imm [[COPY6]], [[VLDA_UPS_S32_S16_ag_pstm_nrm1]], 32, implicit-def $srups_of, implicit $crsat :: (load (<16 x s16>) from stack - 32, basealign 64)
    ; CHECK-NEXT: [[COPY7:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S32_S16_ag_pstm_nrm_imm:%[0-9]+]]:acc512, [[VLDA_UPS_S32_S16_ag_pstm_nrm_imm1:%[0-9]+]]:ep = VLDA_UPS_S32_S16_ag_pstm_nrm_imm [[COPY7]], [[VLDA_UPS_S32_S16_ag_pstm_nrm1]], 0, implicit-def $srups_of, implicit $crsat :: (load (<16 x s16>) from stack - 64, align 64)
    ; CHECK-NEXT: [[REG_SEQUENCE1:%[0-9]+]]:acc1024 = REG_SEQUENCE [[VLDA_UPS_S32_S16_ag_pstm_nrm_imm]], %subreg.sub_512_lo, [[VLDA_UPS_S32_S16_ag_idx_imm1]], %subreg.sub_512_hi
    ; CHECK-NEXT: [[COPY8:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S32_S16_ag_idx_imm2:%[0-9]+]]:acc512 = VLDA_UPS_S32_S16_ag_idx_imm [[COPY8]], [[VLDA_UPS_S32_S16_ag_pstm_nrm_imm1]], 32, implicit-def $srups_of, implicit $crsat :: (load (<16 x s16>) from stack - 32, basealign 64)
    ; CHECK-NEXT: [[COPY9:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S32_S16_ag_pstm_nrm2:%[0-9]+]]:acc512, [[VLDA_UPS_S32_S16_ag_pstm_nrm3:%[0-9]+]]:ep = VLDA_UPS_S32_S16_ag_pstm_nrm [[COPY9]], [[VLDA_UPS_S32_S16_ag_pstm_nrm_imm1]], [[MOV_PD_imm10_pseudo]], implicit-def $srups_of, implicit $crsat :: (load (<16 x s16>) from stack - 64, align 64)
    ; CHECK-NEXT: [[REG_SEQUENCE2:%[0-9]+]]:acc1024 = REG_SEQUENCE [[VLDA_UPS_S32_S16_ag_pstm_nrm2]], %subreg.sub_512_lo, [[VLDA_UPS_S32_S16_ag_idx_imm2]], %subreg.sub_512_hi
    ; CHECK-NEXT: [[COPY10:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S32_S16_ag_idx_imm3:%[0-9]+]]:acc512 = VLDA_UPS_S32_S16_ag_idx_imm [[COPY10]], [[VLDA_UPS_S32_S16_ag_pstm_nrm3]], 32, implicit-def $srups_of, implicit $crsat :: (load (<16 x s16>) from stack - 32, basealign 64)
    ; CHECK-NEXT: [[COPY11:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S32_S16_ag_pstm_nrm_imm2:%[0-9]+]]:acc512, [[VLDA_UPS_S32_S16_ag_pstm_nrm_imm3:%[0-9]+]]:ep = VLDA_UPS_S32_S16_ag_pstm_nrm_imm [[COPY11]], [[VLDA_UPS_S32_S16_ag_pstm_nrm3]], -256, implicit-def $srups_of, implicit $crsat :: (load (<16 x s16>) from stack - 64, align 64)
    ; CHECK-NEXT: [[REG_SEQUENCE3:%[0-9]+]]:acc1024 = REG_SEQUENCE [[VLDA_UPS_S32_S16_ag_pstm_nrm_imm2]], %subreg.sub_512_lo, [[VLDA_UPS_S32_S16_ag_idx_imm3]], %subreg.sub_512_hi
    ; CHECK-NEXT: [[COPY12:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S32_S16_ag_idx_imm4:%[0-9]+]]:acc512 = VLDA_UPS_S32_S16_ag_idx_imm [[COPY12]], [[VLDA_UPS_S32_S16_ag_pstm_nrm_imm3]], 32, implicit-def $srups_of, implicit $crsat :: (load (<16 x s16>) from stack - 32, basealign 64)
    ; CHECK-NEXT: [[COPY13:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S32_S16_ag_pstm_nrm_imm4:%[0-9]+]]:acc512, [[VLDA_UPS_S32_S16_ag_pstm_nrm_imm5:%[0-9]+]]:ep = VLDA_UPS_S32_S16_ag_pstm_nrm_imm [[COPY13]], [[VLDA_UPS_S32_S16_ag_pstm_nrm_imm3]], 224, implicit-def $srups_of, implicit $crsat :: (load (<16 x s16>) from stack - 64, align 64)
    ; CHECK-NEXT: [[REG_SEQUENCE4:%[0-9]+]]:acc1024 = REG_SEQUENCE [[VLDA_UPS_S32_S16_ag_pstm_nrm_imm4]], %subreg.sub_512_lo, [[VLDA_UPS_S32_S16_ag_idx_imm4]], %subreg.sub_512_hi
    ; CHECK-NEXT: [[COPY14:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S32_S16_ag_idx_imm5:%[0-9]+]]:acc512 = VLDA_UPS_S32_S16_ag_idx_imm [[COPY14]], [[VLDA_UPS_S32_S16_ag_pstm_nrm_imm5]], 32, implicit-def $srups_of, implicit $crsat :: (load (<16 x s16>) from stack - 32, basealign 64)
    ; CHECK-NEXT: [[COPY15:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S32_S16_ag_pstm_nrm4:%[0-9]+]]:acc512, [[VLDA_UPS_S32_S16_ag_pstm_nrm5:%[0-9]+]]:ep = VLDA_UPS_S32_S16_ag_pstm_nrm [[COPY15]], [[VLDA_UPS_S32_S16_ag_pstm_nrm_imm5]], [[MOV_PD_imm10_pseudo1]], implicit-def $srups_of, implicit $crsat :: (load (<16 x s16>) from stack - 64, align 64)
    ; CHECK-NEXT: [[REG_SEQUENCE5:%[0-9]+]]:acc1024 = REG_SEQUENCE [[VLDA_UPS_S32_S16_ag_pstm_nrm4]], %subreg.sub_512_lo, [[VLDA_UPS_S32_S16_ag_idx_imm5]], %subreg.sub_512_hi
    ; CHECK-NEXT: PseudoRET implicit $lr, implicit [[REG_SEQUENCE]], implicit [[REG_SEQUENCE1]], implicit [[REG_SEQUENCE2]], implicit [[REG_SEQUENCE3]], implicit [[REG_SEQUENCE4]], implicit [[REG_SEQUENCE5]]
    %0:ptrregbank(p0) = COPY $p0
    %1:gprregbank(s32) = COPY $r0
    %7:modregbank(s20) = G_TRUNC %1
    %8:modregbank(s20) = G_CONSTANT i20 0
    %9:modregbank(s20) = G_CONSTANT i20 16
    %10:modregbank(s20) = G_CONSTANT i20 -256
    %11:modregbank(s20) = G_CONSTANT i20 224
    %12:modregbank(s20) = G_CONSTANT i20 256
    %25:vregbank(<32 x s16>), %19:ptrregbank(p0) = G_AIE_POSTINC_LOAD %0, %7 :: (load (<32 x s16>) from stack - 64)
    %26:vregbank(<32 x s16>), %20:ptrregbank(p0) = G_AIE_POSTINC_LOAD %19, %8 :: (load (<32 x s16>) from stack - 64)
    %27:vregbank(<32 x s16>), %21:ptrregbank(p0) = G_AIE_POSTINC_LOAD %20, %9 :: (load (<32 x s16>) from stack - 64)
    %28:vregbank(<32 x s16>), %22:ptrregbank(p0) = G_AIE_POSTINC_LOAD %21, %10 :: (load (<32 x s16>) from stack - 64)
    %29:vregbank(<32 x s16>), %23:ptrregbank(p0) = G_AIE_POSTINC_LOAD %22, %11 :: (load (<32 x s16>) from stack - 64)
    %30:vregbank(<32 x s16>), %24:ptrregbank(p0) = G_AIE_POSTINC_LOAD %23, %12 :: (load (<32 x s16>) from stack - 64)
    %101:gprregbank(s32) = COPY $r1
    %102:gprregbank(s32) = G_CONSTANT i32 1
    %103:accregbank(<16 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc32.v32.I512.ups), %25:vregbank(<32 x s16>), %101:gprregbank(s32), %102:gprregbank(s32)
    %104:accregbank(<16 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc32.v32.I512.ups), %26:vregbank(<32 x s16>), %101:gprregbank(s32), %102:gprregbank(s32)
    %105:accregbank(<16 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc32.v32.I512.ups), %27:vregbank(<32 x s16>), %101:gprregbank(s32), %102:gprregbank(s32)
    %106:accregbank(<16 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc32.v32.I512.ups), %28:vregbank(<32 x s16>), %101:gprregbank(s32), %102:gprregbank(s32)
    %107:accregbank(<16 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc32.v32.I512.ups), %29:vregbank(<32 x s16>), %101:gprregbank(s32), %102:gprregbank(s32)
    %108:accregbank(<16 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc32.v32.I512.ups), %30:vregbank(<32 x s16>), %101:gprregbank(s32), %102:gprregbank(s32)
    PseudoRET implicit $lr, implicit %103, implicit %104, implicit %105, implicit %106, implicit %107, implicit %108
...

---
name:            VLDA_UPS_S64_S32_512_bits
legalized:       true
regBankSelected: true
tracksRegLiveness: true
body: |
  bb.0:
    liveins: $p0, $r0, $r1, $amll0
    ; CHECK-LABEL: name: VLDA_UPS_S64_S32_512_bits
    ; CHECK: liveins: $p0, $r0, $r1, $amll0
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:ep = COPY $p0
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:er = COPY $r0
    ; CHECK-NEXT: [[COPY2:%[0-9]+]]:em = COPY [[COPY1]]
    ; CHECK-NEXT: [[MOV_PD_imm10_pseudo:%[0-9]+]]:em = MOV_PD_imm10_pseudo 16
    ; CHECK-NEXT: [[MOV_PD_imm10_pseudo1:%[0-9]+]]:em = MOV_PD_imm10_pseudo 256
    ; CHECK-NEXT: [[COPY3:%[0-9]+]]:er = COPY $r1
    ; CHECK-NEXT: [[COPY4:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S64_S32_ag_idx_imm:%[0-9]+]]:acc512 = VLDA_UPS_S64_S32_ag_idx_imm [[COPY4]], [[COPY]], 32, implicit-def $srups_of, implicit $crsat :: (load (<8 x s32>) from stack - 32, basealign 64)
    ; CHECK-NEXT: [[COPY5:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S64_S32_ag_pstm_nrm:%[0-9]+]]:acc512, [[VLDA_UPS_S64_S32_ag_pstm_nrm1:%[0-9]+]]:ep = VLDA_UPS_S64_S32_ag_pstm_nrm [[COPY5]], [[COPY]], [[COPY2]], implicit-def $srups_of, implicit $crsat :: (load (<8 x s32>) from stack - 64, align 64)
    ; CHECK-NEXT: [[REG_SEQUENCE:%[0-9]+]]:acc1024 = REG_SEQUENCE [[VLDA_UPS_S64_S32_ag_pstm_nrm]], %subreg.sub_512_lo, [[VLDA_UPS_S64_S32_ag_idx_imm]], %subreg.sub_512_hi
    ; CHECK-NEXT: [[COPY6:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S64_S32_ag_idx_imm1:%[0-9]+]]:acc512 = VLDA_UPS_S64_S32_ag_idx_imm [[COPY6]], [[VLDA_UPS_S64_S32_ag_pstm_nrm1]], 32, implicit-def $srups_of, implicit $crsat :: (load (<8 x s32>) from stack - 32, basealign 64)
    ; CHECK-NEXT: [[COPY7:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S64_S32_ag_pstm_nrm_imm:%[0-9]+]]:acc512, [[VLDA_UPS_S64_S32_ag_pstm_nrm_imm1:%[0-9]+]]:ep = VLDA_UPS_S64_S32_ag_pstm_nrm_imm [[COPY7]], [[VLDA_UPS_S64_S32_ag_pstm_nrm1]], 0, implicit-def $srups_of, implicit $crsat :: (load (<8 x s32>) from stack - 64, align 64)
    ; CHECK-NEXT: [[REG_SEQUENCE1:%[0-9]+]]:acc1024 = REG_SEQUENCE [[VLDA_UPS_S64_S32_ag_pstm_nrm_imm]], %subreg.sub_512_lo, [[VLDA_UPS_S64_S32_ag_idx_imm1]], %subreg.sub_512_hi
    ; CHECK-NEXT: [[COPY8:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S64_S32_ag_idx_imm2:%[0-9]+]]:acc512 = VLDA_UPS_S64_S32_ag_idx_imm [[COPY8]], [[VLDA_UPS_S64_S32_ag_pstm_nrm_imm1]], 32, implicit-def $srups_of, implicit $crsat :: (load (<8 x s32>) from stack - 32, basealign 64)
    ; CHECK-NEXT: [[COPY9:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S64_S32_ag_pstm_nrm2:%[0-9]+]]:acc512, [[VLDA_UPS_S64_S32_ag_pstm_nrm3:%[0-9]+]]:ep = VLDA_UPS_S64_S32_ag_pstm_nrm [[COPY9]], [[VLDA_UPS_S64_S32_ag_pstm_nrm_imm1]], [[MOV_PD_imm10_pseudo]], implicit-def $srups_of, implicit $crsat :: (load (<8 x s32>) from stack - 64, align 64)
    ; CHECK-NEXT: [[REG_SEQUENCE2:%[0-9]+]]:acc1024 = REG_SEQUENCE [[VLDA_UPS_S64_S32_ag_pstm_nrm2]], %subreg.sub_512_lo, [[VLDA_UPS_S64_S32_ag_idx_imm2]], %subreg.sub_512_hi
    ; CHECK-NEXT: [[COPY10:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S64_S32_ag_idx_imm3:%[0-9]+]]:acc512 = VLDA_UPS_S64_S32_ag_idx_imm [[COPY10]], [[VLDA_UPS_S64_S32_ag_pstm_nrm3]], 32, implicit-def $srups_of, implicit $crsat :: (load (<8 x s32>) from stack - 32, basealign 64)
    ; CHECK-NEXT: [[COPY11:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S64_S32_ag_pstm_nrm_imm2:%[0-9]+]]:acc512, [[VLDA_UPS_S64_S32_ag_pstm_nrm_imm3:%[0-9]+]]:ep = VLDA_UPS_S64_S32_ag_pstm_nrm_imm [[COPY11]], [[VLDA_UPS_S64_S32_ag_pstm_nrm3]], -256, implicit-def $srups_of, implicit $crsat :: (load (<8 x s32>) from stack - 64, align 64)
    ; CHECK-NEXT: [[REG_SEQUENCE3:%[0-9]+]]:acc1024 = REG_SEQUENCE [[VLDA_UPS_S64_S32_ag_pstm_nrm_imm2]], %subreg.sub_512_lo, [[VLDA_UPS_S64_S32_ag_idx_imm3]], %subreg.sub_512_hi
    ; CHECK-NEXT: [[COPY12:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S64_S32_ag_idx_imm4:%[0-9]+]]:acc512 = VLDA_UPS_S64_S32_ag_idx_imm [[COPY12]], [[VLDA_UPS_S64_S32_ag_pstm_nrm_imm3]], 32, implicit-def $srups_of, implicit $crsat :: (load (<8 x s32>) from stack - 32, basealign 64)
    ; CHECK-NEXT: [[COPY13:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S64_S32_ag_pstm_nrm_imm4:%[0-9]+]]:acc512, [[VLDA_UPS_S64_S32_ag_pstm_nrm_imm5:%[0-9]+]]:ep = VLDA_UPS_S64_S32_ag_pstm_nrm_imm [[COPY13]], [[VLDA_UPS_S64_S32_ag_pstm_nrm_imm3]], 224, implicit-def $srups_of, implicit $crsat :: (load (<8 x s32>) from stack - 64, align 64)
    ; CHECK-NEXT: [[REG_SEQUENCE4:%[0-9]+]]:acc1024 = REG_SEQUENCE [[VLDA_UPS_S64_S32_ag_pstm_nrm_imm4]], %subreg.sub_512_lo, [[VLDA_UPS_S64_S32_ag_idx_imm4]], %subreg.sub_512_hi
    ; CHECK-NEXT: [[COPY14:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S64_S32_ag_idx_imm5:%[0-9]+]]:acc512 = VLDA_UPS_S64_S32_ag_idx_imm [[COPY14]], [[VLDA_UPS_S64_S32_ag_pstm_nrm_imm5]], 32, implicit-def $srups_of, implicit $crsat :: (load (<8 x s32>) from stack - 32, basealign 64)
    ; CHECK-NEXT: [[COPY15:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S64_S32_ag_pstm_nrm4:%[0-9]+]]:acc512, [[VLDA_UPS_S64_S32_ag_pstm_nrm5:%[0-9]+]]:ep = VLDA_UPS_S64_S32_ag_pstm_nrm [[COPY15]], [[VLDA_UPS_S64_S32_ag_pstm_nrm_imm5]], [[MOV_PD_imm10_pseudo1]], implicit-def $srups_of, implicit $crsat :: (load (<8 x s32>) from stack - 64, align 64)
    ; CHECK-NEXT: [[REG_SEQUENCE5:%[0-9]+]]:acc1024 = REG_SEQUENCE [[VLDA_UPS_S64_S32_ag_pstm_nrm4]], %subreg.sub_512_lo, [[VLDA_UPS_S64_S32_ag_idx_imm5]], %subreg.sub_512_hi
    ; CHECK-NEXT: PseudoRET implicit $lr, implicit [[REG_SEQUENCE]], implicit [[REG_SEQUENCE1]], implicit [[REG_SEQUENCE2]], implicit [[REG_SEQUENCE3]], implicit [[REG_SEQUENCE4]], implicit [[REG_SEQUENCE5]]
    %0:ptrregbank(p0) = COPY $p0
    %1:gprregbank(s32) = COPY $r0
    %7:modregbank(s20) = G_TRUNC %1
    %8:modregbank(s20) = G_CONSTANT i20 0
    %9:modregbank(s20) = G_CONSTANT i20 16
    %10:modregbank(s20) = G_CONSTANT i20 -256
    %11:modregbank(s20) = G_CONSTANT i20 224
    %12:modregbank(s20) = G_CONSTANT i20 256
    %25:vregbank(<16 x s32>), %19:ptrregbank(p0) = G_AIE_POSTINC_LOAD %0, %7 :: (load (<16 x s32>) from stack - 64)
    %26:vregbank(<16 x s32>), %20:ptrregbank(p0) = G_AIE_POSTINC_LOAD %19, %8 :: (load (<16 x s32>) from stack - 64)
    %27:vregbank(<16 x s32>), %21:ptrregbank(p0) = G_AIE_POSTINC_LOAD %20, %9 :: (load (<16 x s32>) from stack - 64)
    %28:vregbank(<16 x s32>), %22:ptrregbank(p0) = G_AIE_POSTINC_LOAD %21, %10 :: (load (<16 x s32>) from stack - 64)
    %29:vregbank(<16 x s32>), %23:ptrregbank(p0) = G_AIE_POSTINC_LOAD %22, %11 :: (load (<16 x s32>) from stack - 64)
    %30:vregbank(<16 x s32>), %24:ptrregbank(p0) = G_AIE_POSTINC_LOAD %23, %12 :: (load (<16 x s32>) from stack - 64)
    %101:gprregbank(s32) = COPY $r1
    %102:gprregbank(s32) = G_CONSTANT i32 1
    %103:accregbank(<16 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc64.v16.I512.ups), %25:vregbank(<16 x s32>), %101:gprregbank(s32), %102:gprregbank(s32)
    %104:accregbank(<16 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc64.v16.I512.ups), %26:vregbank(<16 x s32>), %101:gprregbank(s32), %102:gprregbank(s32)
    %105:accregbank(<16 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc64.v16.I512.ups), %27:vregbank(<16 x s32>), %101:gprregbank(s32), %102:gprregbank(s32)
    %106:accregbank(<16 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc64.v16.I512.ups), %28:vregbank(<16 x s32>), %101:gprregbank(s32), %102:gprregbank(s32)
    %107:accregbank(<16 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc64.v16.I512.ups), %29:vregbank(<16 x s32>), %101:gprregbank(s32), %102:gprregbank(s32)
    %108:accregbank(<16 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc64.v16.I512.ups), %30:vregbank(<16 x s32>), %101:gprregbank(s32), %102:gprregbank(s32)
    PseudoRET implicit $lr, implicit %103, implicit %104, implicit %105, implicit %106, implicit %107, implicit %108
...

---
name:            VLDA_UPS_S32_D16_512_bits
legalized:       true
regBankSelected: true
tracksRegLiveness: true
body: |
  bb.0:
    liveins: $p0, $r0, $r1, $amll0
    ; CHECK-LABEL: name: VLDA_UPS_S32_D16_512_bits
    ; CHECK: liveins: $p0, $r0, $r1, $amll0
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:ep = COPY $p0
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:er = COPY $r0
    ; CHECK-NEXT: [[COPY2:%[0-9]+]]:em = COPY [[COPY1]]
    ; CHECK-NEXT: [[MOV_PD_imm10_pseudo:%[0-9]+]]:em = MOV_PD_imm10_pseudo 16
    ; CHECK-NEXT: [[MOV_PD_imm10_pseudo1:%[0-9]+]]:em = MOV_PD_imm10_pseudo 256
    ; CHECK-NEXT: [[COPY3:%[0-9]+]]:er = COPY $r1
    ; CHECK-NEXT: [[COPY4:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S32_D16_ag_idx_imm:%[0-9]+]]:acc512 = VLDA_UPS_S32_D16_ag_idx_imm [[COPY4]], [[COPY]], 32, implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<16 x s16>) from stack - 32, basealign 64)
    ; CHECK-NEXT: [[COPY5:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S32_D16_ag_pstm_nrm:%[0-9]+]]:acc512, [[VLDA_UPS_S32_D16_ag_pstm_nrm1:%[0-9]+]]:ep = VLDA_UPS_S32_D16_ag_pstm_nrm [[COPY5]], [[COPY]], [[COPY2]], implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<16 x s16>) from stack - 64, align 64)
    ; CHECK-NEXT: [[REG_SEQUENCE:%[0-9]+]]:acc1024 = REG_SEQUENCE [[VLDA_UPS_S32_D16_ag_pstm_nrm]], %subreg.sub_512_lo, [[VLDA_UPS_S32_D16_ag_idx_imm]], %subreg.sub_512_hi
    ; CHECK-NEXT: [[COPY6:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S32_D16_ag_idx_imm1:%[0-9]+]]:acc512 = VLDA_UPS_S32_D16_ag_idx_imm [[COPY6]], [[VLDA_UPS_S32_D16_ag_pstm_nrm1]], 32, implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<16 x s16>) from stack - 32, basealign 64)
    ; CHECK-NEXT: [[COPY7:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S32_D16_ag_pstm_nrm_imm:%[0-9]+]]:acc512, [[VLDA_UPS_S32_D16_ag_pstm_nrm_imm1:%[0-9]+]]:ep = VLDA_UPS_S32_D16_ag_pstm_nrm_imm [[COPY7]], [[VLDA_UPS_S32_D16_ag_pstm_nrm1]], 0, implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<16 x s16>) from stack - 64, align 64)
    ; CHECK-NEXT: [[REG_SEQUENCE1:%[0-9]+]]:acc1024 = REG_SEQUENCE [[VLDA_UPS_S32_D16_ag_pstm_nrm_imm]], %subreg.sub_512_lo, [[VLDA_UPS_S32_D16_ag_idx_imm1]], %subreg.sub_512_hi
    ; CHECK-NEXT: [[COPY8:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S32_D16_ag_idx_imm2:%[0-9]+]]:acc512 = VLDA_UPS_S32_D16_ag_idx_imm [[COPY8]], [[VLDA_UPS_S32_D16_ag_pstm_nrm_imm1]], 32, implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<16 x s16>) from stack - 32, basealign 64)
    ; CHECK-NEXT: [[COPY9:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S32_D16_ag_pstm_nrm2:%[0-9]+]]:acc512, [[VLDA_UPS_S32_D16_ag_pstm_nrm3:%[0-9]+]]:ep = VLDA_UPS_S32_D16_ag_pstm_nrm [[COPY9]], [[VLDA_UPS_S32_D16_ag_pstm_nrm_imm1]], [[MOV_PD_imm10_pseudo]], implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<16 x s16>) from stack - 64, align 64)
    ; CHECK-NEXT: [[REG_SEQUENCE2:%[0-9]+]]:acc1024 = REG_SEQUENCE [[VLDA_UPS_S32_D16_ag_pstm_nrm2]], %subreg.sub_512_lo, [[VLDA_UPS_S32_D16_ag_idx_imm2]], %subreg.sub_512_hi
    ; CHECK-NEXT: [[COPY10:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S32_D16_ag_idx_imm3:%[0-9]+]]:acc512 = VLDA_UPS_S32_D16_ag_idx_imm [[COPY10]], [[VLDA_UPS_S32_D16_ag_pstm_nrm3]], 32, implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<16 x s16>) from stack - 32, basealign 64)
    ; CHECK-NEXT: [[COPY11:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S32_D16_ag_pstm_nrm_imm2:%[0-9]+]]:acc512, [[VLDA_UPS_S32_D16_ag_pstm_nrm_imm3:%[0-9]+]]:ep = VLDA_UPS_S32_D16_ag_pstm_nrm_imm [[COPY11]], [[VLDA_UPS_S32_D16_ag_pstm_nrm3]], -256, implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<16 x s16>) from stack - 64, align 64)
    ; CHECK-NEXT: [[REG_SEQUENCE3:%[0-9]+]]:acc1024 = REG_SEQUENCE [[VLDA_UPS_S32_D16_ag_pstm_nrm_imm2]], %subreg.sub_512_lo, [[VLDA_UPS_S32_D16_ag_idx_imm3]], %subreg.sub_512_hi
    ; CHECK-NEXT: [[COPY12:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S32_D16_ag_idx_imm4:%[0-9]+]]:acc512 = VLDA_UPS_S32_D16_ag_idx_imm [[COPY12]], [[VLDA_UPS_S32_D16_ag_pstm_nrm_imm3]], 32, implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<16 x s16>) from stack - 32, basealign 64)
    ; CHECK-NEXT: [[COPY13:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S32_D16_ag_pstm_nrm_imm4:%[0-9]+]]:acc512, [[VLDA_UPS_S32_D16_ag_pstm_nrm_imm5:%[0-9]+]]:ep = VLDA_UPS_S32_D16_ag_pstm_nrm_imm [[COPY13]], [[VLDA_UPS_S32_D16_ag_pstm_nrm_imm3]], 224, implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<16 x s16>) from stack - 64, align 64)
    ; CHECK-NEXT: [[REG_SEQUENCE4:%[0-9]+]]:acc1024 = REG_SEQUENCE [[VLDA_UPS_S32_D16_ag_pstm_nrm_imm4]], %subreg.sub_512_lo, [[VLDA_UPS_S32_D16_ag_idx_imm4]], %subreg.sub_512_hi
    ; CHECK-NEXT: [[COPY14:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S32_D16_ag_idx_imm5:%[0-9]+]]:acc512 = VLDA_UPS_S32_D16_ag_idx_imm [[COPY14]], [[VLDA_UPS_S32_D16_ag_pstm_nrm_imm5]], 32, implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<16 x s16>) from stack - 32, basealign 64)
    ; CHECK-NEXT: [[COPY15:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S32_D16_ag_pstm_nrm4:%[0-9]+]]:acc512, [[VLDA_UPS_S32_D16_ag_pstm_nrm5:%[0-9]+]]:ep = VLDA_UPS_S32_D16_ag_pstm_nrm [[COPY15]], [[VLDA_UPS_S32_D16_ag_pstm_nrm_imm5]], [[MOV_PD_imm10_pseudo1]], implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<16 x s16>) from stack - 64, align 64)
    ; CHECK-NEXT: [[REG_SEQUENCE5:%[0-9]+]]:acc1024 = REG_SEQUENCE [[VLDA_UPS_S32_D16_ag_pstm_nrm4]], %subreg.sub_512_lo, [[VLDA_UPS_S32_D16_ag_idx_imm5]], %subreg.sub_512_hi
    ; CHECK-NEXT: PseudoRET implicit $lr, implicit [[REG_SEQUENCE]], implicit [[REG_SEQUENCE1]], implicit [[REG_SEQUENCE2]], implicit [[REG_SEQUENCE3]], implicit [[REG_SEQUENCE4]], implicit [[REG_SEQUENCE5]]
    %0:ptrregbank(p0) = COPY $p0
    %1:gprregbank(s32) = COPY $r0
    %7:modregbank(s20) = G_TRUNC %1
    %8:modregbank(s20) = G_CONSTANT i20 0
    %9:modregbank(s20) = G_CONSTANT i20 16
    %10:modregbank(s20) = G_CONSTANT i20 -256
    %11:modregbank(s20) = G_CONSTANT i20 224
    %12:modregbank(s20) = G_CONSTANT i20 256
    %25:vregbank(<32 x s16>), %19:ptrregbank(p0) = G_AIE_POSTINC_LOAD %0, %7 :: (load (<32 x s16>) from stack - 64)
    %26:vregbank(<32 x s16>), %20:ptrregbank(p0) = G_AIE_POSTINC_LOAD %19, %8 :: (load (<32 x s16>) from stack - 64)
    %27:vregbank(<32 x s16>), %21:ptrregbank(p0) = G_AIE_POSTINC_LOAD %20, %9 :: (load (<32 x s16>) from stack - 64)
    %28:vregbank(<32 x s16>), %22:ptrregbank(p0) = G_AIE_POSTINC_LOAD %21, %10 :: (load (<32 x s16>) from stack - 64)
    %29:vregbank(<32 x s16>), %23:ptrregbank(p0) = G_AIE_POSTINC_LOAD %22, %11 :: (load (<32 x s16>) from stack - 64)
    %30:vregbank(<32 x s16>), %24:ptrregbank(p0) = G_AIE_POSTINC_LOAD %23, %12 :: (load (<32 x s16>) from stack - 64)
    %101:gprregbank(s32) = COPY $r1
    %102:gprregbank(s32) = G_CONSTANT i32 0
    %103:accregbank(<16 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc32.v32.I512.ups), %25:vregbank(<32 x s16>), %101:gprregbank(s32), %102:gprregbank(s32)
    %104:accregbank(<16 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc32.v32.I512.ups), %26:vregbank(<32 x s16>), %101:gprregbank(s32), %102:gprregbank(s32)
    %105:accregbank(<16 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc32.v32.I512.ups), %27:vregbank(<32 x s16>), %101:gprregbank(s32), %102:gprregbank(s32)
    %106:accregbank(<16 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc32.v32.I512.ups), %28:vregbank(<32 x s16>), %101:gprregbank(s32), %102:gprregbank(s32)
    %107:accregbank(<16 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc32.v32.I512.ups), %29:vregbank(<32 x s16>), %101:gprregbank(s32), %102:gprregbank(s32)
    %108:accregbank(<16 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc32.v32.I512.ups), %30:vregbank(<32 x s16>), %101:gprregbank(s32), %102:gprregbank(s32)
    PseudoRET implicit $lr, implicit %103, implicit %104, implicit %105, implicit %106, implicit %107, implicit %108
...

---
name:            VLDA_UPS_S64_D32_512_bits
legalized:       true
regBankSelected: true
tracksRegLiveness: true
body: |
  bb.0:
    liveins: $p0, $r0, $r1, $amll0
    ; CHECK-LABEL: name: VLDA_UPS_S64_D32_512_bits
    ; CHECK: liveins: $p0, $r0, $r1, $amll0
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:ep = COPY $p0
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:er = COPY $r0
    ; CHECK-NEXT: [[COPY2:%[0-9]+]]:em = COPY [[COPY1]]
    ; CHECK-NEXT: [[MOV_PD_imm10_pseudo:%[0-9]+]]:em = MOV_PD_imm10_pseudo 16
    ; CHECK-NEXT: [[MOV_PD_imm10_pseudo1:%[0-9]+]]:em = MOV_PD_imm10_pseudo 256
    ; CHECK-NEXT: [[COPY3:%[0-9]+]]:er = COPY $r1
    ; CHECK-NEXT: [[COPY4:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S64_D32_ag_idx_imm:%[0-9]+]]:acc512 = VLDA_UPS_S64_D32_ag_idx_imm [[COPY4]], [[COPY]], 32, implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<8 x s32>) from stack - 32, basealign 64)
    ; CHECK-NEXT: [[COPY5:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S64_D32_ag_pstm_nrm:%[0-9]+]]:acc512, [[VLDA_UPS_S64_D32_ag_pstm_nrm1:%[0-9]+]]:ep = VLDA_UPS_S64_D32_ag_pstm_nrm [[COPY5]], [[COPY]], [[COPY2]], implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<8 x s32>) from stack - 64, align 64)
    ; CHECK-NEXT: [[REG_SEQUENCE:%[0-9]+]]:acc1024 = REG_SEQUENCE [[VLDA_UPS_S64_D32_ag_pstm_nrm]], %subreg.sub_512_lo, [[VLDA_UPS_S64_D32_ag_idx_imm]], %subreg.sub_512_hi
    ; CHECK-NEXT: [[COPY6:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S64_D32_ag_idx_imm1:%[0-9]+]]:acc512 = VLDA_UPS_S64_D32_ag_idx_imm [[COPY6]], [[VLDA_UPS_S64_D32_ag_pstm_nrm1]], 32, implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<8 x s32>) from stack - 32, basealign 64)
    ; CHECK-NEXT: [[COPY7:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S64_D32_ag_pstm_nrm_imm:%[0-9]+]]:acc512, [[VLDA_UPS_S64_D32_ag_pstm_nrm_imm1:%[0-9]+]]:ep = VLDA_UPS_S64_D32_ag_pstm_nrm_imm [[COPY7]], [[VLDA_UPS_S64_D32_ag_pstm_nrm1]], 0, implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<8 x s32>) from stack - 64, align 64)
    ; CHECK-NEXT: [[REG_SEQUENCE1:%[0-9]+]]:acc1024 = REG_SEQUENCE [[VLDA_UPS_S64_D32_ag_pstm_nrm_imm]], %subreg.sub_512_lo, [[VLDA_UPS_S64_D32_ag_idx_imm1]], %subreg.sub_512_hi
    ; CHECK-NEXT: [[COPY8:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S64_D32_ag_idx_imm2:%[0-9]+]]:acc512 = VLDA_UPS_S64_D32_ag_idx_imm [[COPY8]], [[VLDA_UPS_S64_D32_ag_pstm_nrm_imm1]], 32, implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<8 x s32>) from stack - 32, basealign 64)
    ; CHECK-NEXT: [[COPY9:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S64_D32_ag_pstm_nrm2:%[0-9]+]]:acc512, [[VLDA_UPS_S64_D32_ag_pstm_nrm3:%[0-9]+]]:ep = VLDA_UPS_S64_D32_ag_pstm_nrm [[COPY9]], [[VLDA_UPS_S64_D32_ag_pstm_nrm_imm1]], [[MOV_PD_imm10_pseudo]], implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<8 x s32>) from stack - 64, align 64)
    ; CHECK-NEXT: [[REG_SEQUENCE2:%[0-9]+]]:acc1024 = REG_SEQUENCE [[VLDA_UPS_S64_D32_ag_pstm_nrm2]], %subreg.sub_512_lo, [[VLDA_UPS_S64_D32_ag_idx_imm2]], %subreg.sub_512_hi
    ; CHECK-NEXT: [[COPY10:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S64_D32_ag_idx_imm3:%[0-9]+]]:acc512 = VLDA_UPS_S64_D32_ag_idx_imm [[COPY10]], [[VLDA_UPS_S64_D32_ag_pstm_nrm3]], 32, implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<8 x s32>) from stack - 32, basealign 64)
    ; CHECK-NEXT: [[COPY11:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S64_D32_ag_pstm_nrm_imm2:%[0-9]+]]:acc512, [[VLDA_UPS_S64_D32_ag_pstm_nrm_imm3:%[0-9]+]]:ep = VLDA_UPS_S64_D32_ag_pstm_nrm_imm [[COPY11]], [[VLDA_UPS_S64_D32_ag_pstm_nrm3]], -256, implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<8 x s32>) from stack - 64, align 64)
    ; CHECK-NEXT: [[REG_SEQUENCE3:%[0-9]+]]:acc1024 = REG_SEQUENCE [[VLDA_UPS_S64_D32_ag_pstm_nrm_imm2]], %subreg.sub_512_lo, [[VLDA_UPS_S64_D32_ag_idx_imm3]], %subreg.sub_512_hi
    ; CHECK-NEXT: [[COPY12:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S64_D32_ag_idx_imm4:%[0-9]+]]:acc512 = VLDA_UPS_S64_D32_ag_idx_imm [[COPY12]], [[VLDA_UPS_S64_D32_ag_pstm_nrm_imm3]], 32, implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<8 x s32>) from stack - 32, basealign 64)
    ; CHECK-NEXT: [[COPY13:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S64_D32_ag_pstm_nrm_imm4:%[0-9]+]]:acc512, [[VLDA_UPS_S64_D32_ag_pstm_nrm_imm5:%[0-9]+]]:ep = VLDA_UPS_S64_D32_ag_pstm_nrm_imm [[COPY13]], [[VLDA_UPS_S64_D32_ag_pstm_nrm_imm3]], 224, implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<8 x s32>) from stack - 64, align 64)
    ; CHECK-NEXT: [[REG_SEQUENCE4:%[0-9]+]]:acc1024 = REG_SEQUENCE [[VLDA_UPS_S64_D32_ag_pstm_nrm_imm4]], %subreg.sub_512_lo, [[VLDA_UPS_S64_D32_ag_idx_imm4]], %subreg.sub_512_hi
    ; CHECK-NEXT: [[COPY14:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S64_D32_ag_idx_imm5:%[0-9]+]]:acc512 = VLDA_UPS_S64_D32_ag_idx_imm [[COPY14]], [[VLDA_UPS_S64_D32_ag_pstm_nrm_imm5]], 32, implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<8 x s32>) from stack - 32, basealign 64)
    ; CHECK-NEXT: [[COPY15:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S64_D32_ag_pstm_nrm4:%[0-9]+]]:acc512, [[VLDA_UPS_S64_D32_ag_pstm_nrm5:%[0-9]+]]:ep = VLDA_UPS_S64_D32_ag_pstm_nrm [[COPY15]], [[VLDA_UPS_S64_D32_ag_pstm_nrm_imm5]], [[MOV_PD_imm10_pseudo1]], implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<8 x s32>) from stack - 64, align 64)
    ; CHECK-NEXT: [[REG_SEQUENCE5:%[0-9]+]]:acc1024 = REG_SEQUENCE [[VLDA_UPS_S64_D32_ag_pstm_nrm4]], %subreg.sub_512_lo, [[VLDA_UPS_S64_D32_ag_idx_imm5]], %subreg.sub_512_hi
    ; CHECK-NEXT: PseudoRET implicit $lr, implicit [[REG_SEQUENCE]], implicit [[REG_SEQUENCE1]], implicit [[REG_SEQUENCE2]], implicit [[REG_SEQUENCE3]], implicit [[REG_SEQUENCE4]], implicit [[REG_SEQUENCE5]]
    %0:ptrregbank(p0) = COPY $p0
    %1:gprregbank(s32) = COPY $r0
    %7:modregbank(s20) = G_TRUNC %1
    %8:modregbank(s20) = G_CONSTANT i20 0
    %9:modregbank(s20) = G_CONSTANT i20 16
    %10:modregbank(s20) = G_CONSTANT i20 -256
    %11:modregbank(s20) = G_CONSTANT i20 224
    %12:modregbank(s20) = G_CONSTANT i20 256
    %25:vregbank(<16 x s32>), %19:ptrregbank(p0) = G_AIE_POSTINC_LOAD %0, %7 :: (load (<16 x s32>) from stack - 64)
    %26:vregbank(<16 x s32>), %20:ptrregbank(p0) = G_AIE_POSTINC_LOAD %19, %8 :: (load (<16 x s32>) from stack - 64)
    %27:vregbank(<16 x s32>), %21:ptrregbank(p0) = G_AIE_POSTINC_LOAD %20, %9 :: (load (<16 x s32>) from stack - 64)
    %28:vregbank(<16 x s32>), %22:ptrregbank(p0) = G_AIE_POSTINC_LOAD %21, %10 :: (load (<16 x s32>) from stack - 64)
    %29:vregbank(<16 x s32>), %23:ptrregbank(p0) = G_AIE_POSTINC_LOAD %22, %11 :: (load (<16 x s32>) from stack - 64)
    %30:vregbank(<16 x s32>), %24:ptrregbank(p0) = G_AIE_POSTINC_LOAD %23, %12 :: (load (<16 x s32>) from stack - 64)
    %101:gprregbank(s32) = COPY $r1
    %102:gprregbank(s32) = G_CONSTANT i32 0
    %103:accregbank(<16 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc64.v16.I512.ups), %25:vregbank(<16 x s32>), %101:gprregbank(s32), %102:gprregbank(s32)
    %104:accregbank(<16 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc64.v16.I512.ups), %26:vregbank(<16 x s32>), %101:gprregbank(s32), %102:gprregbank(s32)
    %105:accregbank(<16 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc64.v16.I512.ups), %27:vregbank(<16 x s32>), %101:gprregbank(s32), %102:gprregbank(s32)
    %106:accregbank(<16 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc64.v16.I512.ups), %28:vregbank(<16 x s32>), %101:gprregbank(s32), %102:gprregbank(s32)
    %107:accregbank(<16 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc64.v16.I512.ups), %29:vregbank(<16 x s32>), %101:gprregbank(s32), %102:gprregbank(s32)
    %108:accregbank(<16 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc64.v16.I512.ups), %30:vregbank(<16 x s32>), %101:gprregbank(s32), %102:gprregbank(s32)
    PseudoRET implicit $lr, implicit %103, implicit %104, implicit %105, implicit %106, implicit %107, implicit %108
...

---
name:            VLDA_UPS_S32_D16_512_bits_dyn
legalized:       true
regBankSelected: true
tracksRegLiveness: true
body: |
  bb.0:
    liveins: $p0, $r0, $r1, $amll0
    ; CHECK-LABEL: name: VLDA_UPS_S32_D16_512_bits_dyn
    ; CHECK: liveins: $p0, $r0, $r1, $amll0
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:ep = COPY $p0
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:er = COPY $r0
    ; CHECK-NEXT: [[COPY2:%[0-9]+]]:em = COPY [[COPY1]]
    ; CHECK-NEXT: [[MOV_PD_imm10_pseudo:%[0-9]+]]:em = MOV_PD_imm10_pseudo 16
    ; CHECK-NEXT: [[MOV_PD_imm10_pseudo1:%[0-9]+]]:em = MOV_PD_imm10_pseudo 256
    ; CHECK-NEXT: [[COPY3:%[0-9]+]]:er = COPY $r1
    ; CHECK-NEXT: [[COPY4:%[0-9]+]]:er = COPY $r1
    ; CHECK-NEXT: $crupssign = COPY [[COPY4]]
    ; CHECK-NEXT: [[COPY5:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S32_D16_ag_idx_imm:%[0-9]+]]:acc512 = VLDA_UPS_S32_D16_ag_idx_imm [[COPY5]], [[COPY]], 32, implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<16 x s16>) from stack - 32, basealign 64)
    ; CHECK-NEXT: [[COPY6:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S32_D16_ag_pstm_nrm:%[0-9]+]]:acc512, [[VLDA_UPS_S32_D16_ag_pstm_nrm1:%[0-9]+]]:ep = VLDA_UPS_S32_D16_ag_pstm_nrm [[COPY6]], [[COPY]], [[COPY2]], implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<16 x s16>) from stack - 64, align 64)
    ; CHECK-NEXT: $crupssign = MOV_scalar_imm10_pseudo 0
    ; CHECK-NEXT: [[REG_SEQUENCE:%[0-9]+]]:acc1024 = REG_SEQUENCE [[VLDA_UPS_S32_D16_ag_pstm_nrm]], %subreg.sub_512_lo, [[VLDA_UPS_S32_D16_ag_idx_imm]], %subreg.sub_512_hi
    ; CHECK-NEXT: $crupssign = COPY [[COPY4]]
    ; CHECK-NEXT: [[COPY7:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S32_D16_ag_idx_imm1:%[0-9]+]]:acc512 = VLDA_UPS_S32_D16_ag_idx_imm [[COPY7]], [[VLDA_UPS_S32_D16_ag_pstm_nrm1]], 32, implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<16 x s16>) from stack - 32, basealign 64)
    ; CHECK-NEXT: [[COPY8:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S32_D16_ag_pstm_nrm_imm:%[0-9]+]]:acc512, [[VLDA_UPS_S32_D16_ag_pstm_nrm_imm1:%[0-9]+]]:ep = VLDA_UPS_S32_D16_ag_pstm_nrm_imm [[COPY8]], [[VLDA_UPS_S32_D16_ag_pstm_nrm1]], 0, implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<16 x s16>) from stack - 64, align 64)
    ; CHECK-NEXT: $crupssign = MOV_scalar_imm10_pseudo 0
    ; CHECK-NEXT: [[REG_SEQUENCE1:%[0-9]+]]:acc1024 = REG_SEQUENCE [[VLDA_UPS_S32_D16_ag_pstm_nrm_imm]], %subreg.sub_512_lo, [[VLDA_UPS_S32_D16_ag_idx_imm1]], %subreg.sub_512_hi
    ; CHECK-NEXT: $crupssign = COPY [[COPY4]]
    ; CHECK-NEXT: [[COPY9:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S32_D16_ag_idx_imm2:%[0-9]+]]:acc512 = VLDA_UPS_S32_D16_ag_idx_imm [[COPY9]], [[VLDA_UPS_S32_D16_ag_pstm_nrm_imm1]], 32, implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<16 x s16>) from stack - 32, basealign 64)
    ; CHECK-NEXT: [[COPY10:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S32_D16_ag_pstm_nrm2:%[0-9]+]]:acc512, [[VLDA_UPS_S32_D16_ag_pstm_nrm3:%[0-9]+]]:ep = VLDA_UPS_S32_D16_ag_pstm_nrm [[COPY10]], [[VLDA_UPS_S32_D16_ag_pstm_nrm_imm1]], [[MOV_PD_imm10_pseudo]], implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<16 x s16>) from stack - 64, align 64)
    ; CHECK-NEXT: $crupssign = MOV_scalar_imm10_pseudo 0
    ; CHECK-NEXT: [[REG_SEQUENCE2:%[0-9]+]]:acc1024 = REG_SEQUENCE [[VLDA_UPS_S32_D16_ag_pstm_nrm2]], %subreg.sub_512_lo, [[VLDA_UPS_S32_D16_ag_idx_imm2]], %subreg.sub_512_hi
    ; CHECK-NEXT: $crupssign = COPY [[COPY4]]
    ; CHECK-NEXT: [[COPY11:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S32_D16_ag_idx_imm3:%[0-9]+]]:acc512 = VLDA_UPS_S32_D16_ag_idx_imm [[COPY11]], [[VLDA_UPS_S32_D16_ag_pstm_nrm3]], 32, implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<16 x s16>) from stack - 32, basealign 64)
    ; CHECK-NEXT: [[COPY12:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S32_D16_ag_pstm_nrm_imm2:%[0-9]+]]:acc512, [[VLDA_UPS_S32_D16_ag_pstm_nrm_imm3:%[0-9]+]]:ep = VLDA_UPS_S32_D16_ag_pstm_nrm_imm [[COPY12]], [[VLDA_UPS_S32_D16_ag_pstm_nrm3]], -256, implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<16 x s16>) from stack - 64, align 64)
    ; CHECK-NEXT: $crupssign = MOV_scalar_imm10_pseudo 0
    ; CHECK-NEXT: [[REG_SEQUENCE3:%[0-9]+]]:acc1024 = REG_SEQUENCE [[VLDA_UPS_S32_D16_ag_pstm_nrm_imm2]], %subreg.sub_512_lo, [[VLDA_UPS_S32_D16_ag_idx_imm3]], %subreg.sub_512_hi
    ; CHECK-NEXT: $crupssign = COPY [[COPY4]]
    ; CHECK-NEXT: [[COPY13:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S32_D16_ag_idx_imm4:%[0-9]+]]:acc512 = VLDA_UPS_S32_D16_ag_idx_imm [[COPY13]], [[VLDA_UPS_S32_D16_ag_pstm_nrm_imm3]], 32, implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<16 x s16>) from stack - 32, basealign 64)
    ; CHECK-NEXT: [[COPY14:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S32_D16_ag_pstm_nrm_imm4:%[0-9]+]]:acc512, [[VLDA_UPS_S32_D16_ag_pstm_nrm_imm5:%[0-9]+]]:ep = VLDA_UPS_S32_D16_ag_pstm_nrm_imm [[COPY14]], [[VLDA_UPS_S32_D16_ag_pstm_nrm_imm3]], 224, implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<16 x s16>) from stack - 64, align 64)
    ; CHECK-NEXT: $crupssign = MOV_scalar_imm10_pseudo 0
    ; CHECK-NEXT: [[REG_SEQUENCE4:%[0-9]+]]:acc1024 = REG_SEQUENCE [[VLDA_UPS_S32_D16_ag_pstm_nrm_imm4]], %subreg.sub_512_lo, [[VLDA_UPS_S32_D16_ag_idx_imm4]], %subreg.sub_512_hi
    ; CHECK-NEXT: $crupssign = COPY [[COPY4]]
    ; CHECK-NEXT: [[COPY15:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S32_D16_ag_idx_imm5:%[0-9]+]]:acc512 = VLDA_UPS_S32_D16_ag_idx_imm [[COPY15]], [[VLDA_UPS_S32_D16_ag_pstm_nrm_imm5]], 32, implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<16 x s16>) from stack - 32, basealign 64)
    ; CHECK-NEXT: [[COPY16:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S32_D16_ag_pstm_nrm4:%[0-9]+]]:acc512, [[VLDA_UPS_S32_D16_ag_pstm_nrm5:%[0-9]+]]:ep = VLDA_UPS_S32_D16_ag_pstm_nrm [[COPY16]], [[VLDA_UPS_S32_D16_ag_pstm_nrm_imm5]], [[MOV_PD_imm10_pseudo1]], implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<16 x s16>) from stack - 64, align 64)
    ; CHECK-NEXT: $crupssign = MOV_scalar_imm10_pseudo 0
    ; CHECK-NEXT: [[REG_SEQUENCE5:%[0-9]+]]:acc1024 = REG_SEQUENCE [[VLDA_UPS_S32_D16_ag_pstm_nrm4]], %subreg.sub_512_lo, [[VLDA_UPS_S32_D16_ag_idx_imm5]], %subreg.sub_512_hi
    ; CHECK-NEXT: PseudoRET implicit $lr, implicit [[REG_SEQUENCE]], implicit [[REG_SEQUENCE1]], implicit [[REG_SEQUENCE2]], implicit [[REG_SEQUENCE3]], implicit [[REG_SEQUENCE4]], implicit [[REG_SEQUENCE5]]
    %0:ptrregbank(p0) = COPY $p0
    %1:gprregbank(s32) = COPY $r0
    %7:modregbank(s20) = G_TRUNC %1
    %8:modregbank(s20) = G_CONSTANT i20 0
    %9:modregbank(s20) = G_CONSTANT i20 16
    %10:modregbank(s20) = G_CONSTANT i20 -256
    %11:modregbank(s20) = G_CONSTANT i20 224
    %12:modregbank(s20) = G_CONSTANT i20 256
    %25:vregbank(<32 x s16>), %19:ptrregbank(p0) = G_AIE_POSTINC_LOAD %0, %7 :: (load (<32 x s16>) from stack - 64)
    %26:vregbank(<32 x s16>), %20:ptrregbank(p0) = G_AIE_POSTINC_LOAD %19, %8 :: (load (<32 x s16>) from stack - 64)
    %27:vregbank(<32 x s16>), %21:ptrregbank(p0) = G_AIE_POSTINC_LOAD %20, %9 :: (load (<32 x s16>) from stack - 64)
    %28:vregbank(<32 x s16>), %22:ptrregbank(p0) = G_AIE_POSTINC_LOAD %21, %10 :: (load (<32 x s16>) from stack - 64)
    %29:vregbank(<32 x s16>), %23:ptrregbank(p0) = G_AIE_POSTINC_LOAD %22, %11 :: (load (<32 x s16>) from stack - 64)
    %30:vregbank(<32 x s16>), %24:ptrregbank(p0) = G_AIE_POSTINC_LOAD %23, %12 :: (load (<32 x s16>) from stack - 64)
    %101:gprregbank(s32) = COPY $r1
    %102:gprregbank(s32) = COPY $r1
    %103:accregbank(<16 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc32.v32.I512.ups), %25:vregbank(<32 x s16>), %101:gprregbank(s32), %102:gprregbank(s32)
    %104:accregbank(<16 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc32.v32.I512.ups), %26:vregbank(<32 x s16>), %101:gprregbank(s32), %102:gprregbank(s32)
    %105:accregbank(<16 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc32.v32.I512.ups), %27:vregbank(<32 x s16>), %101:gprregbank(s32), %102:gprregbank(s32)
    %106:accregbank(<16 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc32.v32.I512.ups), %28:vregbank(<32 x s16>), %101:gprregbank(s32), %102:gprregbank(s32)
    %107:accregbank(<16 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc32.v32.I512.ups), %29:vregbank(<32 x s16>), %101:gprregbank(s32), %102:gprregbank(s32)
    %108:accregbank(<16 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc32.v32.I512.ups), %30:vregbank(<32 x s16>), %101:gprregbank(s32), %102:gprregbank(s32)
    PseudoRET implicit $lr, implicit %103, implicit %104, implicit %105, implicit %106, implicit %107, implicit %108
...

---
name:            VLDA_UPS_S64_D32_512_bits_dyn
legalized:       true
regBankSelected: true
tracksRegLiveness: true
body: |
  bb.0:
    liveins: $p0, $r0, $r1, $amll0
    ; CHECK-LABEL: name: VLDA_UPS_S64_D32_512_bits_dyn
    ; CHECK: liveins: $p0, $r0, $r1, $amll0
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:ep = COPY $p0
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:er = COPY $r0
    ; CHECK-NEXT: [[COPY2:%[0-9]+]]:em = COPY [[COPY1]]
    ; CHECK-NEXT: [[MOV_PD_imm10_pseudo:%[0-9]+]]:em = MOV_PD_imm10_pseudo 16
    ; CHECK-NEXT: [[MOV_PD_imm10_pseudo1:%[0-9]+]]:em = MOV_PD_imm10_pseudo 256
    ; CHECK-NEXT: [[COPY3:%[0-9]+]]:er = COPY $r1
    ; CHECK-NEXT: [[COPY4:%[0-9]+]]:er = COPY $r1
    ; CHECK-NEXT: $crupssign = COPY [[COPY4]]
    ; CHECK-NEXT: [[COPY5:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S64_D32_ag_idx_imm:%[0-9]+]]:acc512 = VLDA_UPS_S64_D32_ag_idx_imm [[COPY5]], [[COPY]], 32, implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<8 x s32>) from stack - 32, basealign 64)
    ; CHECK-NEXT: [[COPY6:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S64_D32_ag_pstm_nrm:%[0-9]+]]:acc512, [[VLDA_UPS_S64_D32_ag_pstm_nrm1:%[0-9]+]]:ep = VLDA_UPS_S64_D32_ag_pstm_nrm [[COPY6]], [[COPY]], [[COPY2]], implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<8 x s32>) from stack - 64, align 64)
    ; CHECK-NEXT: $crupssign = MOV_scalar_imm10_pseudo 0
    ; CHECK-NEXT: [[REG_SEQUENCE:%[0-9]+]]:acc1024 = REG_SEQUENCE [[VLDA_UPS_S64_D32_ag_pstm_nrm]], %subreg.sub_512_lo, [[VLDA_UPS_S64_D32_ag_idx_imm]], %subreg.sub_512_hi
    ; CHECK-NEXT: $crupssign = COPY [[COPY4]]
    ; CHECK-NEXT: [[COPY7:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S64_D32_ag_idx_imm1:%[0-9]+]]:acc512 = VLDA_UPS_S64_D32_ag_idx_imm [[COPY7]], [[VLDA_UPS_S64_D32_ag_pstm_nrm1]], 32, implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<8 x s32>) from stack - 32, basealign 64)
    ; CHECK-NEXT: [[COPY8:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S64_D32_ag_pstm_nrm_imm:%[0-9]+]]:acc512, [[VLDA_UPS_S64_D32_ag_pstm_nrm_imm1:%[0-9]+]]:ep = VLDA_UPS_S64_D32_ag_pstm_nrm_imm [[COPY8]], [[VLDA_UPS_S64_D32_ag_pstm_nrm1]], 0, implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<8 x s32>) from stack - 64, align 64)
    ; CHECK-NEXT: $crupssign = MOV_scalar_imm10_pseudo 0
    ; CHECK-NEXT: [[REG_SEQUENCE1:%[0-9]+]]:acc1024 = REG_SEQUENCE [[VLDA_UPS_S64_D32_ag_pstm_nrm_imm]], %subreg.sub_512_lo, [[VLDA_UPS_S64_D32_ag_idx_imm1]], %subreg.sub_512_hi
    ; CHECK-NEXT: $crupssign = COPY [[COPY4]]
    ; CHECK-NEXT: [[COPY9:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S64_D32_ag_idx_imm2:%[0-9]+]]:acc512 = VLDA_UPS_S64_D32_ag_idx_imm [[COPY9]], [[VLDA_UPS_S64_D32_ag_pstm_nrm_imm1]], 32, implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<8 x s32>) from stack - 32, basealign 64)
    ; CHECK-NEXT: [[COPY10:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S64_D32_ag_pstm_nrm2:%[0-9]+]]:acc512, [[VLDA_UPS_S64_D32_ag_pstm_nrm3:%[0-9]+]]:ep = VLDA_UPS_S64_D32_ag_pstm_nrm [[COPY10]], [[VLDA_UPS_S64_D32_ag_pstm_nrm_imm1]], [[MOV_PD_imm10_pseudo]], implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<8 x s32>) from stack - 64, align 64)
    ; CHECK-NEXT: $crupssign = MOV_scalar_imm10_pseudo 0
    ; CHECK-NEXT: [[REG_SEQUENCE2:%[0-9]+]]:acc1024 = REG_SEQUENCE [[VLDA_UPS_S64_D32_ag_pstm_nrm2]], %subreg.sub_512_lo, [[VLDA_UPS_S64_D32_ag_idx_imm2]], %subreg.sub_512_hi
    ; CHECK-NEXT: $crupssign = COPY [[COPY4]]
    ; CHECK-NEXT: [[COPY11:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S64_D32_ag_idx_imm3:%[0-9]+]]:acc512 = VLDA_UPS_S64_D32_ag_idx_imm [[COPY11]], [[VLDA_UPS_S64_D32_ag_pstm_nrm3]], 32, implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<8 x s32>) from stack - 32, basealign 64)
    ; CHECK-NEXT: [[COPY12:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S64_D32_ag_pstm_nrm_imm2:%[0-9]+]]:acc512, [[VLDA_UPS_S64_D32_ag_pstm_nrm_imm3:%[0-9]+]]:ep = VLDA_UPS_S64_D32_ag_pstm_nrm_imm [[COPY12]], [[VLDA_UPS_S64_D32_ag_pstm_nrm3]], -256, implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<8 x s32>) from stack - 64, align 64)
    ; CHECK-NEXT: $crupssign = MOV_scalar_imm10_pseudo 0
    ; CHECK-NEXT: [[REG_SEQUENCE3:%[0-9]+]]:acc1024 = REG_SEQUENCE [[VLDA_UPS_S64_D32_ag_pstm_nrm_imm2]], %subreg.sub_512_lo, [[VLDA_UPS_S64_D32_ag_idx_imm3]], %subreg.sub_512_hi
    ; CHECK-NEXT: $crupssign = COPY [[COPY4]]
    ; CHECK-NEXT: [[COPY13:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S64_D32_ag_idx_imm4:%[0-9]+]]:acc512 = VLDA_UPS_S64_D32_ag_idx_imm [[COPY13]], [[VLDA_UPS_S64_D32_ag_pstm_nrm_imm3]], 32, implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<8 x s32>) from stack - 32, basealign 64)
    ; CHECK-NEXT: [[COPY14:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S64_D32_ag_pstm_nrm_imm4:%[0-9]+]]:acc512, [[VLDA_UPS_S64_D32_ag_pstm_nrm_imm5:%[0-9]+]]:ep = VLDA_UPS_S64_D32_ag_pstm_nrm_imm [[COPY14]], [[VLDA_UPS_S64_D32_ag_pstm_nrm_imm3]], 224, implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<8 x s32>) from stack - 64, align 64)
    ; CHECK-NEXT: $crupssign = MOV_scalar_imm10_pseudo 0
    ; CHECK-NEXT: [[REG_SEQUENCE4:%[0-9]+]]:acc1024 = REG_SEQUENCE [[VLDA_UPS_S64_D32_ag_pstm_nrm_imm4]], %subreg.sub_512_lo, [[VLDA_UPS_S64_D32_ag_idx_imm4]], %subreg.sub_512_hi
    ; CHECK-NEXT: $crupssign = COPY [[COPY4]]
    ; CHECK-NEXT: [[COPY15:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S64_D32_ag_idx_imm5:%[0-9]+]]:acc512 = VLDA_UPS_S64_D32_ag_idx_imm [[COPY15]], [[VLDA_UPS_S64_D32_ag_pstm_nrm_imm5]], 32, implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<8 x s32>) from stack - 32, basealign 64)
    ; CHECK-NEXT: [[COPY16:%[0-9]+]]:mss = COPY [[COPY3]]
    ; CHECK-NEXT: [[VLDA_UPS_S64_D32_ag_pstm_nrm4:%[0-9]+]]:acc512, [[VLDA_UPS_S64_D32_ag_pstm_nrm5:%[0-9]+]]:ep = VLDA_UPS_S64_D32_ag_pstm_nrm [[COPY16]], [[VLDA_UPS_S64_D32_ag_pstm_nrm_imm5]], [[MOV_PD_imm10_pseudo1]], implicit-def $srups_of, implicit $crsat, implicit $crupssign :: (load (<8 x s32>) from stack - 64, align 64)
    ; CHECK-NEXT: $crupssign = MOV_scalar_imm10_pseudo 0
    ; CHECK-NEXT: [[REG_SEQUENCE5:%[0-9]+]]:acc1024 = REG_SEQUENCE [[VLDA_UPS_S64_D32_ag_pstm_nrm4]], %subreg.sub_512_lo, [[VLDA_UPS_S64_D32_ag_idx_imm5]], %subreg.sub_512_hi
    ; CHECK-NEXT: PseudoRET implicit $lr, implicit [[REG_SEQUENCE]], implicit [[REG_SEQUENCE1]], implicit [[REG_SEQUENCE2]], implicit [[REG_SEQUENCE3]], implicit [[REG_SEQUENCE4]], implicit [[REG_SEQUENCE5]]
    %0:ptrregbank(p0) = COPY $p0
    %1:gprregbank(s32) = COPY $r0
    %7:modregbank(s20) = G_TRUNC %1
    %8:modregbank(s20) = G_CONSTANT i20 0
    %9:modregbank(s20) = G_CONSTANT i20 16
    %10:modregbank(s20) = G_CONSTANT i20 -256
    %11:modregbank(s20) = G_CONSTANT i20 224
    %12:modregbank(s20) = G_CONSTANT i20 256
    %25:vregbank(<16 x s32>), %19:ptrregbank(p0) = G_AIE_POSTINC_LOAD %0, %7 :: (load (<16 x s32>) from stack - 64)
    %26:vregbank(<16 x s32>), %20:ptrregbank(p0) = G_AIE_POSTINC_LOAD %19, %8 :: (load (<16 x s32>) from stack - 64)
    %27:vregbank(<16 x s32>), %21:ptrregbank(p0) = G_AIE_POSTINC_LOAD %20, %9 :: (load (<16 x s32>) from stack - 64)
    %28:vregbank(<16 x s32>), %22:ptrregbank(p0) = G_AIE_POSTINC_LOAD %21, %10 :: (load (<16 x s32>) from stack - 64)
    %29:vregbank(<16 x s32>), %23:ptrregbank(p0) = G_AIE_POSTINC_LOAD %22, %11 :: (load (<16 x s32>) from stack - 64)
    %30:vregbank(<16 x s32>), %24:ptrregbank(p0) = G_AIE_POSTINC_LOAD %23, %12 :: (load (<16 x s32>) from stack - 64)
    %101:gprregbank(s32) = COPY $r1
    %102:gprregbank(s32) = COPY $r1
    %103:accregbank(<16 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc64.v16.I512.ups), %25:vregbank(<16 x s32>), %101:gprregbank(s32), %102:gprregbank(s32)
    %104:accregbank(<16 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc64.v16.I512.ups), %26:vregbank(<16 x s32>), %101:gprregbank(s32), %102:gprregbank(s32)
    %105:accregbank(<16 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc64.v16.I512.ups), %27:vregbank(<16 x s32>), %101:gprregbank(s32), %102:gprregbank(s32)
    %106:accregbank(<16 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc64.v16.I512.ups), %28:vregbank(<16 x s32>), %101:gprregbank(s32), %102:gprregbank(s32)
    %107:accregbank(<16 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc64.v16.I512.ups), %29:vregbank(<16 x s32>), %101:gprregbank(s32), %102:gprregbank(s32)
    %108:accregbank(<16 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.acc64.v16.I512.ups), %30:vregbank(<16 x s32>), %101:gprregbank(s32), %102:gprregbank(s32)
    PseudoRET implicit $lr, implicit %103, implicit %104, implicit %105, implicit %106, implicit %107, implicit %108
...
