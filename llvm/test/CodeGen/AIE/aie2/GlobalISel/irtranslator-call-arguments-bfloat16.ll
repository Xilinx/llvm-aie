; NOTE: Assertions have been autogenerated by utils/update_mir_test_checks.py
;
; This file is licensed under the Apache License v2.0 with LLVM Exceptions.
; See https://llvm.org/LICENSE.txt for license information.
; SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
;
; (c) Copyright 2023-2024 Advanced Micro Devices, Inc. or its affiliates
; RUN: llc -mtriple=aie2 -O0 -stop-after=irtranslator -global-isel -verify-machineinstrs %s -o - 2>&1 | FileCheck %s

%class.bfloat16 = type { bfloat }
define dso_local void @_Z17test_get_bfloat16v() local_unnamed_addr #0 {
  ; CHECK-LABEL: name: _Z17test_get_bfloat16v
  ; CHECK: bb.1.entry:
  ; CHECK-NEXT:   [[DEF:%[0-9]+]]:_(s16) = G_IMPLICIT_DEF
  ; CHECK-NEXT:   ADJCALLSTACKUP 0, 0, implicit-def $sp, implicit $sp
  ; CHECK-NEXT:   [[ANYEXT:%[0-9]+]]:_(s32) = G_ANYEXT [[DEF]](s16)
  ; CHECK-NEXT:   $r1 = COPY [[ANYEXT]](s32)
  ; CHECK-NEXT:   PseudoJL @_Z12ret_bfloat168bfloat16, csr_aie2, implicit-def $lr, implicit $r1, implicit-def $r0
  ; CHECK-NEXT:   [[COPY:%[0-9]+]]:_(s32) = COPY $r0
  ; CHECK-NEXT:   [[TRUNC:%[0-9]+]]:_(s16) = G_TRUNC [[COPY]](s32)
  ; CHECK-NEXT:   ADJCALLSTACKDOWN 0, 0, implicit-def $sp, implicit $sp
  ; CHECK-NEXT:   PseudoRET implicit $lr
entry:
  %call = tail call %class.bfloat16 @_Z12ret_bfloat168bfloat16(%class.bfloat16 undef)
  ret void
}
declare dso_local %class.bfloat16 @_Z12ret_bfloat168bfloat16(%class.bfloat16) local_unnamed_addr #1


define dso_local void @_Z20test_pass_v2bfloat16v() local_unnamed_addr #2 {
  ; CHECK-LABEL: name: _Z20test_pass_v2bfloat16v
  ; CHECK: bb.1.entry:
  ; CHECK-NEXT:   [[DEF:%[0-9]+]]:_(<2 x s16>) = G_IMPLICIT_DEF
  ; CHECK-NEXT:   [[FRAME_INDEX:%[0-9]+]]:_(p0) = G_FRAME_INDEX %stack.0.ret
  ; CHECK-NEXT:   ADJCALLSTACKUP 0, 0, implicit-def $sp, implicit $sp
  ; CHECK-NEXT:   $r1 = COPY [[DEF]](<2 x s16>)
  ; CHECK-NEXT:   PseudoJL @_Z15test_v2bfloat16Dv2_u6__bf16, csr_aie2, implicit-def $lr, implicit $r1, implicit-def $r0
  ; CHECK-NEXT:   [[COPY:%[0-9]+]]:_(<2 x s16>) = COPY $r0
  ; CHECK-NEXT:   ADJCALLSTACKDOWN 0, 0, implicit-def $sp, implicit $sp
  ; CHECK-NEXT:   G_STORE [[COPY]](<2 x s16>), [[FRAME_INDEX]](p0) :: (volatile store (<2 x s16>) into %ir.ret)
  ; CHECK-NEXT:   PseudoRET implicit $lr
entry:
  %ret = alloca <2 x bfloat>, align 4
  %call = tail call noundef <2 x bfloat> @_Z15test_v2bfloat16Dv2_u6__bf16(<2 x bfloat> noundef undef)
  store volatile <2 x bfloat> %call, ptr %ret, align 4
  ret void
}
declare dso_local noundef <2 x bfloat> @_Z15test_v2bfloat16Dv2_u6__bf16(<2 x bfloat> noundef) local_unnamed_addr


define dso_local void @_Z20test_pass_v4bfloat16v() local_unnamed_addr #2 {
  ; CHECK-LABEL: name: _Z20test_pass_v4bfloat16v
  ; CHECK: bb.1.entry:
  ; CHECK-NEXT:   [[DEF:%[0-9]+]]:_(<4 x s16>) = G_IMPLICIT_DEF
  ; CHECK-NEXT:   [[FRAME_INDEX:%[0-9]+]]:_(p0) = G_FRAME_INDEX %stack.0.ret
  ; CHECK-NEXT:   ADJCALLSTACKUP 0, 0, implicit-def $sp, implicit $sp
  ; CHECK-NEXT:   $l1 = COPY [[DEF]](<4 x s16>)
  ; CHECK-NEXT:   PseudoJL @_Z15test_v4bfloat16Dv4_u6__bf16, CustomRegMask($lr,$l2,$l3,$p6,$p7,$r20,$r21,$r22,$r23), implicit-def $lr, implicit $l1, implicit-def $l0
  ; CHECK-NEXT:   [[COPY:%[0-9]+]]:_(<4 x s16>) = COPY $l0
  ; CHECK-NEXT:   ADJCALLSTACKDOWN 0, 0, implicit-def $sp, implicit $sp
  ; CHECK-NEXT:   G_STORE [[COPY]](<4 x s16>), [[FRAME_INDEX]](p0) :: (volatile store (<4 x s16>) into %ir.ret)
  ; CHECK-NEXT:   PseudoRET implicit $lr
entry:
  %ret = alloca <4 x bfloat>, align 8
  %call = tail call noundef <4 x bfloat> @_Z15test_v4bfloat16Dv4_u6__bf16(<4 x bfloat> noundef undef)
  store volatile <4 x bfloat> %call, ptr %ret, align 8
  ret void
}
declare dso_local noundef <4 x bfloat> @_Z15test_v4bfloat16Dv4_u6__bf16(<4 x bfloat> noundef) local_unnamed_addr


define void @_Z20test_call_v8bfloat16v() #0 {
  ; CHECK-LABEL: name: _Z20test_call_v8bfloat16v
  ; CHECK: bb.1.entry:
  ; CHECK-NEXT:   [[FRAME_INDEX:%[0-9]+]]:_(p0) = G_FRAME_INDEX %stack.0.call
  ; CHECK-NEXT:   [[LOAD:%[0-9]+]]:_(<8 x s16>) = G_LOAD [[FRAME_INDEX]](p0) :: (volatile dereferenceable load (<8 x s16>) from %ir.call)
  ; CHECK-NEXT:   ADJCALLSTACKUP 0, 0, implicit-def $sp, implicit $sp
  ; CHECK-NEXT:   [[UV:%[0-9]+]]:_(s16), [[UV1:%[0-9]+]]:_(s16), [[UV2:%[0-9]+]]:_(s16), [[UV3:%[0-9]+]]:_(s16), [[UV4:%[0-9]+]]:_(s16), [[UV5:%[0-9]+]]:_(s16), [[UV6:%[0-9]+]]:_(s16), [[UV7:%[0-9]+]]:_(s16) = G_UNMERGE_VALUES [[LOAD]](<8 x s16>)
  ; CHECK-NEXT:   [[DEF:%[0-9]+]]:_(s16) = G_IMPLICIT_DEF
  ; CHECK-NEXT:   [[BUILD_VECTOR:%[0-9]+]]:_(<16 x s16>) = G_BUILD_VECTOR [[UV]](s16), [[UV1]](s16), [[UV2]](s16), [[UV3]](s16), [[UV4]](s16), [[UV5]](s16), [[UV6]](s16), [[UV7]](s16), [[DEF]](s16), [[DEF]](s16), [[DEF]](s16), [[DEF]](s16), [[DEF]](s16), [[DEF]](s16), [[DEF]](s16), [[DEF]](s16)
  ; CHECK-NEXT:   $wl2 = COPY [[BUILD_VECTOR]](<16 x s16>)
  ; CHECK-NEXT:   PseudoJL @_Z14take_v8bfloat16Dv8_u6__bf16, csr_aie2, implicit-def $lr, implicit $wl2, implicit-def $wl0
  ; CHECK-NEXT:   [[COPY:%[0-9]+]]:_(<16 x s16>) = COPY $wl0
  ; CHECK-NEXT:   [[UV8:%[0-9]+]]:_(<8 x s16>), [[UV9:%[0-9]+]]:_(<8 x s16>) = G_UNMERGE_VALUES [[COPY]](<16 x s16>)
  ; CHECK-NEXT:   ADJCALLSTACKDOWN 0, 0, implicit-def $sp, implicit $sp
  ; CHECK-NEXT:   PseudoRET implicit $lr
entry:
  %call = alloca <8 x bfloat>, align 16
  %0 = load volatile <8 x bfloat>, ptr %call, align 16
  %call1 = call noundef <8 x bfloat> @_Z14take_v8bfloat16Dv8_u6__bf16(<8 x bfloat> noundef %0)
  ret void
}

declare  <8 x bfloat> @_Z14take_v8bfloat16Dv8_u6__bf16(<8 x bfloat> noundef) #1

define void @_Z21test_call_v16bfloat16v() #0 {
  ; CHECK-LABEL: name: _Z21test_call_v16bfloat16v
  ; CHECK: bb.1.entry:
  ; CHECK-NEXT:   [[FRAME_INDEX:%[0-9]+]]:_(p0) = G_FRAME_INDEX %stack.0.call
  ; CHECK-NEXT:   [[LOAD:%[0-9]+]]:_(<16 x s16>) = G_LOAD [[FRAME_INDEX]](p0) :: (volatile dereferenceable load (<16 x s16>) from %ir.call)
  ; CHECK-NEXT:   ADJCALLSTACKUP 0, 0, implicit-def $sp, implicit $sp
  ; CHECK-NEXT:   $wl2 = COPY [[LOAD]](<16 x s16>)
  ; CHECK-NEXT:   PseudoJL @_Z15take_v16bfloat16Dv16_u6__bf16, csr_aie2, implicit-def $lr, implicit $wl2, implicit-def $wl0
  ; CHECK-NEXT:   [[COPY:%[0-9]+]]:_(<16 x s16>) = COPY $wl0
  ; CHECK-NEXT:   ADJCALLSTACKDOWN 0, 0, implicit-def $sp, implicit $sp
  ; CHECK-NEXT:   PseudoRET implicit $lr
entry:
  %call = alloca <16 x bfloat>, align 32
  %0 = load volatile <16 x bfloat>, ptr %call, align 32
  %call1 = call noundef <16 x bfloat> @_Z15take_v16bfloat16Dv16_u6__bf16(<16 x bfloat> noundef %0)
  ret void
}

declare  <16 x bfloat> @_Z15take_v16bfloat16Dv16_u6__bf16(<16 x bfloat> noundef) #1

define void @_Z21test_call_v32bfloat16v() #0 {
  ; CHECK-LABEL: name: _Z21test_call_v32bfloat16v
  ; CHECK: bb.1.entry:
  ; CHECK-NEXT:   [[FRAME_INDEX:%[0-9]+]]:_(p0) = G_FRAME_INDEX %stack.0.call
  ; CHECK-NEXT:   [[LOAD:%[0-9]+]]:_(<32 x s16>) = G_LOAD [[FRAME_INDEX]](p0) :: (volatile dereferenceable load (<32 x s16>) from %ir.call)
  ; CHECK-NEXT:   ADJCALLSTACKUP 0, 0, implicit-def $sp, implicit $sp
  ; CHECK-NEXT:   $x2 = COPY [[LOAD]](<32 x s16>)
  ; CHECK-NEXT:   PseudoJL @_Z15take_v32bfloat16Dv32_u6__bf16, csr_aie2, implicit-def $lr, implicit $x2, implicit-def $x0
  ; CHECK-NEXT:   [[COPY:%[0-9]+]]:_(<32 x s16>) = COPY $x0
  ; CHECK-NEXT:   ADJCALLSTACKDOWN 0, 0, implicit-def $sp, implicit $sp
  ; CHECK-NEXT:   PseudoRET implicit $lr
entry:
  %call = alloca <32 x bfloat>, align 64
  %0 = load volatile <32 x bfloat>, ptr %call, align 64
  %call1 = call noundef <32 x bfloat> @_Z15take_v32bfloat16Dv32_u6__bf16(<32 x bfloat> noundef %0)
  ret void
}

declare  <32 x bfloat> @_Z15take_v32bfloat16Dv32_u6__bf16(<32 x bfloat> noundef) #1

define void @_Z21test_call_v64bfloat16v() #0 {
  ; CHECK-LABEL: name: _Z21test_call_v64bfloat16v
  ; CHECK: bb.1.entry:
  ; CHECK-NEXT:   [[FRAME_INDEX:%[0-9]+]]:_(p0) = G_FRAME_INDEX %stack.0.call
  ; CHECK-NEXT:   [[LOAD:%[0-9]+]]:_(<64 x s16>) = G_LOAD [[FRAME_INDEX]](p0) :: (volatile dereferenceable load (<64 x s16>) from %ir.call)
  ; CHECK-NEXT:   ADJCALLSTACKUP 0, 0, implicit-def $sp, implicit $sp
  ; CHECK-NEXT:   $y3 = COPY [[LOAD]](<64 x s16>)
  ; CHECK-NEXT:   PseudoJL @_Z15take_v64bfloat16Dv64_u6__bf16, csr_aie2, implicit-def $lr, implicit $y3, implicit-def $y2
  ; CHECK-NEXT:   [[COPY:%[0-9]+]]:_(<64 x s16>) = COPY $y2
  ; CHECK-NEXT:   ADJCALLSTACKDOWN 0, 0, implicit-def $sp, implicit $sp
  ; CHECK-NEXT:   PseudoRET implicit $lr
entry:
  %call = alloca <64 x bfloat>, align 128
  %0 = load volatile <64 x bfloat>, ptr %call, align 128
  %call1 = call noundef <64 x bfloat> @_Z15take_v64bfloat16Dv64_u6__bf16(<64 x bfloat> noundef %0)
  ret void
}

declare  <64 x bfloat> @_Z15take_v64bfloat16Dv64_u6__bf16(<64 x bfloat> noundef) #1
