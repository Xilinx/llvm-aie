# NOTE: Assertions have been autogenerated by utils/update_mir_test_checks.py
#
# This file is licensed under the Apache License v2.0 with LLVM Exceptions.
# See https://llvm.org/LICENSE.txt for license information.
# SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
#
# (c) Copyright 2023-2024 Advanced Micro Devices, Inc. or its affiliates

# RUN: llc -mtriple aie2 -run-pass=instruction-select %s -verify-machineinstrs -o - | FileCheck %s

---
name:            VLDB_UNPACK_S8_S4
alignment:       16
legalized:       true
regBankSelected: true
body:             |
  bb.1.entry:
    liveins: $p0
    ; CHECK-LABEL: name: VLDB_UNPACK_S8_S4
    ; CHECK: liveins: $p0
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:ep = COPY $p0
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:edj = COPY $m0
    ; CHECK-NEXT: [[VLDB_UNPACK_S8_S4_ag_idx:%[0-9]+]]:vec512 = VLDB_UNPACK_S8_S4_ag_idx [[COPY]], [[COPY1]] :: (load (<32 x s8>))
    ; CHECK-NEXT: $x0 = COPY [[VLDB_UNPACK_S8_S4_ag_idx]]
    ; CHECK-NEXT: PseudoRET implicit $lr, implicit $x0
    %1:ptrregbank(p0) = COPY $p0
    %8:modregbank(s20) = COPY $m0
    %6:gprregbank(s32) = G_CONSTANT i32 1
    %5:vregbank(<32 x s8>) = G_AIE_OFFSET_LOAD %1:ptrregbank(p0), %8:modregbank(s20) :: (load (<32 x s8>))
    %7:vregbank(<32 x s16>) = G_INTRINSIC intrinsic(@llvm.aie2.unpack.I8.I4), %5:vregbank(<32 x s8>), %6:gprregbank(s32)
    $x0 = COPY %7:vregbank(<32 x s16>)
    PseudoRET implicit $lr, implicit $x0
...


---
name:            VLDB_UNPACK_D8_D4
alignment:       16
legalized:       true
regBankSelected: true
body:             |
  bb.1.entry:
    liveins: $p0, $r0, $r1
    ; CHECK-LABEL: name: VLDB_UNPACK_D8_D4
    ; CHECK: liveins: $p0, $r0, $r1
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:ep = COPY $p0
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:edj = COPY $m0
    ; CHECK-NEXT: [[VLDB_UNPACK_D8_D4_ag_idx:%[0-9]+]]:vec512 = VLDB_UNPACK_D8_D4_ag_idx [[COPY]], [[COPY1]], implicit $crunpacksign :: (load (<32 x s8>))
    ; CHECK-NEXT: $x0 = COPY [[VLDB_UNPACK_D8_D4_ag_idx]]
    ; CHECK-NEXT: PseudoRET implicit $lr, implicit $x0
    %1:ptrregbank(p0) = COPY $p0
    %8:modregbank(s20) = COPY $m0
    %6:gprregbank(s32) = G_CONSTANT i32 0
    %5:vregbank(<32 x s8>) = G_AIE_OFFSET_LOAD %1:ptrregbank(p0), %8:modregbank(s20) :: (load (<32 x s8>))
    %7:vregbank(<32 x s16>) = G_INTRINSIC intrinsic(@llvm.aie2.unpack.I8.I4), %5:vregbank(<32 x s8>), %6:gprregbank(s32)
    $x0 = COPY %7:vregbank(<32 x s16>)
    PseudoRET implicit $lr, implicit $x0
...



---
name:            VLDB_UNPACK_D8_D4_dyn
alignment:       16
legalized:       true
regBankSelected: true
body:             |
  bb.1.entry:
    liveins: $p0, $m0, $r1
    ; CHECK-LABEL: name: VLDB_UNPACK_D8_D4_dyn
    ; CHECK: liveins: $p0, $m0, $r1
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:ep = COPY $p0
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:edj = COPY $m0
    ; CHECK-NEXT: [[COPY2:%[0-9]+]]:er = COPY $r1
    ; CHECK-NEXT: $crunpacksign = COPY [[COPY2]]
    ; CHECK-NEXT: [[VLDB_UNPACK_D8_D4_ag_idx:%[0-9]+]]:vec512 = VLDB_UNPACK_D8_D4_ag_idx [[COPY]], [[COPY1]], implicit $crunpacksign :: (load (<32 x s8>))
    ; CHECK-NEXT: $crunpacksign = MOV_scalar_imm10_pseudo 0
    ; CHECK-NEXT: $x0 = COPY [[VLDB_UNPACK_D8_D4_ag_idx]]
    ; CHECK-NEXT: PseudoRET implicit $lr, implicit $x0
    %1:ptrregbank(p0) = COPY $p0
    %8:modregbank(s20) = COPY $m0
    %6:gprregbank(s32) = COPY $r1
    %5:vregbank(<32 x s8>) = G_AIE_OFFSET_LOAD %1:ptrregbank(p0), %8:modregbank(s20) :: (load (<32 x s8>))
    %7:vregbank(<32 x s16>) = G_INTRINSIC intrinsic(@llvm.aie2.unpack.I8.I4), %5:vregbank(<32 x s8>), %6:gprregbank(s32)
    $x0 = COPY %7:vregbank(<32 x s16>)
    PseudoRET implicit $lr, implicit $x0
...


---
name:            VLDB_UNPACK_S16_S8
alignment:       16
legalized:       true
regBankSelected: true
body:             |
  bb.1.entry:
    liveins: $p0
    ; CHECK-LABEL: name: VLDB_UNPACK_S16_S8
    ; CHECK: liveins: $p0
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:ep = COPY $p0
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:edj = COPY $m0
    ; CHECK-NEXT: [[VLDB_UNPACK_S16_S8_ag_idx:%[0-9]+]]:vec512 = VLDB_UNPACK_S16_S8_ag_idx [[COPY]], [[COPY1]] :: (load (<32 x s8>))
    ; CHECK-NEXT: $x0 = COPY [[VLDB_UNPACK_S16_S8_ag_idx]]
    ; CHECK-NEXT: PseudoRET implicit $lr, implicit $x0
    %1:ptrregbank(p0) = COPY $p0
    %8:modregbank(s20) = COPY $m0
    %6:gprregbank(s32) = G_CONSTANT i32 1
    %5:vregbank(<32 x s8>) = G_AIE_OFFSET_LOAD %1:ptrregbank(p0), %8:modregbank(s20) :: (load (<32 x s8>))
    %7:vregbank(<32 x s16>) = G_INTRINSIC intrinsic(@llvm.aie2.unpack.I16.I8), %5:vregbank(<32 x s8>), %6:gprregbank(s32)
    $x0 = COPY %7:vregbank(<32 x s16>)
    PseudoRET implicit $lr, implicit $x0
...


---
name:            VLDB_UNPACK_D16_D8
alignment:       16
legalized:       true
regBankSelected: true
body:             |
  bb.1.entry:
    liveins: $p0, $r0, $r1
    ; CHECK-LABEL: name: VLDB_UNPACK_D16_D8
    ; CHECK: liveins: $p0, $r0, $r1
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:ep = COPY $p0
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:edj = COPY $m0
    ; CHECK-NEXT: [[VLDB_UNPACK_D16_D8_ag_idx:%[0-9]+]]:vec512 = VLDB_UNPACK_D16_D8_ag_idx [[COPY]], [[COPY1]], implicit $crunpacksign :: (load (<32 x s8>))
    ; CHECK-NEXT: $x0 = COPY [[VLDB_UNPACK_D16_D8_ag_idx]]
    ; CHECK-NEXT: PseudoRET implicit $lr, implicit $x0
    %1:ptrregbank(p0) = COPY $p0
    %8:modregbank(s20) = COPY $m0
    %6:gprregbank(s32) = G_CONSTANT i32 0
    %5:vregbank(<32 x s8>) = G_AIE_OFFSET_LOAD %1:ptrregbank(p0), %8:modregbank(s20) :: (load (<32 x s8>))
    %7:vregbank(<32 x s16>) = G_INTRINSIC intrinsic(@llvm.aie2.unpack.I16.I8), %5:vregbank(<32 x s8>), %6:gprregbank(s32)
    $x0 = COPY %7:vregbank(<32 x s16>)
    PseudoRET implicit $lr, implicit $x0
...



---
name:            VLDB_UNPACK_D16_D8_dyn
alignment:       16
legalized:       true
regBankSelected: true
body:             |
  bb.1.entry:
    liveins: $p0, $m0, $r1
    ; CHECK-LABEL: name: VLDB_UNPACK_D16_D8_dyn
    ; CHECK: liveins: $p0, $m0, $r1
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:ep = COPY $p0
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:edj = COPY $m0
    ; CHECK-NEXT: [[COPY2:%[0-9]+]]:er = COPY $r1
    ; CHECK-NEXT: $crunpacksign = COPY [[COPY2]]
    ; CHECK-NEXT: [[VLDB_UNPACK_D16_D8_ag_idx:%[0-9]+]]:vec512 = VLDB_UNPACK_D16_D8_ag_idx [[COPY]], [[COPY1]], implicit $crunpacksign :: (load (<32 x s8>))
    ; CHECK-NEXT: $crunpacksign = MOV_scalar_imm10_pseudo 0
    ; CHECK-NEXT: $x0 = COPY [[VLDB_UNPACK_D16_D8_ag_idx]]
    ; CHECK-NEXT: PseudoRET implicit $lr, implicit $x0
    %1:ptrregbank(p0) = COPY $p0
    %8:modregbank(s20) = COPY $m0
    %6:gprregbank(s32) = COPY $r1
    %5:vregbank(<32 x s8>) = G_AIE_OFFSET_LOAD %1:ptrregbank(p0), %8:modregbank(s20) :: (load (<32 x s8>))
    %7:vregbank(<32 x s16>) = G_INTRINSIC intrinsic(@llvm.aie2.unpack.I16.I8), %5:vregbank(<32 x s8>), %6:gprregbank(s32)
    $x0 = COPY %7:vregbank(<32 x s16>)
    PseudoRET implicit $lr, implicit $x0
...


