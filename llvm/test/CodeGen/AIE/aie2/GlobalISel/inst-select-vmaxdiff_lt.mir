# NOTE: Assertions have been autogenerated by utils/update_mir_test_checks.py
#
# This file is licensed under the Apache License v2.0 with LLVM Exceptions.
# See https://llvm.org/LICENSE.txt for license information.
# SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
#
# (c) Copyright 2023-2024 Advanced Micro Devices, Inc. or its affiliates
# RUN: llc -mtriple aie2 -run-pass=instruction-select %s -verify-machineinstrs -o - | FileCheck %s


---
name:            VMAXDIFF_LT8
alignment:       16
legalized:       true
regBankSelected: true
body:             |
  bb.1.entry:
    liveins: $p0, $r0, $x2, $x3
    ; CHEC
    ; CHECK-LABEL: name: VMAXDIFF_LT8
    ; CHECK: liveins: $p0, $r0, $x2, $x3
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:vec512 = COPY $x2
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:vec512 = COPY $x3
    ; CHECK-NEXT: [[COPY2:%[0-9]+]]:er = COPY $r0
    ; CHECK-NEXT: $crvaddsign = COPY [[COPY2]]
    ; CHECK-NEXT: [[VMAXDIFF_LT_D8_:%[0-9]+]]:vec512, [[VMAXDIFF_LT_D8_1:%[0-9]+]]:el = VMAXDIFF_LT_D8 [[COPY]], [[COPY1]], implicit $crvaddsign
    ; CHECK-NEXT: $crvaddsign = MOV_scalar_imm10_pseudo 0
    ; CHECK-NEXT: $x0 = COPY [[VMAXDIFF_LT_D8_]]
    ; CHECK-NEXT: PseudoRET implicit $lr, implicit $x0
    %1:vregbank(<64 x s8>) = COPY $x2
    %11:vregbank(<64 x s8>) = COPY $x3
    %4:gprregbank(s32) = COPY $r0
    %7:vregbank(<64 x s8>), %8:gprregbank(<2 x s32>) = G_INTRINSIC intrinsic(@llvm.aie2.vmaxdiff.lt8), %1:vregbank(<64 x s8>), %11:vregbank(<64 x s8>), %4:gprregbank(s32)
    $x0 = COPY %7:vregbank(<64 x s8>)
    PseudoRET implicit $lr, implicit $x0
...

---
name:            VMAXDIFF_LT8_SIGN0
alignment:       16
legalized:       true
regBankSelected: true
body:             |
  bb.1.entry:
    liveins: $p0, $x2, $x3
    ; CHECK-LABEL: name: VMAXDIFF_LT8_SIGN0
    ; CHECK: liveins: $p0, $x2, $x3
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:vec512 = COPY $x2
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:vec512 = COPY $x3
    ; CHECK-NEXT: [[VMAX_LT_D8_:%[0-9]+]]:vec512, [[VMAX_LT_D8_1:%[0-9]+]]:el = VMAX_LT_D8 [[COPY]], [[COPY1]], implicit $crvaddsign
    ; CHECK-NEXT: $x0 = COPY [[VMAX_LT_D8_]]
    ; CHECK-NEXT: PseudoRET implicit $lr, implicit $x0
    %1:vregbank(<64 x s8>) = COPY $x2
    %11:vregbank(<64 x s8>) = COPY $x3
    %5:gprregbank(s32) = G_CONSTANT i32 0
    %3:vregbank(<64 x s8>), %4:gprregbank(<2 x s32>) = G_INTRINSIC intrinsic(@llvm.aie2.vmaxdiff.lt8), %1:vregbank(<64 x s8>), %11:vregbank(<64 x s8>), %5:gprregbank(s32)
    $x0 = COPY %3:vregbank(<64 x s8>)
    PseudoRET implicit $lr, implicit $x0
...

---
name:            VMAXDIFF_LT8_SIGN1
alignment:       16
legalized:       true
regBankSelected: true
body:             |
  bb.1.entry:
    liveins: $p0, $x2, $x3
    ; CHECK-LABEL: name: VMAXDIFF_LT8_SIGN1
    ; CHECK: liveins: $p0, $x2, $x3
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:vec512 = COPY $x2
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:vec512 = COPY $x3
    ; CHECK-NEXT: [[VMAX_LT_S8_:%[0-9]+]]:vec512, [[VMAX_LT_S8_1:%[0-9]+]]:el = VMAX_LT_S8 [[COPY]], [[COPY1]]
    ; CHECK-NEXT: $x0 = COPY [[VMAX_LT_S8_]]
    ; CHECK-NEXT: PseudoRET implicit $lr, implicit $x0
    %1:vregbank(<64 x s8>) = COPY $x2
    %11:vregbank(<64 x s8>) = COPY $x3
    %5:gprregbank(s32) = G_CONSTANT i32 1
    %3:vregbank(<64 x s8>), %4:gprregbank(<2 x s32>) = G_INTRINSIC intrinsic(@llvm.aie2.vmaxdiff.lt8), %1:vregbank(<64 x s8>), %11:vregbank(<64 x s8>), %5:gprregbank(s32)
    $x0 = COPY %3:vregbank(<64 x s8>)
    PseudoRET implicit $lr, implicit $x0
...

---
name:            VMAXDIFF_LT16
alignment:       16
legalized:       true
regBankSelected: true
body:             |
  bb.1.entry:
    liveins: $p0, $r0, $x2, $x3
    ; CHECK-LABEL: name: VMAXDIFF_LT16
    ; CHECK: liveins: $p0, $r0, $x2, $x3
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:vec512 = COPY $x2
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:vec512 = COPY $x3
    ; CHECK-NEXT: [[COPY2:%[0-9]+]]:er = COPY $r0
    ; CHECK-NEXT: $crvaddsign = COPY [[COPY2]]
    ; CHECK-NEXT: [[VMAXDIFF_LT_D16_:%[0-9]+]]:vec512, [[VMAXDIFF_LT_D16_1:%[0-9]+]]:ers8 = VMAXDIFF_LT_D16 [[COPY]], [[COPY1]], implicit $crvaddsign
    ; CHECK-NEXT: $crvaddsign = MOV_scalar_imm10_pseudo 0
    ; CHECK-NEXT: $x0 = COPY [[VMAXDIFF_LT_D16_]]
    ; CHECK-NEXT: PseudoRET implicit $lr, implicit $x0
    %1:vregbank(<32 x s16>) = COPY $x2
    %11:vregbank(<32 x s16>) = COPY $x3
    %4:gprregbank(s32) = COPY $r0
    %7:vregbank(<32 x s16>), %8:gprregbank(s32) = G_INTRINSIC intrinsic(@llvm.aie2.vmaxdiff.lt16), %1:vregbank(<32 x s16>), %11:vregbank(<32 x s16>), %4:gprregbank(s32)
    $x0 = COPY %7:vregbank(<32 x s16>)
    PseudoRET implicit $lr, implicit $x0
...

---
name:            VMAXDIFF_LT16_SIGN0
alignment:       16
legalized:       true
regBankSelected: true
body:             |
  bb.1.entry:
    liveins: $p0, $x2, $x3
    ; CHECK-LABEL: name: VMAXDIFF_LT16_SIGN0
    ; CHECK: liveins: $p0, $x2, $x3
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:vec512 = COPY $x2
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:vec512 = COPY $x3
    ; CHECK-NEXT: [[VMAX_LT_D16_:%[0-9]+]]:vec512, [[VMAX_LT_D16_1:%[0-9]+]]:ers8 = VMAX_LT_D16 [[COPY]], [[COPY1]], implicit $crvaddsign
    ; CHECK-NEXT: $x0 = COPY [[VMAX_LT_D16_]]
    ; CHECK-NEXT: PseudoRET implicit $lr, implicit $x0
    %1:vregbank(<32 x s16>) = COPY $x2
    %11:vregbank(<32 x s16>) = COPY $x3
    %5:gprregbank(s32) = G_CONSTANT i32 0
    %3:vregbank(<32 x s16>), %4:gprregbank(s32) = G_INTRINSIC intrinsic(@llvm.aie2.vmaxdiff.lt16), %1:vregbank(<32 x s16>), %11:vregbank(<32 x s16>), %5:gprregbank(s32)
    $x0 = COPY %3:vregbank(<32 x s16>)
    PseudoRET implicit $lr, implicit $x0
...

---
name:            VMAXDIFF_LT16_SIGN1
alignment:       16
legalized:       true
regBankSelected: true
body:             |
  bb.1.entry:
    liveins: $p0, $x2, $x3
    ; CHECK-LABEL: name: VMAXDIFF_LT16_SIGN1
    ; CHECK: liveins: $p0, $x2, $x3
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:vec512 = COPY $x2
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:vec512 = COPY $x3
    ; CHECK-NEXT: [[VMAX_LT_S16_:%[0-9]+]]:vec512, [[VMAX_LT_S16_1:%[0-9]+]]:ers8 = VMAX_LT_S16 [[COPY]], [[COPY1]]
    ; CHECK-NEXT: $x0 = COPY [[VMAX_LT_S16_]]
    ; CHECK-NEXT: PseudoRET implicit $lr, implicit $x0
    %1:vregbank(<32 x s16>) = COPY $x2
    %11:vregbank(<32 x s16>) = COPY $x3
    %5:gprregbank(s32) = G_CONSTANT i32 1
    %3:vregbank(<32 x s16>), %4:gprregbank(s32) = G_INTRINSIC intrinsic(@llvm.aie2.vmaxdiff.lt16), %1:vregbank(<32 x s16>), %11:vregbank(<32 x s16>), %5:gprregbank(s32)
    $x0 = COPY %3:vregbank(<32 x s16>)
    PseudoRET implicit $lr, implicit $x0
...

---
name:            VMAXDIFF_LT32
alignment:       16
legalized:       true
regBankSelected: true
body:             |
  bb.1.entry:
    liveins: $p0, $r0, $x2, $x3
    ; CHECK-LABEL: name: VMAXDIFF_LT32
    ; CHECK: liveins: $p0, $r0, $x2, $x3
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:vec512 = COPY $x2
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:vec512 = COPY $x3
    ; CHECK-NEXT: [[COPY2:%[0-9]+]]:er = COPY $r0
    ; CHECK-NEXT: $crvaddsign = COPY [[COPY2]]
    ; CHECK-NEXT: [[VMAXDIFF_LT_D32_:%[0-9]+]]:vec512, [[VMAXDIFF_LT_D32_1:%[0-9]+]]:ers8 = VMAXDIFF_LT_D32 [[COPY]], [[COPY1]], implicit $crvaddsign
    ; CHECK-NEXT: $crvaddsign = MOV_scalar_imm10_pseudo 0
    ; CHECK-NEXT: $x0 = COPY [[VMAXDIFF_LT_D32_]]
    ; CHECK-NEXT: PseudoRET implicit $lr, implicit $x0
    %1:vregbank(<16 x s32>) = COPY $x2
    %11:vregbank(<16 x s32>) = COPY $x3
    %4:gprregbank(s32) = COPY $r0
    %7:vregbank(<16 x s32>), %8:gprregbank(s32) = G_INTRINSIC intrinsic(@llvm.aie2.vmaxdiff.lt32), %1:vregbank(<16 x s32>), %11:vregbank(<16 x s32>), %4:gprregbank(s32)
    $x0 = COPY %7:vregbank(<16 x s32>)
    PseudoRET implicit $lr, implicit $x0
...

---
name:            VMAXDIFF_LT32_SIGN0
alignment:       16
legalized:       true
regBankSelected: true
body:             |
  bb.1.entry:
    liveins: $p0, $x2, $x3
    ; CHECK-LABEL: name: VMAXDIFF_LT32_SIGN0
    ; CHECK: liveins: $p0, $x2, $x3
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:vec512 = COPY $x2
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:vec512 = COPY $x3
    ; CHECK-NEXT: [[VMAX_LT_D32_:%[0-9]+]]:vec512, [[VMAX_LT_D32_1:%[0-9]+]]:ers8 = VMAX_LT_D32 [[COPY]], [[COPY1]], implicit $crvaddsign
    ; CHECK-NEXT: $x0 = COPY [[VMAX_LT_D32_]]
    ; CHECK-NEXT: PseudoRET implicit $lr, implicit $x0
    %1:vregbank(<16 x s32>) = COPY $x2
    %11:vregbank(<16 x s32>) = COPY $x3
    %5:gprregbank(s32) = G_CONSTANT i32 0
    %3:vregbank(<16 x s32>), %4:gprregbank(s32) = G_INTRINSIC intrinsic(@llvm.aie2.vmaxdiff.lt32), %1:vregbank(<16 x s32>), %11:vregbank(<16 x s32>), %5:gprregbank(s32)
    $x0 = COPY %3:vregbank(<16 x s32>)
    PseudoRET implicit $lr, implicit $x0
...

---
name:            VMAXDIFF_LT32_SIGN1
alignment:       16
legalized:       true
regBankSelected: true
body:             |
  bb.1.entry:
    liveins: $p0, $x2, $x3
    ; CHECK-LABEL: name: VMAXDIFF_LT32_SIGN1
    ; CHECK: liveins: $p0, $x2, $x3
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:vec512 = COPY $x2
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:vec512 = COPY $x3
    ; CHECK-NEXT: [[VMAX_LT_S32_:%[0-9]+]]:vec512, [[VMAX_LT_S32_1:%[0-9]+]]:ers8 = VMAX_LT_S32 [[COPY]], [[COPY1]]
    ; CHECK-NEXT: $x0 = COPY [[VMAX_LT_S32_]]
    ; CHECK-NEXT: PseudoRET implicit $lr, implicit $x0
    %1:vregbank(<16 x s32>) = COPY $x2
    %11:vregbank(<16 x s32>) = COPY $x3
    %5:gprregbank(s32) = G_CONSTANT i32 1
    %3:vregbank(<16 x s32>), %4:gprregbank(s32) = G_INTRINSIC intrinsic(@llvm.aie2.vmaxdiff.lt32), %1:vregbank(<16 x s32>), %11:vregbank(<16 x s32>), %5:gprregbank(s32)
    $x0 = COPY %3:vregbank(<16 x s32>)
    PseudoRET implicit $lr, implicit $x0
...
