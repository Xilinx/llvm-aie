# NOTE: Assertions have been autogenerated by utils/update_mir_test_checks.py
#
# This file is licensed under the Apache License v2.0 with LLVM Exceptions.
# See https://llvm.org/LICENSE.txt for license information.
# SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
#
# (c) Copyright 2023-2024 Advanced Micro Devices, Inc. or its affiliates
# RUN: llc -mtriple aie2 -start-before=aie2-postlegalizer-custom-combiner -stop-after=instruction-select %s -verify-machineinstrs -o - | FileCheck %s

# The way we currently select 512-bit offset memory operantions when the offset
# does not fit in the immediate range of the instruction leads to unnecessarily
# selecting an identical PADD twice in certain situations.
# For simpler tests CSE picks up on these cases and removes one copy of the PADD
# further down the compilation pipeline, but in both examples below the
# duplicated PADD reaches the final assembly.
# TODO: This can and should be avoided!

---
name:            load
legalized:       true
tracksRegLiveness: true
body:             |
  bb.0:
    liveins: $p0
    ; CHECK-LABEL: name: load
    ; CHECK: liveins: $p0
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:ep = COPY $p0
    ; CHECK-NEXT: [[MOV_RLC_imm10_pseudo:%[0-9]+]]:er = MOV_RLC_imm10_pseudo 24
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:edj = COPY [[MOV_RLC_imm10_pseudo]]
    ; CHECK-NEXT: [[COPY2:%[0-9]+]]:em = COPY [[COPY1]]
    ; CHECK-NEXT: [[PADD_mod_pseudo:%[0-9]+]]:ep = PADD_mod_pseudo [[COPY]], [[COPY2]]
    ; CHECK-NEXT: [[COPY3:%[0-9]+]]:em = COPY [[COPY1]]
    ; CHECK-NEXT: [[PADD_mod_pseudo1:%[0-9]+]]:ep = PADD_mod_pseudo [[COPY]], [[COPY3]]
    ; CHECK-NEXT: [[VLDA_dmw_lda_w_ag_idx_imm:%[0-9]+]]:vec256 = VLDA_dmw_lda_w_ag_idx_imm [[PADD_mod_pseudo1]], 32 :: (load (<16 x s16>) from unknown-address + 32)
    ; CHECK-NEXT: [[VLDA_dmw_lda_w_ag_idx_imm1:%[0-9]+]]:vec256 = VLDA_dmw_lda_w_ag_idx_imm [[PADD_mod_pseudo1]], 0 :: (load (<16 x s16>), align 64)
    ; CHECK-NEXT: [[REG_SEQUENCE:%[0-9]+]]:vec512 = REG_SEQUENCE [[VLDA_dmw_lda_w_ag_idx_imm1]], %subreg.sub_256_lo, [[VLDA_dmw_lda_w_ag_idx_imm]], %subreg.sub_256_hi
    ; CHECK-NEXT: [[VLDA_dmw_lda_w_ag_idx:%[0-9]+]]:vec256 = VLDA_dmw_lda_w_ag_idx [[PADD_mod_pseudo]], [[COPY1]] :: (load (<16 x s16>))
    ; CHECK-NEXT: PseudoRET implicit $lr, implicit [[PADD_mod_pseudo]], implicit [[REG_SEQUENCE]], implicit [[VLDA_dmw_lda_w_ag_idx]]
    %0:_(p0) = COPY $p0
    %1:_(s32) = G_CONSTANT i32 24
    %2:_(s20) = G_TRUNC %1
    %3:_(p0) = G_PTR_ADD %0, %2
    %4:_(<32 x s16>) = G_LOAD %3(p0) :: (load (<32 x s16>))
    %5:_(p0) = G_PTR_ADD %3, %2
    %6:_(<16 x s16>) = G_LOAD %5(p0) :: (load (<16 x s16>))
    PseudoRET implicit $lr, implicit %3, implicit %4, implicit %6
...

---
name:            store
legalized:       true
tracksRegLiveness: true
body:             |
  bb.0:
    liveins: $p0, $x0, $wl2
    ; CHECK-LABEL: name: store
    ; CHECK: liveins: $p0, $x0, $wl2
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:ep = COPY $p0
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:vec512 = COPY $x0
    ; CHECK-NEXT: [[COPY2:%[0-9]+]]:vec256 = COPY $wl2
    ; CHECK-NEXT: [[MOV_RLC_imm10_pseudo:%[0-9]+]]:er = MOV_RLC_imm10_pseudo 24
    ; CHECK-NEXT: [[COPY3:%[0-9]+]]:edj = COPY [[MOV_RLC_imm10_pseudo]]
    ; CHECK-NEXT: [[COPY4:%[0-9]+]]:em = COPY [[COPY3]]
    ; CHECK-NEXT: [[PADD_mod_pseudo:%[0-9]+]]:ep = PADD_mod_pseudo [[COPY]], [[COPY4]]
    ; CHECK-NEXT: [[COPY5:%[0-9]+]]:vec256 = COPY [[COPY1]].sub_256_lo
    ; CHECK-NEXT: [[COPY6:%[0-9]+]]:vec256 = COPY [[COPY1]].sub_256_hi
    ; CHECK-NEXT: [[COPY7:%[0-9]+]]:em = COPY [[COPY3]]
    ; CHECK-NEXT: [[PADD_mod_pseudo1:%[0-9]+]]:ep = PADD_mod_pseudo [[COPY]], [[COPY7]]
    ; CHECK-NEXT: VST_dmw_sts_w_ag_idx_imm [[COPY6]], [[PADD_mod_pseudo1]], 32 :: (store (<16 x s16>) into unknown-address + 32)
    ; CHECK-NEXT: VST_dmw_sts_w_ag_idx_imm [[COPY5]], [[PADD_mod_pseudo1]], 0 :: (store (<16 x s16>), align 64)
    ; CHECK-NEXT: VST_dmw_sts_w_ag_idx [[COPY2]], [[PADD_mod_pseudo]], [[COPY3]] :: (store (<16 x s16>))
    ; CHECK-NEXT: PseudoRET implicit $lr, implicit [[PADD_mod_pseudo]]
    %0:_(p0) = COPY $p0
    %1:_(<32 x s16>) = COPY $x0
    %2:_(<16 x s16>) = COPY $wl2
    %3:_(s32) = G_CONSTANT i32 24
    %4:_(s20) = G_TRUNC %3
    %5:_(p0) = G_PTR_ADD %0, %4
    G_STORE %1, %5(p0) :: (store (<32 x s16>))
    %6:_(p0) = G_PTR_ADD %5, %4
    G_STORE %2, %6(p0) :: (store (<16 x s16>))
    PseudoRET implicit $lr, implicit %5
...
