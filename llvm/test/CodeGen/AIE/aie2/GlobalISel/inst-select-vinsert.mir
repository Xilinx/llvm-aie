# NOTE: Assertions have been autogenerated by utils/update_mir_test_checks.py
#
# This file is licensed under the Apache License v2.0 with LLVM Exceptions.
# See https://llvm.org/LICENSE.txt for license information.
# SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
#
# (c) Copyright 2023-2024 Advanced Micro Devices, Inc. or its affiliates
# RUN: llc -mtriple aie2 -run-pass=instruction-select %s -verify-machineinstrs -o - | FileCheck %s

---
name:            VINSERT_8
alignment:       16
legalized:       true
regBankSelected: true
body:             |
   bb.1.entry:
     liveins: $r0, $r1, $x2
    ; CHECK-LABEL: name: VINSERT_8
    ; CHECK: liveins: $r0, $r1, $x2
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:vec512 = COPY $x2
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:er29 = COPY $r0
    ; CHECK-NEXT: [[COPY2:%[0-9]+]]:er = COPY $r1
    ; CHECK-NEXT: [[VINSERT_8_:%[0-9]+]]:vec512 = VINSERT_8 [[COPY]], [[COPY1]], [[COPY2]]
    ; CHECK-NEXT: $x0 = COPY [[VINSERT_8_]]
    ; CHECK-NEXT: PseudoRET implicit $lr, implicit $x0
     %1:vregbank(<64 x s8>) = COPY $x2
     %2:gprregbank(s32) = COPY $r0
     %4:gprregbank(s32) = COPY $r1
     %5:gprregbank(s32) = G_ASSERT_SEXT %4:gprregbank, 8
     %6:vregbank(<16 x s32>) = G_BITCAST %1:vregbank(<64 x s8>)
     %8:vregbank(<16 x s32>) = G_INTRINSIC intrinsic(@llvm.aie2.vinsert8.I512), %6:vregbank(<16 x s32>), %2:gprregbank(s32), %5:gprregbank(s32)
     %0:vregbank(<64 x s8>) = G_BITCAST %8:vregbank(<16 x s32>)
     $x0 = COPY %0:vregbank(<64 x s8>)
     PseudoRET implicit $lr, implicit $x0
...

---
name:            VINSERT_16
alignment:       16
legalized:       true
regBankSelected: true
body:             |
   bb.1.entry:
     liveins: $r0, $r1, $x2
    ; CHECK-LABEL: name: VINSERT_16
    ; CHECK: liveins: $r0, $r1, $x2
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:vec512 = COPY $x2
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:er29 = COPY $r0
    ; CHECK-NEXT: [[COPY2:%[0-9]+]]:er = COPY $r1
    ; CHECK-NEXT: [[VINSERT_16_:%[0-9]+]]:vec512 = VINSERT_16 [[COPY]], [[COPY1]], [[COPY2]]
    ; CHECK-NEXT: $x0 = COPY [[VINSERT_16_]]
    ; CHECK-NEXT: PseudoRET implicit $lr, implicit $x0
     %1:vregbank(<64 x s8>) = COPY $x2
     %2:gprregbank(s32) = COPY $r0
     %4:gprregbank(s32) = COPY $r1
     %5:gprregbank(s32) = G_ASSERT_SEXT %4:gprregbank, 16
     %6:vregbank(<16 x s32>) = G_BITCAST %1:vregbank(<64 x s8>)
     %8:vregbank(<16 x s32>) = G_INTRINSIC intrinsic(@llvm.aie2.vinsert16.I512), %6:vregbank(<16 x s32>), %2:gprregbank(s32), %5:gprregbank(s32)
     %0:vregbank(<64 x s8>) = G_BITCAST %8:vregbank(<16 x s32>)
     $x0 = COPY %0:vregbank(<64 x s8>)
     PseudoRET implicit $lr, implicit $x0
...

---
name:            VINSERT_32
alignment:       16
legalized:       true
regBankSelected: true
body:             |
   bb.1.entry:
     liveins: $r0, $r1, $x2
    ; CHECK-LABEL: name: VINSERT_32
    ; CHECK: liveins: $r0, $r1, $x2
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:vec512 = COPY $x2
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:er29 = COPY $r0
    ; CHECK-NEXT: [[COPY2:%[0-9]+]]:er = COPY $r1
    ; CHECK-NEXT: [[VINSERT_32_:%[0-9]+]]:vec512 = VINSERT_32 [[COPY]], [[COPY1]], [[COPY2]]
    ; CHECK-NEXT: $x0 = COPY [[VINSERT_32_]]
    ; CHECK-NEXT: PseudoRET implicit $lr, implicit $x0
     %1:vregbank(<64 x s8>) = COPY $x2
     %2:gprregbank(s32) = COPY $r0
     %3:gprregbank(s32) = COPY $r1
     %4:vregbank(<16 x s32>) = G_BITCAST %1:vregbank(<64 x s8>)
     %5:vregbank(<16 x s32>) = G_INTRINSIC intrinsic(@llvm.aie2.vinsert32.I512), %4:vregbank(<16 x s32>), %2:gprregbank(s32), %3:gprregbank(s32)
     %0:vregbank(<64 x s8>) = G_BITCAST %5:vregbank(<16 x s32>)
     $x0 = COPY %0:vregbank(<64 x s8>)
     PseudoRET implicit $lr, implicit $x0
...


---
name:            VINSERT_64
alignment:       16
legalized:       true
regBankSelected: true
body:             |
   bb.1.entry:
     liveins: $r0, $l0, $x2
    ; CHECK-LABEL: name: VINSERT_64
    ; CHECK: liveins: $r0, $l0, $x2
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:vec512 = COPY $x2
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:er29 = COPY $r0
    ; CHECK-NEXT: [[COPY2:%[0-9]+]]:el = COPY $l0
    ; CHECK-NEXT: [[VINSERT_64_:%[0-9]+]]:vec512 = VINSERT_64 [[COPY]], [[COPY1]], [[COPY2]]
    ; CHECK-NEXT: $x0 = COPY [[VINSERT_64_]]
    ; CHECK-NEXT: PseudoRET implicit $lr, implicit $x0
     %1:vregbank(<64 x s8>) = COPY $x2
     %2:gprregbank(s32) = COPY $r0
     %3:el(<2 x s32>) = COPY $l0
     %4:vregbank(<16 x s32>) = G_BITCAST %1:vregbank(<64 x s8>)
     %5:vregbank(<16 x s32>) = G_INTRINSIC intrinsic(@llvm.aie2.vinsert64.I512), %4:vregbank(<16 x s32>), %2:gprregbank(s32), %3:el(<2 x s32>)
     %0:vregbank(<64 x s8>) = G_BITCAST %5:vregbank(<16 x s32>)
     $x0 = COPY %0:vregbank(<64 x s8>)
     PseudoRET implicit $lr, implicit $x0
...

---
name:            VINSERT_16_bf
alignment:       16
legalized:       true
regBankSelected: true
body:             |
  bb.1.entry:
    liveins: $r0, $r1, $x2
    ; CHECK-LABEL: name: VINSERT_16_bf
    ; CHECK: liveins: $r0, $r1, $x2
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:vec512 = COPY $x2
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:er29 = COPY $r0
    ; CHECK-NEXT: [[COPY2:%[0-9]+]]:er = COPY $r1
    ; CHECK-NEXT: [[VINSERT_16_:%[0-9]+]]:vec512 = VINSERT_16 [[COPY]], [[COPY1]], [[COPY2]]
    ; CHECK-NEXT: $x0 = COPY [[VINSERT_16_]]
    ; CHECK-NEXT: PseudoRET implicit $lr, implicit $x0
    %1:vregbank(<32 x s16>) = COPY $x2
    %2:gprregbank(s32) = COPY $r0
    %4:gprregbank(s32) = COPY $r1
    %3:gprregbank(s16) = G_TRUNC %4:gprregbank(s32)
    %0:vregbank(<32 x s16>) = G_INTRINSIC intrinsic(@llvm.aie2.vinsert16.bf512), %1:vregbank(<32 x s16>), %2:gprregbank(s32), %3:gprregbank(s16)
    $x0 = COPY %0:vregbank(<32 x s16>)
    PseudoRET implicit $lr, implicit $x0
...


---
name:            VINSERT_32_bf
alignment:       16
legalized:       true
regBankSelected: true
body:             |
  bb.1.entry:
    liveins: $r0, $r1, $x2
    ; CHECK-LABEL: name: VINSERT_32_bf
    ; CHECK: liveins: $r0, $r1, $x2
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:vec512 = COPY $x2
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:er29 = COPY $r0
    ; CHECK-NEXT: [[COPY2:%[0-9]+]]:er = COPY $r1
    ; CHECK-NEXT: [[VINSERT_32_:%[0-9]+]]:vec512 = VINSERT_32 [[COPY]], [[COPY1]], [[COPY2]]
    ; CHECK-NEXT: $x0 = COPY [[VINSERT_32_]]
    ; CHECK-NEXT: PseudoRET implicit $lr, implicit $x0
    %1:vregbank(<32 x s16>) = COPY $x2
    %2:gprregbank(s32) = COPY $r0
    %3:gprregbank(<2 x s16>) = COPY $r1
    %0:vregbank(<32 x s16>) = G_INTRINSIC intrinsic(@llvm.aie2.vinsert32.bf512), %1:vregbank(<32 x s16>), %2:gprregbank(s32), %3:gprregbank(<2 x s16>)
    $x0 = COPY %0:vregbank(<32 x s16>)
    PseudoRET implicit $lr, implicit $x0
...

---
name:            VINSERT_64_bf
alignment:       16
legalized:       true
regBankSelected: true
body:             |
  bb.1.entry:
    liveins: $l0, $r0, $x2
    ; CHECK-LABEL: name: VINSERT_64_bf
    ; CHECK: liveins: $l0, $r0, $x2
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:vec512 = COPY $x2
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:er29 = COPY $r0
    ; CHECK-NEXT: [[COPY2:%[0-9]+]]:el = COPY $l0
    ; CHECK-NEXT: [[VINSERT_64_:%[0-9]+]]:vec512 = VINSERT_64 [[COPY]], [[COPY1]], [[COPY2]]
    ; CHECK-NEXT: $x0 = COPY [[VINSERT_64_]]
    ; CHECK-NEXT: PseudoRET implicit $lr, implicit $x0
    %1:vregbank(<32 x s16>) = COPY $x2
    %2:gprregbank(s32) = COPY $r0
    %3:gprregbank(<4 x s16>) = COPY $l0
    %0:vregbank(<32 x s16>) = G_INTRINSIC intrinsic(@llvm.aie2.vinsert64.bf512), %1:vregbank(<32 x s16>), %2:gprregbank(s32), %3:gprregbank(<4 x s16>)
    $x0 = COPY %0:vregbank(<32 x s16>)
    PseudoRET implicit $lr, implicit $x0
...

---
name:            VINSERT_accfloat
alignment:       16
legalized:       true
regBankSelected: true
body:             |
  bb.1.entry:
    liveins: $bml1, $r0
    ; CHECK-LABEL: name: VINSERT_accfloat
    ; CHECK: liveins: $bml1, $r0
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:acc512 = COPY $bml1
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:er = COPY $r0
    ; CHECK-NEXT: [[MOV_RLC_imm10_pseudo:%[0-9]+]]:er29 = MOV_RLC_imm10_pseudo 0
    ; CHECK-NEXT: [[COPY2:%[0-9]+]]:mxm = COPY [[COPY]]
    ; CHECK-NEXT: [[VINSERT_32_:%[0-9]+]]:mxm = VINSERT_32 [[COPY2]], [[MOV_RLC_imm10_pseudo]], [[COPY1]]
    ; CHECK-NEXT: [[COPY3:%[0-9]+]]:acc512 = COPY [[VINSERT_32_]]
    ; CHECK-NEXT: $bml0 = COPY [[COPY3]]
    ; CHECK-NEXT: PseudoRET implicit $lr, implicit $bml0
    %1:accregbank(<8 x s64>) = COPY $bml1
    %2:gprregbank(s32) = COPY $r0
    %3:gprregbank(s32) = G_CONSTANT i32 0
    %0:accregbank(<8 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.vinsert32.accfloat), %1:accregbank(<8 x s64>), %3:gprregbank(s32), %2:gprregbank(s32)
    $bml0 = COPY %0:accregbank(<8 x s64>)
    PseudoRET implicit $lr, implicit $bml0
...
