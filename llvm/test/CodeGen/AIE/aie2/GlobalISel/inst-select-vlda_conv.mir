# NOTE: Assertions have been autogenerated by utils/update_mir_test_checks.py
#
# This file is licensed under the Apache License v2.0 with LLVM Exceptions.
# See https://llvm.org/LICENSE.txt for license information.
# SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
#
# (c) Copyright 2023-2024 Advanced Micro Devices, Inc. or its affiliates

# RUN: llc -mtriple aie2 -run-pass=instruction-select %s -verify-machineinstrs -o - | FileCheck %s

---
name:            VLDA_CONV
legalized:       true
regBankSelected: true
tracksRegLiveness: true
body: |
  bb.0:
    liveins: $p0, $r0
    ; CHECK-LABEL: name: VLDA_CONV
    ; CHECK: liveins: $p0, $r0
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:ep = COPY $p0
    ; CHECK-NEXT: [[VLDA_CONV_FP32_BF16_ag_idx_imm:%[0-9]+]]:acc512 = VLDA_CONV_FP32_BF16_ag_idx_imm [[COPY]], 0 :: (load (<16 x s16>))
    ; CHECK-NEXT: PseudoRET implicit $lr, implicit [[VLDA_CONV_FP32_BF16_ag_idx_imm]]
    %0:ptrregbank(p0) = COPY $p0
    %1:vregbank(<16 x s16>) = G_LOAD %0:ptrregbank(p0) :: (load (<16 x s16>))
    %2:accregbank(<8 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.v16bf16.to.v16accfloat), %1:vregbank(<16 x s16>)
    PseudoRET implicit $lr, implicit %2
...


---
name:            VLDA_CONV_OFFSET
legalized:       true
regBankSelected: true
tracksRegLiveness: true
body: |
  bb.0:
    liveins: $p0, $m0
    ; CHECK-LABEL: name: VLDA_CONV_OFFSET
    ; CHECK: liveins: $p0, $m0
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:ep = COPY $p0
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:edj = COPY $m0
    ; CHECK-NEXT: [[MOV_PD_imm10_pseudo:%[0-9]+]]:edj = MOV_PD_imm10_pseudo 16
    ; CHECK-NEXT: [[MOV_PD_imm10_pseudo1:%[0-9]+]]:edj = MOV_PD_imm10_pseudo 128
    ; CHECK-NEXT: [[VLDA_CONV_FP32_BF16_ag_idx:%[0-9]+]]:acc512 = VLDA_CONV_FP32_BF16_ag_idx [[COPY]], [[COPY1]] :: (load (<16 x s16>))
    ; CHECK-NEXT: [[VLDA_CONV_FP32_BF16_ag_idx_imm:%[0-9]+]]:acc512 = VLDA_CONV_FP32_BF16_ag_idx_imm [[COPY]], 0 :: (load (<16 x s16>))
    ; CHECK-NEXT: [[VLDA_CONV_FP32_BF16_ag_idx1:%[0-9]+]]:acc512 = VLDA_CONV_FP32_BF16_ag_idx [[COPY]], [[MOV_PD_imm10_pseudo]] :: (load (<16 x s16>))
    ; CHECK-NEXT: [[VLDA_CONV_FP32_BF16_ag_idx_imm1:%[0-9]+]]:acc512 = VLDA_CONV_FP32_BF16_ag_idx_imm [[COPY]], -128 :: (load (<16 x s16>))
    ; CHECK-NEXT: [[VLDA_CONV_FP32_BF16_ag_idx_imm2:%[0-9]+]]:acc512 = VLDA_CONV_FP32_BF16_ag_idx_imm [[COPY]], 96 :: (load (<16 x s16>))
    ; CHECK-NEXT: [[VLDA_CONV_FP32_BF16_ag_idx2:%[0-9]+]]:acc512 = VLDA_CONV_FP32_BF16_ag_idx [[COPY]], [[MOV_PD_imm10_pseudo1]] :: (load (<16 x s16>))
    ; CHECK-NEXT: PseudoRET implicit $lr, implicit [[VLDA_CONV_FP32_BF16_ag_idx]], implicit [[VLDA_CONV_FP32_BF16_ag_idx_imm]], implicit [[VLDA_CONV_FP32_BF16_ag_idx1]], implicit [[VLDA_CONV_FP32_BF16_ag_idx_imm1]], implicit [[VLDA_CONV_FP32_BF16_ag_idx_imm2]], implicit [[VLDA_CONV_FP32_BF16_ag_idx2]]
    %0:ptrregbank(p0) = COPY $p0
    %7:modregbank(s20) = COPY $m0
    %8:modregbank(s20) = G_CONSTANT i20 0
    %9:modregbank(s20) = G_CONSTANT i20 16
    %10:modregbank(s20) = G_CONSTANT i20 -128
    %11:modregbank(s20) = G_CONSTANT i20 96
    %12:modregbank(s20) = G_CONSTANT i20 128
    %25:vregbank(<16 x s16>) = G_AIE_OFFSET_LOAD %0, %7 :: (load (<16 x s16>))
    %26:vregbank(<16 x s16>) = G_AIE_OFFSET_LOAD %0, %8 :: (load (<16 x s16>))
    %27:vregbank(<16 x s16>) = G_AIE_OFFSET_LOAD %0, %9 :: (load (<16 x s16>))
    %28:vregbank(<16 x s16>) = G_AIE_OFFSET_LOAD %0, %10 :: (load (<16 x s16>))
    %29:vregbank(<16 x s16>) = G_AIE_OFFSET_LOAD %0, %11 :: (load (<16 x s16>))
    %30:vregbank(<16 x s16>) = G_AIE_OFFSET_LOAD %0, %12 :: (load (<16 x s16>))
    %103:accregbank(<8 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.v16bf16.to.v16accfloat), %25:vregbank(<16 x s16>)
    %104:accregbank(<8 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.v16bf16.to.v16accfloat), %26:vregbank(<16 x s16>)
    %105:accregbank(<8 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.v16bf16.to.v16accfloat), %27:vregbank(<16 x s16>)
    %106:accregbank(<8 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.v16bf16.to.v16accfloat), %28:vregbank(<16 x s16>)
    %107:accregbank(<8 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.v16bf16.to.v16accfloat), %29:vregbank(<16 x s16>)
    %108:accregbank(<8 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.v16bf16.to.v16accfloat), %30:vregbank(<16 x s16>)
    PseudoRET implicit $lr, implicit %103, implicit %104, implicit %105, implicit %106, implicit %107, implicit %108
...



---
name:            VLDA_CONV_2D
legalized:       true
regBankSelected: true
tracksRegLiveness: true
body: |
  bb.0:
    liveins: $p0, $r1, $amll0
    ; CHECK-LABEL: name: VLDA_CONV_2D
    ; CHECK: liveins: $p0, $r1, $amll0
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:ep = COPY $p0
    ; CHECK-NEXT: [[MOV_PD_imm10_pseudo:%[0-9]+]]:em = MOV_PD_imm10_pseudo 1
    ; CHECK-NEXT: [[MOV_PD_imm10_pseudo1:%[0-9]+]]:edj = MOV_PD_imm10_pseudo 2
    ; CHECK-NEXT: [[MOV_PD_imm10_pseudo2:%[0-9]+]]:edn = MOV_PD_imm10_pseudo 3
    ; CHECK-NEXT: [[MOV_PD_imm10_pseudo3:%[0-9]+]]:edc = MOV_PD_imm10_pseudo 4
    ; CHECK-NEXT: [[REG_SEQUENCE:%[0-9]+]]:ed = REG_SEQUENCE [[MOV_PD_imm10_pseudo]], %subreg.sub_mod, [[MOV_PD_imm10_pseudo2]], %subreg.sub_dim_size, [[MOV_PD_imm10_pseudo1]], %subreg.sub_dim_stride, [[MOV_PD_imm10_pseudo3]], %subreg.sub_dim_count
    ; CHECK-NEXT: [[VLDA_2D_CONV_FP32_BF16_:%[0-9]+]]:acc512, [[VLDA_2D_CONV_FP32_BF16_1:%[0-9]+]]:ep, [[VLDA_2D_CONV_FP32_BF16_2:%[0-9]+]]:edc = VLDA_2D_CONV_FP32_BF16 [[COPY]], [[REG_SEQUENCE]] :: (load (<16 x s16>))
    ; CHECK-NEXT: PseudoRET implicit $lr, implicit [[VLDA_2D_CONV_FP32_BF16_]]
    %0:ptrregbank(p0) = COPY $p0
    %1:em(s20) = G_CONSTANT i20 1
    %2:edj(s20) = G_CONSTANT i20 2
    %3:edn(s20) = G_CONSTANT i20 3
    %4:edc(s20) = G_CONSTANT i20 4
    %25:vregbank(<16 x s16>), %5:ptrregbank(p0), %6:modregbank(s20) = G_AIE_POSTINC_2D_LOAD %0, %1, %2, %3, %4 :: (load (<16 x s16>))
    %103:accregbank(<8 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.v16bf16.to.v16accfloat), %25:vregbank(<16 x s16>)
    PseudoRET implicit $lr, implicit %103
...


---
name:            VLDA_CONV_3D
legalized:       true
regBankSelected: true
tracksRegLiveness: true
body: |
  bb.0:
    liveins: $p0, $r1, $amll0
    ; CHECK-LABEL: name: VLDA_CONV_3D
    ; CHECK: liveins: $p0, $r1, $amll0
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:ep = COPY $p0
    ; CHECK-NEXT: [[MOV_PD_imm10_pseudo:%[0-9]+]]:em = MOV_PD_imm10_pseudo 1
    ; CHECK-NEXT: [[MOV_PD_imm10_pseudo1:%[0-9]+]]:edj = MOV_PD_imm10_pseudo 2
    ; CHECK-NEXT: [[MOV_PD_imm10_pseudo2:%[0-9]+]]:edj = MOV_PD_imm10_pseudo 3
    ; CHECK-NEXT: [[MOV_PD_imm10_pseudo3:%[0-9]+]]:edn = MOV_PD_imm10_pseudo 4
    ; CHECK-NEXT: [[MOV_PD_imm10_pseudo4:%[0-9]+]]:edn = MOV_PD_imm10_pseudo 5
    ; CHECK-NEXT: [[MOV_PD_imm10_pseudo5:%[0-9]+]]:edc = MOV_PD_imm10_pseudo 6
    ; CHECK-NEXT: [[MOV_PD_imm10_pseudo6:%[0-9]+]]:edc = MOV_PD_imm10_pseudo 7
    ; CHECK-NEXT: [[REG_SEQUENCE:%[0-9]+]]:eds = REG_SEQUENCE [[MOV_PD_imm10_pseudo]], %subreg.sub_mod, [[MOV_PD_imm10_pseudo3]], %subreg.sub_dim_size, [[MOV_PD_imm10_pseudo1]], %subreg.sub_dim_stride, [[MOV_PD_imm10_pseudo5]], %subreg.sub_dim_count, [[MOV_PD_imm10_pseudo4]], %subreg.sub_hi_dim_then_sub_dim_size, [[MOV_PD_imm10_pseudo2]], %subreg.sub_hi_dim_then_sub_dim_stride, [[MOV_PD_imm10_pseudo6]], %subreg.sub_hi_dim_then_sub_dim_count
    ; CHECK-NEXT: [[VLDA_3D_CONV_FP32_BF16_:%[0-9]+]]:acc512, [[VLDA_3D_CONV_FP32_BF16_1:%[0-9]+]]:ep, [[VLDA_3D_CONV_FP32_BF16_2:%[0-9]+]]:edc, [[VLDA_3D_CONV_FP32_BF16_3:%[0-9]+]]:edc = VLDA_3D_CONV_FP32_BF16 [[COPY]], [[REG_SEQUENCE]] :: (load (<16 x s16>))
    ; CHECK-NEXT: PseudoRET implicit $lr, implicit [[VLDA_3D_CONV_FP32_BF16_]]
    %0:ptrregbank(p0) = COPY $p0
    %1:em(s20) = G_CONSTANT i20 1
    %2:edj(s20) = G_CONSTANT i20 2
    %3:edj(s20) = G_CONSTANT i20 3
    %4:edn(s20) = G_CONSTANT i20 4
    %5:edn(s20) = G_CONSTANT i20 5
    %6:edc(s20) = G_CONSTANT i20 6
    %7:edc(s20) = G_CONSTANT i20 7
    %25:vregbank(<16 x s16>), %8:ptrregbank(p0), %9:modregbank(s20), %10:modregbank(s20) = G_AIE_POSTINC_3D_LOAD %0, %1, %2, %3, %4, %6, %5, %7 :: (load (<16 x s16>))
    %103:accregbank(<8 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.v16bf16.to.v16accfloat), %25:vregbank(<16 x s16>)
    PseudoRET implicit $lr, implicit %103
...

---
name:            VLDA_CONV_POSTINC
legalized:       true
regBankSelected: true
tracksRegLiveness: true
body: |
  bb.0:
    liveins: $p0, $m0, $amll0
    ; CHECK-LABEL: name: VLDA_CONV_POSTINC
    ; CHECK: liveins: $p0, $m0, $amll0
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:ep = COPY $p0
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:em = COPY $m0
    ; CHECK-NEXT: [[MOV_PD_imm10_pseudo:%[0-9]+]]:em = MOV_PD_imm10_pseudo 16
    ; CHECK-NEXT: [[MOV_PD_imm10_pseudo1:%[0-9]+]]:em = MOV_PD_imm10_pseudo 256
    ; CHECK-NEXT: [[VLDA_CONV_FP32_BF16_pstm_nrm:%[0-9]+]]:acc512, [[VLDA_CONV_FP32_BF16_pstm_nrm1:%[0-9]+]]:ep = VLDA_CONV_FP32_BF16_pstm_nrm [[COPY]], [[COPY1]] :: (load (<16 x s16>))
    ; CHECK-NEXT: [[VLDA_CONV_FP32_BF16_pstm_nrm_imm:%[0-9]+]]:acc512, [[VLDA_CONV_FP32_BF16_pstm_nrm_imm1:%[0-9]+]]:ep = VLDA_CONV_FP32_BF16_pstm_nrm_imm [[COPY]], 0 :: (load (<16 x s16>))
    ; CHECK-NEXT: [[VLDA_CONV_FP32_BF16_pstm_nrm2:%[0-9]+]]:acc512, [[VLDA_CONV_FP32_BF16_pstm_nrm3:%[0-9]+]]:ep = VLDA_CONV_FP32_BF16_pstm_nrm [[COPY]], [[MOV_PD_imm10_pseudo]] :: (load (<16 x s16>))
    ; CHECK-NEXT: [[VLDA_CONV_FP32_BF16_pstm_nrm_imm2:%[0-9]+]]:acc512, [[VLDA_CONV_FP32_BF16_pstm_nrm_imm3:%[0-9]+]]:ep = VLDA_CONV_FP32_BF16_pstm_nrm_imm [[COPY]], -256 :: (load (<16 x s16>))
    ; CHECK-NEXT: [[VLDA_CONV_FP32_BF16_pstm_nrm_imm4:%[0-9]+]]:acc512, [[VLDA_CONV_FP32_BF16_pstm_nrm_imm5:%[0-9]+]]:ep = VLDA_CONV_FP32_BF16_pstm_nrm_imm [[COPY]], 224 :: (load (<16 x s16>))
    ; CHECK-NEXT: [[VLDA_CONV_FP32_BF16_pstm_nrm4:%[0-9]+]]:acc512, [[VLDA_CONV_FP32_BF16_pstm_nrm5:%[0-9]+]]:ep = VLDA_CONV_FP32_BF16_pstm_nrm [[COPY]], [[MOV_PD_imm10_pseudo1]] :: (load (<16 x s16>))
    ; CHECK-NEXT: PseudoRET implicit $lr, implicit [[VLDA_CONV_FP32_BF16_pstm_nrm]], implicit [[VLDA_CONV_FP32_BF16_pstm_nrm_imm]], implicit [[VLDA_CONV_FP32_BF16_pstm_nrm2]], implicit [[VLDA_CONV_FP32_BF16_pstm_nrm_imm2]], implicit [[VLDA_CONV_FP32_BF16_pstm_nrm_imm4]], implicit [[VLDA_CONV_FP32_BF16_pstm_nrm4]]
    %0:ptrregbank(p0) = COPY $p0
    %7:modregbank(s20) = COPY $m0
    %8:modregbank(s20) = G_CONSTANT i20 0
    %9:modregbank(s20) = G_CONSTANT i20 16
    %10:modregbank(s20) = G_CONSTANT i20 -256
    %11:modregbank(s20) = G_CONSTANT i20 224
    %12:modregbank(s20) = G_CONSTANT i20 256
    %25:vregbank(<16 x s16>), %19:ptrregbank(p0) = G_AIE_POSTINC_LOAD %0, %7 :: (load (<16 x s16>))
    %26:vregbank(<16 x s16>), %20:ptrregbank(p0) = G_AIE_POSTINC_LOAD %0, %8 :: (load (<16 x s16>))
    %27:vregbank(<16 x s16>), %21:ptrregbank(p0) = G_AIE_POSTINC_LOAD %0, %9 :: (load (<16 x s16>))
    %28:vregbank(<16 x s16>), %22:ptrregbank(p0) = G_AIE_POSTINC_LOAD %0, %10 :: (load (<16 x s16>))
    %29:vregbank(<16 x s16>), %23:ptrregbank(p0) = G_AIE_POSTINC_LOAD %0, %11 :: (load (<16 x s16>))
    %30:vregbank(<16 x s16>), %24:ptrregbank(p0) = G_AIE_POSTINC_LOAD %0, %12 :: (load (<16 x s16>))
    %103:accregbank(<8 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.v16bf16.to.v16accfloat), %25:vregbank(<16 x s16>)
    %104:accregbank(<8 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.v16bf16.to.v16accfloat), %26:vregbank(<16 x s16>)
    %105:accregbank(<8 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.v16bf16.to.v16accfloat), %27:vregbank(<16 x s16>)
    %106:accregbank(<8 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.v16bf16.to.v16accfloat), %28:vregbank(<16 x s16>)
    %107:accregbank(<8 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.v16bf16.to.v16accfloat), %29:vregbank(<16 x s16>)
    %108:accregbank(<8 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.v16bf16.to.v16accfloat), %30:vregbank(<16 x s16>)
    PseudoRET implicit $lr, implicit %103, implicit %104, implicit %105, implicit %106, implicit %107, implicit %108
...

# This tests that we don't combine if a store is in between the load and VCONV instruction
---
name:            VLD_CONV_store
legalized:       true
regBankSelected: true
tracksRegLiveness: true
body: |
  bb.0:
    liveins: $p0, $m0, $m1, $m2, $r0, $amll0, $p1
    ; CHECK-LABEL: name: VLD_CONV_store
    ; CHECK: liveins: $p0, $m0, $m1, $m2, $r0, $amll0, $p1
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:ep = COPY $p0
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:ep = COPY $p1
    ; CHECK-NEXT: [[COPY2:%[0-9]+]]:em = COPY $m0
    ; CHECK-NEXT: [[COPY3:%[0-9]+]]:vec256 = COPY $amll0
    ; CHECK-NEXT: [[VLDA_dmw_lda_w_ag_pstm_nrm:%[0-9]+]]:vec256, [[VLDA_dmw_lda_w_ag_pstm_nrm1:%[0-9]+]]:ep = VLDA_dmw_lda_w_ag_pstm_nrm [[COPY]], [[COPY2]] :: (load (<16 x s16>))
    ; CHECK-NEXT: VST_dmw_sts_w_ag_idx_imm [[COPY3]], [[COPY1]], 0 :: (store (<16 x s16>))
    ; CHECK-NEXT: [[VCONV_FP32_BF16_:%[0-9]+]]:acc512 = VCONV_FP32_BF16 [[VLDA_dmw_lda_w_ag_pstm_nrm]]
    ; CHECK-NEXT: PseudoRET implicit $lr, implicit [[VCONV_FP32_BF16_]]
    %0:ptrregbank(p0) = COPY $p0
    %20:ptrregbank(p0) = COPY $p1
    %7:modregbank(s20) = COPY $m0
    %70:gprregbank(s32) = COPY $r0
    %80:vregbank(<16 x s16>) = COPY $amll0
    %25:vregbank(<16 x s16>), %19:ptrregbank(p0) = G_AIE_POSTINC_LOAD %0, %7 :: (load (<16 x s16>))
    G_STORE %80:vregbank(<16 x s16>), %20:ptrregbank(p0) :: (store (<16 x s16>))
    %103:accregbank(<8 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.v16bf16.to.v16accfloat), %25:vregbank(<16 x s16>)
    PseudoRET implicit $lr, implicit %103
...

# This tests that we don't combine if one of the load's defs is used before the VCONV instruction
---
name:            VLD_CONV_use
legalized:       true
regBankSelected: true
tracksRegLiveness: true
body: |
  bb.0:
    liveins: $p0, $m0, $m1, $m2, $r0
    ; CHECK-LABEL: name: VLD_CONV_use
    ; CHECK: liveins: $p0, $m0, $m1, $m2, $r0
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:ep = COPY $p0
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:em = COPY $m0
    ; CHECK-NEXT: [[VLDA_dmw_lda_w_ag_pstm_nrm:%[0-9]+]]:vec256, [[VLDA_dmw_lda_w_ag_pstm_nrm1:%[0-9]+]]:ep = VLDA_dmw_lda_w_ag_pstm_nrm [[COPY]], [[COPY1]] :: (load (<16 x s16>))
    ; CHECK-NEXT: $m1 = COPY [[VLDA_dmw_lda_w_ag_pstm_nrm1]]
    ; CHECK-NEXT: [[VCONV_FP32_BF16_:%[0-9]+]]:acc512 = VCONV_FP32_BF16 [[VLDA_dmw_lda_w_ag_pstm_nrm]]
    ; CHECK-NEXT: PseudoRET implicit $lr, implicit [[VCONV_FP32_BF16_]], implicit $m1
    %0:ptrregbank(p0) = COPY $p0
    %7:modregbank(s20) = COPY $m0
    %70:gprregbank(s32) = COPY $r0
    %25:vregbank(<16 x s16>), %19:ptrregbank(p0) = G_AIE_POSTINC_LOAD %0, %7 :: (load (<16 x s16>))
    $m1 = COPY %19:ptrregbank(p0)
    %103:accregbank(<8 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.v16bf16.to.v16accfloat), %25:vregbank(<16 x s16>)
    PseudoRET implicit $lr, implicit %103, implicit $m1
...

# This test shows that only the last load is combined when having consecutive loads using the same pointer
# This is due to the fact that the generic load is not erased when doing the combine at instruction selection
# but left to be eliminated later by the trivial dead code elimination. This load will be leftover from the
# first combine operation and will prevent the following combines to be performed since it uses the same register
# defined by the preceding load.
# This is a missed opportunity since we could have done the combines of all the loads and that would have been safe.
---
name:            VLDA_CONV_POSTINC_dead_use
legalized:       true
regBankSelected: true
tracksRegLiveness: true
body: |
  bb.0:
    liveins: $p0, $m0, $amll0
    ; CHECK-LABEL: name: VLDA_CONV_POSTINC_dead_use
    ; CHECK: liveins: $p0, $m0, $amll0
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:ep = COPY $p0
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:em = COPY $m0
    ; CHECK-NEXT: [[MOV_PD_imm10_pseudo:%[0-9]+]]:em = MOV_PD_imm10_pseudo 16
    ; CHECK-NEXT: [[MOV_PD_imm10_pseudo1:%[0-9]+]]:em = MOV_PD_imm10_pseudo 256
    ; CHECK-NEXT: [[VLDA_dmw_lda_w_ag_pstm_nrm:%[0-9]+]]:vec256, [[VLDA_dmw_lda_w_ag_pstm_nrm1:%[0-9]+]]:ep = VLDA_dmw_lda_w_ag_pstm_nrm [[COPY]], [[COPY1]] :: (load (<16 x s16>))
    ; CHECK-NEXT: [[VLDA_dmw_lda_w_ag_pstm_nrm_imm:%[0-9]+]]:vec256, [[VLDA_dmw_lda_w_ag_pstm_nrm_imm1:%[0-9]+]]:ep = VLDA_dmw_lda_w_ag_pstm_nrm_imm [[VLDA_dmw_lda_w_ag_pstm_nrm1]], 0 :: (load (<16 x s16>))
    ; CHECK-NEXT: [[VLDA_dmw_lda_w_ag_pstm_nrm2:%[0-9]+]]:vec256, [[VLDA_dmw_lda_w_ag_pstm_nrm3:%[0-9]+]]:ep = VLDA_dmw_lda_w_ag_pstm_nrm [[VLDA_dmw_lda_w_ag_pstm_nrm_imm1]], [[MOV_PD_imm10_pseudo]] :: (load (<16 x s16>))
    ; CHECK-NEXT: [[VLDA_dmw_lda_w_ag_pstm_nrm_imm2:%[0-9]+]]:vec256, [[VLDA_dmw_lda_w_ag_pstm_nrm_imm3:%[0-9]+]]:ep = VLDA_dmw_lda_w_ag_pstm_nrm_imm [[VLDA_dmw_lda_w_ag_pstm_nrm3]], -256 :: (load (<16 x s16>))
    ; CHECK-NEXT: [[VLDA_dmw_lda_w_ag_pstm_nrm_imm4:%[0-9]+]]:vec256, [[VLDA_dmw_lda_w_ag_pstm_nrm_imm5:%[0-9]+]]:ep = VLDA_dmw_lda_w_ag_pstm_nrm_imm [[VLDA_dmw_lda_w_ag_pstm_nrm_imm3]], 224 :: (load (<16 x s16>))
    ; CHECK-NEXT: [[VCONV_FP32_BF16_:%[0-9]+]]:acc512 = VCONV_FP32_BF16 [[VLDA_dmw_lda_w_ag_pstm_nrm]]
    ; CHECK-NEXT: [[VCONV_FP32_BF16_1:%[0-9]+]]:acc512 = VCONV_FP32_BF16 [[VLDA_dmw_lda_w_ag_pstm_nrm_imm]]
    ; CHECK-NEXT: [[VCONV_FP32_BF16_2:%[0-9]+]]:acc512 = VCONV_FP32_BF16 [[VLDA_dmw_lda_w_ag_pstm_nrm2]]
    ; CHECK-NEXT: [[VCONV_FP32_BF16_3:%[0-9]+]]:acc512 = VCONV_FP32_BF16 [[VLDA_dmw_lda_w_ag_pstm_nrm_imm2]]
    ; CHECK-NEXT: [[VCONV_FP32_BF16_4:%[0-9]+]]:acc512 = VCONV_FP32_BF16 [[VLDA_dmw_lda_w_ag_pstm_nrm_imm4]]
    ; CHECK-NEXT: [[VLDA_CONV_FP32_BF16_pstm_nrm:%[0-9]+]]:acc512, [[VLDA_CONV_FP32_BF16_pstm_nrm1:%[0-9]+]]:ep = VLDA_CONV_FP32_BF16_pstm_nrm [[VLDA_dmw_lda_w_ag_pstm_nrm_imm5]], [[MOV_PD_imm10_pseudo1]] :: (load (<16 x s16>))
    ; CHECK-NEXT: PseudoRET implicit $lr, implicit [[VCONV_FP32_BF16_]], implicit [[VCONV_FP32_BF16_1]], implicit [[VCONV_FP32_BF16_2]], implicit [[VCONV_FP32_BF16_3]], implicit [[VCONV_FP32_BF16_4]], implicit [[VLDA_CONV_FP32_BF16_pstm_nrm]]
    %0:ptrregbank(p0) = COPY $p0
    %7:modregbank(s20) = COPY $m0
    %8:modregbank(s20) = G_CONSTANT i20 0
    %9:modregbank(s20) = G_CONSTANT i20 16
    %10:modregbank(s20) = G_CONSTANT i20 -256
    %11:modregbank(s20) = G_CONSTANT i20 224
    %12:modregbank(s20) = G_CONSTANT i20 256
    %25:vregbank(<16 x s16>), %19:ptrregbank(p0) = G_AIE_POSTINC_LOAD %0, %7 :: (load (<16 x s16>))
    %26:vregbank(<16 x s16>), %20:ptrregbank(p0) = G_AIE_POSTINC_LOAD %19, %8 :: (load (<16 x s16>))
    %27:vregbank(<16 x s16>), %21:ptrregbank(p0) = G_AIE_POSTINC_LOAD %20, %9 :: (load (<16 x s16>))
    %28:vregbank(<16 x s16>), %22:ptrregbank(p0) = G_AIE_POSTINC_LOAD %21, %10 :: (load (<16 x s16>))
    %29:vregbank(<16 x s16>), %23:ptrregbank(p0) = G_AIE_POSTINC_LOAD %22, %11 :: (load (<16 x s16>))
    %30:vregbank(<16 x s16>), %24:ptrregbank(p0) = G_AIE_POSTINC_LOAD %23, %12 :: (load (<16 x s16>))
    %103:accregbank(<8 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.v16bf16.to.v16accfloat), %25:vregbank(<16 x s16>)
    %104:accregbank(<8 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.v16bf16.to.v16accfloat), %26:vregbank(<16 x s16>)
    %105:accregbank(<8 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.v16bf16.to.v16accfloat), %27:vregbank(<16 x s16>)
    %106:accregbank(<8 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.v16bf16.to.v16accfloat), %28:vregbank(<16 x s16>)
    %107:accregbank(<8 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.v16bf16.to.v16accfloat), %29:vregbank(<16 x s16>)
    %108:accregbank(<8 x s64>) = G_INTRINSIC intrinsic(@llvm.aie2.v16bf16.to.v16accfloat), %30:vregbank(<16 x s16>)
    PseudoRET implicit $lr, implicit %103, implicit %104, implicit %105, implicit %106, implicit %107, implicit %108
...
