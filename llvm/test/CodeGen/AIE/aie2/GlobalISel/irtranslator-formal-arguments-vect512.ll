; NOTE: Assertions have been autogenerated by utils/update_mir_test_checks.py UTC_ARGS: --print-fixed-stack
;
; This file is licensed under the Apache License v2.0 with LLVM Exceptions.
; See https://llvm.org/LICENSE.txt for license information.
; SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
;
; (c) Copyright 2023-2024 Advanced Micro Devices, Inc. or its affiliates
; RUN: llc -mtriple=aie2 -O0 -stop-after=irtranslator -global-isel -verify-machineinstrs %s -o - 2>&1 | FileCheck %s

; 512-bit vector types

define void @callee_v16int32(<16 x i32>, <16 x i32>, <16 x i32>, <16 x i32>, <16 x i32>, <16 x i32>,
  ; CHECK-LABEL: name: callee_v16int32
  ; CHECK: fixedStack:
  ; CHECK:   - { id: 0, type: default, offset: -64, size: 64, alignment: 32, stack-id: default,
  ; CHECK:       isImmutable: true, isAliased: false, callee-saved-register: '', callee-saved-restored: true,
  ; CHECK:       debug-info-variable: '', debug-info-expression: '', debug-info-location: '' }
  ; CHECK: bb.1 (%ir-block.13):
  ; CHECK-NEXT:   liveins: $x0, $x1, $x2, $x3, $x4, $x5, $x6, $x7, $x8, $x9, $x10, $x11
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT:   [[COPY:%[0-9]+]]:_(<16 x s32>) = COPY $x0
  ; CHECK-NEXT:   [[COPY1:%[0-9]+]]:_(<16 x s32>) = COPY $x2
  ; CHECK-NEXT:   [[COPY2:%[0-9]+]]:_(<16 x s32>) = COPY $x4
  ; CHECK-NEXT:   [[COPY3:%[0-9]+]]:_(<16 x s32>) = COPY $x6
  ; CHECK-NEXT:   [[COPY4:%[0-9]+]]:_(<16 x s32>) = COPY $x8
  ; CHECK-NEXT:   [[COPY5:%[0-9]+]]:_(<16 x s32>) = COPY $x10
  ; CHECK-NEXT:   [[COPY6:%[0-9]+]]:_(<16 x s32>) = COPY $x1
  ; CHECK-NEXT:   [[COPY7:%[0-9]+]]:_(<16 x s32>) = COPY $x3
  ; CHECK-NEXT:   [[COPY8:%[0-9]+]]:_(<16 x s32>) = COPY $x5
  ; CHECK-NEXT:   [[COPY9:%[0-9]+]]:_(<16 x s32>) = COPY $x7
  ; CHECK-NEXT:   [[COPY10:%[0-9]+]]:_(<16 x s32>) = COPY $x9
  ; CHECK-NEXT:   [[COPY11:%[0-9]+]]:_(<16 x s32>) = COPY $x11
  ; CHECK-NEXT:   [[FRAME_INDEX:%[0-9]+]]:_(p0) = G_FRAME_INDEX %fixed-stack.0
  ; CHECK-NEXT:   [[LOAD:%[0-9]+]]:_(<16 x s32>) = G_LOAD [[FRAME_INDEX]](p0) :: (invariant load (<16 x s32>) from %fixed-stack.0, align 32)
  ; CHECK-NEXT:   [[C:%[0-9]+]]:_(s32) = G_CONSTANT i32 0
  ; CHECK-NEXT:   [[BUILD_VECTOR:%[0-9]+]]:_(<16 x s32>) = G_BUILD_VECTOR [[C]](s32), [[C]](s32), [[C]](s32), [[C]](s32), [[C]](s32), [[C]](s32), [[C]](s32), [[C]](s32), [[C]](s32), [[C]](s32), [[C]](s32), [[C]](s32), [[C]](s32), [[C]](s32), [[C]](s32), [[C]](s32)
  ; CHECK-NEXT:   ADJCALLSTACKUP 64, 0
  ; CHECK-NEXT:   [[COPY12:%[0-9]+]]:_(p0) = COPY $sp
  ; CHECK-NEXT:   [[C1:%[0-9]+]]:_(s32) = G_CONSTANT i32 -64
  ; CHECK-NEXT:   [[PTR_ADD:%[0-9]+]]:_(p0) = G_PTR_ADD [[COPY12]], [[C1]](s32)
  ; CHECK-NEXT:   G_STORE [[BUILD_VECTOR]](<16 x s32>), [[PTR_ADD]](p0) :: (store (<16 x s32>) into stack - 64, align 32)
  ; CHECK-NEXT:   $x0 = COPY [[BUILD_VECTOR]](<16 x s32>)
  ; CHECK-NEXT:   $x2 = COPY [[BUILD_VECTOR]](<16 x s32>)
  ; CHECK-NEXT:   $x4 = COPY [[BUILD_VECTOR]](<16 x s32>)
  ; CHECK-NEXT:   $x6 = COPY [[BUILD_VECTOR]](<16 x s32>)
  ; CHECK-NEXT:   $x8 = COPY [[BUILD_VECTOR]](<16 x s32>)
  ; CHECK-NEXT:   $x10 = COPY [[BUILD_VECTOR]](<16 x s32>)
  ; CHECK-NEXT:   $x1 = COPY [[BUILD_VECTOR]](<16 x s32>)
  ; CHECK-NEXT:   $x3 = COPY [[BUILD_VECTOR]](<16 x s32>)
  ; CHECK-NEXT:   $x5 = COPY [[BUILD_VECTOR]](<16 x s32>)
  ; CHECK-NEXT:   $x7 = COPY [[BUILD_VECTOR]](<16 x s32>)
  ; CHECK-NEXT:   $x9 = COPY [[BUILD_VECTOR]](<16 x s32>)
  ; CHECK-NEXT:   $x11 = COPY [[BUILD_VECTOR]](<16 x s32>)
  ; CHECK-NEXT:   JL @callee_v16int32, csr_aie2, implicit-def $lr, implicit $x0, implicit $x2, implicit $x4, implicit $x6, implicit $x8, implicit $x10, implicit $x1, implicit $x3, implicit $x5, implicit $x7, implicit $x9, implicit $x11
  ; CHECK-NEXT:   ADJCALLSTACKDOWN 64, 0
  ; CHECK-NEXT:   PseudoRET implicit $lr
                              <16 x i32>, <16 x i32>, <16 x i32>, <16 x i32>, <16 x i32>, <16 x i32>,
                              <16 x i32>) {
  call void @callee_v16int32(<16 x i32> zeroinitializer, <16 x i32> zeroinitializer, <16 x i32> zeroinitializer, <16 x i32> zeroinitializer, <16 x i32> zeroinitializer, <16 x i32> zeroinitializer,
                             <16 x i32> zeroinitializer, <16 x i32> zeroinitializer, <16 x i32> zeroinitializer, <16 x i32> zeroinitializer, <16 x i32> zeroinitializer, <16 x i32> zeroinitializer,
                             <16 x i32> zeroinitializer)
  ret void
}

define void @callee_v32int16(<32 x i16>, <32 x i16>, <32 x i16>, <32 x i16>, <32 x i16>, <32 x i16>,
  ; CHECK-LABEL: name: callee_v32int16
  ; CHECK: fixedStack:
  ; CHECK:   - { id: 0, type: default, offset: -64, size: 64, alignment: 32, stack-id: default,
  ; CHECK:       isImmutable: true, isAliased: false, callee-saved-register: '', callee-saved-restored: true,
  ; CHECK:       debug-info-variable: '', debug-info-expression: '', debug-info-location: '' }
  ; CHECK: bb.1 (%ir-block.13):
  ; CHECK-NEXT:   liveins: $x0, $x1, $x2, $x3, $x4, $x5, $x6, $x7, $x8, $x9, $x10, $x11
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT:   [[COPY:%[0-9]+]]:_(<32 x s16>) = COPY $x0
  ; CHECK-NEXT:   [[COPY1:%[0-9]+]]:_(<32 x s16>) = COPY $x2
  ; CHECK-NEXT:   [[COPY2:%[0-9]+]]:_(<32 x s16>) = COPY $x4
  ; CHECK-NEXT:   [[COPY3:%[0-9]+]]:_(<32 x s16>) = COPY $x6
  ; CHECK-NEXT:   [[COPY4:%[0-9]+]]:_(<32 x s16>) = COPY $x8
  ; CHECK-NEXT:   [[COPY5:%[0-9]+]]:_(<32 x s16>) = COPY $x10
  ; CHECK-NEXT:   [[COPY6:%[0-9]+]]:_(<32 x s16>) = COPY $x1
  ; CHECK-NEXT:   [[COPY7:%[0-9]+]]:_(<32 x s16>) = COPY $x3
  ; CHECK-NEXT:   [[COPY8:%[0-9]+]]:_(<32 x s16>) = COPY $x5
  ; CHECK-NEXT:   [[COPY9:%[0-9]+]]:_(<32 x s16>) = COPY $x7
  ; CHECK-NEXT:   [[COPY10:%[0-9]+]]:_(<32 x s16>) = COPY $x9
  ; CHECK-NEXT:   [[COPY11:%[0-9]+]]:_(<32 x s16>) = COPY $x11
  ; CHECK-NEXT:   [[FRAME_INDEX:%[0-9]+]]:_(p0) = G_FRAME_INDEX %fixed-stack.0
  ; CHECK-NEXT:   [[LOAD:%[0-9]+]]:_(<32 x s16>) = G_LOAD [[FRAME_INDEX]](p0) :: (invariant load (<32 x s16>) from %fixed-stack.0, align 32)
  ; CHECK-NEXT:   [[C:%[0-9]+]]:_(s16) = G_CONSTANT i16 0
  ; CHECK-NEXT:   [[BUILD_VECTOR:%[0-9]+]]:_(<32 x s16>) = G_BUILD_VECTOR [[C]](s16), [[C]](s16), [[C]](s16), [[C]](s16), [[C]](s16), [[C]](s16), [[C]](s16), [[C]](s16), [[C]](s16), [[C]](s16), [[C]](s16), [[C]](s16), [[C]](s16), [[C]](s16), [[C]](s16), [[C]](s16), [[C]](s16), [[C]](s16), [[C]](s16), [[C]](s16), [[C]](s16), [[C]](s16), [[C]](s16), [[C]](s16), [[C]](s16), [[C]](s16), [[C]](s16), [[C]](s16), [[C]](s16), [[C]](s16), [[C]](s16), [[C]](s16)
  ; CHECK-NEXT:   ADJCALLSTACKUP 64, 0
  ; CHECK-NEXT:   [[COPY12:%[0-9]+]]:_(p0) = COPY $sp
  ; CHECK-NEXT:   [[C1:%[0-9]+]]:_(s32) = G_CONSTANT i32 -64
  ; CHECK-NEXT:   [[PTR_ADD:%[0-9]+]]:_(p0) = G_PTR_ADD [[COPY12]], [[C1]](s32)
  ; CHECK-NEXT:   G_STORE [[BUILD_VECTOR]](<32 x s16>), [[PTR_ADD]](p0) :: (store (<32 x s16>) into stack - 64, align 32)
  ; CHECK-NEXT:   $x0 = COPY [[BUILD_VECTOR]](<32 x s16>)
  ; CHECK-NEXT:   $x2 = COPY [[BUILD_VECTOR]](<32 x s16>)
  ; CHECK-NEXT:   $x4 = COPY [[BUILD_VECTOR]](<32 x s16>)
  ; CHECK-NEXT:   $x6 = COPY [[BUILD_VECTOR]](<32 x s16>)
  ; CHECK-NEXT:   $x8 = COPY [[BUILD_VECTOR]](<32 x s16>)
  ; CHECK-NEXT:   $x10 = COPY [[BUILD_VECTOR]](<32 x s16>)
  ; CHECK-NEXT:   $x1 = COPY [[BUILD_VECTOR]](<32 x s16>)
  ; CHECK-NEXT:   $x3 = COPY [[BUILD_VECTOR]](<32 x s16>)
  ; CHECK-NEXT:   $x5 = COPY [[BUILD_VECTOR]](<32 x s16>)
  ; CHECK-NEXT:   $x7 = COPY [[BUILD_VECTOR]](<32 x s16>)
  ; CHECK-NEXT:   $x9 = COPY [[BUILD_VECTOR]](<32 x s16>)
  ; CHECK-NEXT:   $x11 = COPY [[BUILD_VECTOR]](<32 x s16>)
  ; CHECK-NEXT:   JL @callee_v32int16, csr_aie2, implicit-def $lr, implicit $x0, implicit $x2, implicit $x4, implicit $x6, implicit $x8, implicit $x10, implicit $x1, implicit $x3, implicit $x5, implicit $x7, implicit $x9, implicit $x11
  ; CHECK-NEXT:   ADJCALLSTACKDOWN 64, 0
  ; CHECK-NEXT:   PseudoRET implicit $lr
                              <32 x i16>, <32 x i16>, <32 x i16>, <32 x i16>, <32 x i16>, <32 x i16>,
                              <32 x i16>) {
  call void @callee_v32int16(<32 x i16> zeroinitializer, <32 x i16> zeroinitializer, <32 x i16> zeroinitializer, <32 x i16> zeroinitializer, <32 x i16> zeroinitializer, <32 x i16> zeroinitializer,
                             <32 x i16> zeroinitializer, <32 x i16> zeroinitializer, <32 x i16> zeroinitializer, <32 x i16> zeroinitializer, <32 x i16> zeroinitializer, <32 x i16> zeroinitializer,
                             <32 x i16> zeroinitializer)
  ret void
}

define void @callee_v64int8(<64 x i8>, <64 x i8>, <64 x i8>, <64 x i8>, <64 x i8>, <64 x i8>,
  ; CHECK-LABEL: name: callee_v64int8
  ; CHECK: fixedStack:
  ; CHECK:   - { id: 0, type: default, offset: -64, size: 64, alignment: 32, stack-id: default,
  ; CHECK:       isImmutable: true, isAliased: false, callee-saved-register: '', callee-saved-restored: true,
  ; CHECK:       debug-info-variable: '', debug-info-expression: '', debug-info-location: '' }
  ; CHECK: bb.1 (%ir-block.13):
  ; CHECK-NEXT:   liveins: $x0, $x1, $x2, $x3, $x4, $x5, $x6, $x7, $x8, $x9, $x10, $x11
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT:   [[COPY:%[0-9]+]]:_(<64 x s8>) = COPY $x0
  ; CHECK-NEXT:   [[COPY1:%[0-9]+]]:_(<64 x s8>) = COPY $x2
  ; CHECK-NEXT:   [[COPY2:%[0-9]+]]:_(<64 x s8>) = COPY $x4
  ; CHECK-NEXT:   [[COPY3:%[0-9]+]]:_(<64 x s8>) = COPY $x6
  ; CHECK-NEXT:   [[COPY4:%[0-9]+]]:_(<64 x s8>) = COPY $x8
  ; CHECK-NEXT:   [[COPY5:%[0-9]+]]:_(<64 x s8>) = COPY $x10
  ; CHECK-NEXT:   [[COPY6:%[0-9]+]]:_(<64 x s8>) = COPY $x1
  ; CHECK-NEXT:   [[COPY7:%[0-9]+]]:_(<64 x s8>) = COPY $x3
  ; CHECK-NEXT:   [[COPY8:%[0-9]+]]:_(<64 x s8>) = COPY $x5
  ; CHECK-NEXT:   [[COPY9:%[0-9]+]]:_(<64 x s8>) = COPY $x7
  ; CHECK-NEXT:   [[COPY10:%[0-9]+]]:_(<64 x s8>) = COPY $x9
  ; CHECK-NEXT:   [[COPY11:%[0-9]+]]:_(<64 x s8>) = COPY $x11
  ; CHECK-NEXT:   [[FRAME_INDEX:%[0-9]+]]:_(p0) = G_FRAME_INDEX %fixed-stack.0
  ; CHECK-NEXT:   [[LOAD:%[0-9]+]]:_(<64 x s8>) = G_LOAD [[FRAME_INDEX]](p0) :: (invariant load (<64 x s8>) from %fixed-stack.0, align 32)
  ; CHECK-NEXT:   [[C:%[0-9]+]]:_(s8) = G_CONSTANT i8 0
  ; CHECK-NEXT:   [[BUILD_VECTOR:%[0-9]+]]:_(<64 x s8>) = G_BUILD_VECTOR [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8), [[C]](s8)
  ; CHECK-NEXT:   ADJCALLSTACKUP 64, 0
  ; CHECK-NEXT:   [[COPY12:%[0-9]+]]:_(p0) = COPY $sp
  ; CHECK-NEXT:   [[C1:%[0-9]+]]:_(s32) = G_CONSTANT i32 -64
  ; CHECK-NEXT:   [[PTR_ADD:%[0-9]+]]:_(p0) = G_PTR_ADD [[COPY12]], [[C1]](s32)
  ; CHECK-NEXT:   G_STORE [[BUILD_VECTOR]](<64 x s8>), [[PTR_ADD]](p0) :: (store (<64 x s8>) into stack - 64, align 32)
  ; CHECK-NEXT:   $x0 = COPY [[BUILD_VECTOR]](<64 x s8>)
  ; CHECK-NEXT:   $x2 = COPY [[BUILD_VECTOR]](<64 x s8>)
  ; CHECK-NEXT:   $x4 = COPY [[BUILD_VECTOR]](<64 x s8>)
  ; CHECK-NEXT:   $x6 = COPY [[BUILD_VECTOR]](<64 x s8>)
  ; CHECK-NEXT:   $x8 = COPY [[BUILD_VECTOR]](<64 x s8>)
  ; CHECK-NEXT:   $x10 = COPY [[BUILD_VECTOR]](<64 x s8>)
  ; CHECK-NEXT:   $x1 = COPY [[BUILD_VECTOR]](<64 x s8>)
  ; CHECK-NEXT:   $x3 = COPY [[BUILD_VECTOR]](<64 x s8>)
  ; CHECK-NEXT:   $x5 = COPY [[BUILD_VECTOR]](<64 x s8>)
  ; CHECK-NEXT:   $x7 = COPY [[BUILD_VECTOR]](<64 x s8>)
  ; CHECK-NEXT:   $x9 = COPY [[BUILD_VECTOR]](<64 x s8>)
  ; CHECK-NEXT:   $x11 = COPY [[BUILD_VECTOR]](<64 x s8>)
  ; CHECK-NEXT:   JL @callee_v64int8, csr_aie2, implicit-def $lr, implicit $x0, implicit $x2, implicit $x4, implicit $x6, implicit $x8, implicit $x10, implicit $x1, implicit $x3, implicit $x5, implicit $x7, implicit $x9, implicit $x11
  ; CHECK-NEXT:   ADJCALLSTACKDOWN 64, 0
  ; CHECK-NEXT:   PseudoRET implicit $lr
                             <64 x i8>, <64 x i8>, <64 x i8>, <64 x i8>, <64 x i8>, <64 x i8>,
                             <64 x i8>) {
  call void @callee_v64int8(<64 x i8> zeroinitializer, <64 x i8> zeroinitializer, <64 x i8> zeroinitializer, <64 x i8> zeroinitializer, <64 x i8> zeroinitializer, <64 x i8> zeroinitializer,
                            <64 x i8> zeroinitializer, <64 x i8> zeroinitializer, <64 x i8> zeroinitializer, <64 x i8> zeroinitializer, <64 x i8> zeroinitializer, <64 x i8> zeroinitializer,
                            <64 x i8> zeroinitializer)
  ret void
}

define void @callee_v16float(<16 x float>, <16 x float>, <16 x float>, <16 x float>, <16 x float>, <16 x float>,
  ; CHECK-LABEL: name: callee_v16float
  ; CHECK: fixedStack:
  ; CHECK:   - { id: 0, type: default, offset: -64, size: 64, alignment: 32, stack-id: default,
  ; CHECK:       isImmutable: true, isAliased: false, callee-saved-register: '', callee-saved-restored: true,
  ; CHECK:       debug-info-variable: '', debug-info-expression: '', debug-info-location: '' }
  ; CHECK: bb.1 (%ir-block.13):
  ; CHECK-NEXT:   liveins: $x0, $x1, $x2, $x3, $x4, $x5, $x6, $x7, $x8, $x9, $x10, $x11
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT:   [[COPY:%[0-9]+]]:_(<16 x s32>) = COPY $x0
  ; CHECK-NEXT:   [[COPY1:%[0-9]+]]:_(<16 x s32>) = COPY $x2
  ; CHECK-NEXT:   [[COPY2:%[0-9]+]]:_(<16 x s32>) = COPY $x4
  ; CHECK-NEXT:   [[COPY3:%[0-9]+]]:_(<16 x s32>) = COPY $x6
  ; CHECK-NEXT:   [[COPY4:%[0-9]+]]:_(<16 x s32>) = COPY $x8
  ; CHECK-NEXT:   [[COPY5:%[0-9]+]]:_(<16 x s32>) = COPY $x10
  ; CHECK-NEXT:   [[COPY6:%[0-9]+]]:_(<16 x s32>) = COPY $x1
  ; CHECK-NEXT:   [[COPY7:%[0-9]+]]:_(<16 x s32>) = COPY $x3
  ; CHECK-NEXT:   [[COPY8:%[0-9]+]]:_(<16 x s32>) = COPY $x5
  ; CHECK-NEXT:   [[COPY9:%[0-9]+]]:_(<16 x s32>) = COPY $x7
  ; CHECK-NEXT:   [[COPY10:%[0-9]+]]:_(<16 x s32>) = COPY $x9
  ; CHECK-NEXT:   [[COPY11:%[0-9]+]]:_(<16 x s32>) = COPY $x11
  ; CHECK-NEXT:   [[FRAME_INDEX:%[0-9]+]]:_(p0) = G_FRAME_INDEX %fixed-stack.0
  ; CHECK-NEXT:   [[LOAD:%[0-9]+]]:_(<16 x s32>) = G_LOAD [[FRAME_INDEX]](p0) :: (invariant load (<16 x s32>) from %fixed-stack.0, align 32)
  ; CHECK-NEXT:   [[C:%[0-9]+]]:_(s32) = G_FCONSTANT float 0.000000e+00
  ; CHECK-NEXT:   [[BUILD_VECTOR:%[0-9]+]]:_(<16 x s32>) = G_BUILD_VECTOR [[C]](s32), [[C]](s32), [[C]](s32), [[C]](s32), [[C]](s32), [[C]](s32), [[C]](s32), [[C]](s32), [[C]](s32), [[C]](s32), [[C]](s32), [[C]](s32), [[C]](s32), [[C]](s32), [[C]](s32), [[C]](s32)
  ; CHECK-NEXT:   ADJCALLSTACKUP 64, 0
  ; CHECK-NEXT:   [[COPY12:%[0-9]+]]:_(p0) = COPY $sp
  ; CHECK-NEXT:   [[C1:%[0-9]+]]:_(s32) = G_CONSTANT i32 -64
  ; CHECK-NEXT:   [[PTR_ADD:%[0-9]+]]:_(p0) = G_PTR_ADD [[COPY12]], [[C1]](s32)
  ; CHECK-NEXT:   G_STORE [[BUILD_VECTOR]](<16 x s32>), [[PTR_ADD]](p0) :: (store (<16 x s32>) into stack - 64, align 32)
  ; CHECK-NEXT:   $x0 = COPY [[BUILD_VECTOR]](<16 x s32>)
  ; CHECK-NEXT:   $x2 = COPY [[BUILD_VECTOR]](<16 x s32>)
  ; CHECK-NEXT:   $x4 = COPY [[BUILD_VECTOR]](<16 x s32>)
  ; CHECK-NEXT:   $x6 = COPY [[BUILD_VECTOR]](<16 x s32>)
  ; CHECK-NEXT:   $x8 = COPY [[BUILD_VECTOR]](<16 x s32>)
  ; CHECK-NEXT:   $x10 = COPY [[BUILD_VECTOR]](<16 x s32>)
  ; CHECK-NEXT:   $x1 = COPY [[BUILD_VECTOR]](<16 x s32>)
  ; CHECK-NEXT:   $x3 = COPY [[BUILD_VECTOR]](<16 x s32>)
  ; CHECK-NEXT:   $x5 = COPY [[BUILD_VECTOR]](<16 x s32>)
  ; CHECK-NEXT:   $x7 = COPY [[BUILD_VECTOR]](<16 x s32>)
  ; CHECK-NEXT:   $x9 = COPY [[BUILD_VECTOR]](<16 x s32>)
  ; CHECK-NEXT:   $x11 = COPY [[BUILD_VECTOR]](<16 x s32>)
  ; CHECK-NEXT:   JL @callee_v16float, csr_aie2, implicit-def $lr, implicit $x0, implicit $x2, implicit $x4, implicit $x6, implicit $x8, implicit $x10, implicit $x1, implicit $x3, implicit $x5, implicit $x7, implicit $x9, implicit $x11
  ; CHECK-NEXT:   ADJCALLSTACKDOWN 64, 0
  ; CHECK-NEXT:   PseudoRET implicit $lr
                              <16 x float>, <16 x float>, <16 x float>, <16 x float>, <16 x float>, <16 x float>,
                              <16 x float>) {
  call void @callee_v16float(<16 x float> zeroinitializer, <16 x float> zeroinitializer, <16 x float> zeroinitializer, <16 x float> zeroinitializer, <16 x float> zeroinitializer, <16 x float> zeroinitializer,
                             <16 x float> zeroinitializer, <16 x float> zeroinitializer, <16 x float> zeroinitializer, <16 x float> zeroinitializer, <16 x float> zeroinitializer, <16 x float> zeroinitializer,
                             <16 x float> zeroinitializer)
  ret void
}
