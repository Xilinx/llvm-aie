# NOTE: Assertions have been autogenerated by utils/update_mir_test_checks.py
#
# This file is licensed under the Apache License v2.0 with LLVM Exceptions.
# See https://llvm.org/LICENSE.txt for license information.
# SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
#
# (c) Copyright 2023-2024 Advanced Micro Devices, Inc. or its affiliates
# RUN: llc -mtriple aie2 -run-pass=aie2-prelegalizer-combiner --aie-s20-narrowing=true %s -verify-machineinstrs -o - | FileCheck %s


# Simple case where a 128-bit vector is extended to a 256-bit vector
---
name:            extend_to_256_bits
body:             |
  bb.1:
    ; CHECK-LABEL: name: extend_to_256_bits
    ; CHECK: [[COPY:%[0-9]+]]:_(<4 x s32>) = COPY $q0
    ; CHECK-NEXT: [[AIE_PAD_VECTOR_UNDEF:%[0-9]+]]:_(<8 x s32>) = G_AIE_PAD_VECTOR_UNDEF [[COPY]](<4 x s32>)
    ; CHECK-NEXT: $wl0 = COPY [[AIE_PAD_VECTOR_UNDEF]](<8 x s32>)
      %10:_(<4 x s32>) = COPY $q0
      %0:_(s32), %1:_(s32), %2:_(s32), %3:_(s32) = G_UNMERGE_VALUES %10
      %4:_(s32) = G_IMPLICIT_DEF
      %11:_(<8 x s32>) = G_BUILD_VECTOR %0, %1, %2, %3, %4, %4, %4, %4
      $wl0 = COPY %11
...

# Simple case where a 128-bit vector is extended to a 512-bit vector
---
name:            extend_to_512_bits
body:             |
  bb.1:
    ; CHECK-LABEL: name: extend_to_512_bits
    ; CHECK: [[COPY:%[0-9]+]]:_(<4 x s32>) = COPY $q0
    ; CHECK-NEXT: [[AIE_PAD_VECTOR_UNDEF:%[0-9]+]]:_(<16 x s32>) = G_AIE_PAD_VECTOR_UNDEF [[COPY]](<4 x s32>)
    ; CHECK-NEXT: $x0 = COPY [[AIE_PAD_VECTOR_UNDEF]](<16 x s32>)
      %10:_(<4 x s32>) = COPY $q0
      %0:_(s32), %1:_(s32), %2:_(s32), %3:_(s32) = G_UNMERGE_VALUES %10
      %4:_(s32) = G_IMPLICIT_DEF
      %11:_(<16 x s32>) = G_BUILD_VECTOR %0, %1, %2, %3, %4, %4, %4, %4, %4, %4, %4, %4, %4, %4, %4, %4
      $x0 = COPY %11
...

# Cannot combine: lanes are shuffled
---
name:            no_combine_lanes_shuffled
body:             |
  bb.1:
    ; CHECK-LABEL: name: no_combine_lanes_shuffled
    ; CHECK: [[COPY:%[0-9]+]]:_(<4 x s32>) = COPY $q0
    ; CHECK-NEXT: [[UV:%[0-9]+]]:_(s32), [[UV1:%[0-9]+]]:_(s32), [[UV2:%[0-9]+]]:_(s32), [[UV3:%[0-9]+]]:_(s32) = G_UNMERGE_VALUES [[COPY]](<4 x s32>)
    ; CHECK-NEXT: [[DEF:%[0-9]+]]:_(s32) = G_IMPLICIT_DEF
    ; CHECK-NEXT: [[BUILD_VECTOR:%[0-9]+]]:_(<8 x s32>) = G_BUILD_VECTOR [[UV]](s32), [[UV2]](s32), [[UV1]](s32), [[UV3]](s32), [[DEF]](s32), [[DEF]](s32), [[DEF]](s32), [[DEF]](s32)
    ; CHECK-NEXT: $wl0 = COPY [[BUILD_VECTOR]](<8 x s32>)
      %10:_(<4 x s32>) = COPY $q0
      %0:_(s32), %1:_(s32), %2:_(s32), %3:_(s32) = G_UNMERGE_VALUES %10
      %4:_(s32) = G_IMPLICIT_DEF
      %11:_(<8 x s32>) = G_BUILD_VECTOR %0, %2, %1, %3, %4, %4, %4, %4
      $wl0 = COPY %11
...

# Cannot combine: missing lanes from input vector
---
name:            no_combine_missing_lanes
body:             |
  bb.1:
    ; CHECK-LABEL: name: no_combine_missing_lanes
    ; CHECK: [[COPY:%[0-9]+]]:_(<4 x s32>) = COPY $q0
    ; CHECK-NEXT: [[UV:%[0-9]+]]:_(s32), [[UV1:%[0-9]+]]:_(s32), [[UV2:%[0-9]+]]:_(s32), [[UV3:%[0-9]+]]:_(s32) = G_UNMERGE_VALUES [[COPY]](<4 x s32>)
    ; CHECK-NEXT: [[DEF:%[0-9]+]]:_(s32) = G_IMPLICIT_DEF
    ; CHECK-NEXT: [[BUILD_VECTOR:%[0-9]+]]:_(<8 x s32>) = G_BUILD_VECTOR [[UV]](s32), [[UV1]](s32), [[UV2]](s32), [[DEF]](s32), [[DEF]](s32), [[DEF]](s32), [[DEF]](s32), [[DEF]](s32)
    ; CHECK-NEXT: $wl0 = COPY [[BUILD_VECTOR]](<8 x s32>)
      %10:_(<4 x s32>) = COPY $q0
      %0:_(s32), %1:_(s32), %2:_(s32), %3:_(s32) = G_UNMERGE_VALUES %10
      %4:_(s32) = G_IMPLICIT_DEF
      %11:_(<8 x s32>) = G_BUILD_VECTOR %0, %1, %2, %4, %4, %4, %4, %4
      $wl0 = COPY %11
...

# Cannot combine: not padded with undef
---
name:            no_combine_not_undef_padded
body:             |
  bb.1:
    ; CHECK-LABEL: name: no_combine_not_undef_padded
    ; CHECK: [[COPY:%[0-9]+]]:_(<4 x s32>) = COPY $q0
    ; CHECK-NEXT: [[UV:%[0-9]+]]:_(s32), [[UV1:%[0-9]+]]:_(s32), [[UV2:%[0-9]+]]:_(s32), [[UV3:%[0-9]+]]:_(s32) = G_UNMERGE_VALUES [[COPY]](<4 x s32>)
    ; CHECK-NEXT: [[C:%[0-9]+]]:_(s32) = G_CONSTANT i32 1
    ; CHECK-NEXT: [[BUILD_VECTOR:%[0-9]+]]:_(<8 x s32>) = G_BUILD_VECTOR [[UV]](s32), [[UV2]](s32), [[UV1]](s32), [[UV3]](s32), [[C]](s32), [[C]](s32), [[C]](s32), [[C]](s32)
    ; CHECK-NEXT: $wl0 = COPY [[BUILD_VECTOR]](<8 x s32>)
      %10:_(<4 x s32>) = COPY $q0
      %0:_(s32), %1:_(s32), %2:_(s32), %3:_(s32) = G_UNMERGE_VALUES %10
      %4:_(s32) = G_CONSTANT i32 1
      %11:_(<8 x s32>) = G_BUILD_VECTOR %0, %2, %1, %3, %4, %4, %4, %4
      $wl0 = COPY %11
...

# Cannot combine: no 128-bit input vector
---
name:            no_combine_no_128_bit_input
body:             |
  bb.1:
    ; CHECK-LABEL: name: no_combine_no_128_bit_input
    ; CHECK: [[COPY:%[0-9]+]]:_(<8 x s32>) = COPY $wh0
    ; CHECK-NEXT: [[UV:%[0-9]+]]:_(s32), [[UV1:%[0-9]+]]:_(s32), [[UV2:%[0-9]+]]:_(s32), [[UV3:%[0-9]+]]:_(s32), [[UV4:%[0-9]+]]:_(s32), [[UV5:%[0-9]+]]:_(s32), [[UV6:%[0-9]+]]:_(s32), [[UV7:%[0-9]+]]:_(s32) = G_UNMERGE_VALUES [[COPY]](<8 x s32>)
    ; CHECK-NEXT: [[DEF:%[0-9]+]]:_(s32) = G_IMPLICIT_DEF
    ; CHECK-NEXT: [[BUILD_VECTOR:%[0-9]+]]:_(<16 x s32>) = G_BUILD_VECTOR [[UV]](s32), [[UV2]](s32), [[UV1]](s32), [[UV3]](s32), [[UV4]](s32), [[UV5]](s32), [[UV6]](s32), [[UV7]](s32), [[DEF]](s32), [[DEF]](s32), [[DEF]](s32), [[DEF]](s32), [[DEF]](s32), [[DEF]](s32), [[DEF]](s32), [[DEF]](s32)
    ; CHECK-NEXT: $x0 = COPY [[BUILD_VECTOR]](<16 x s32>)
      %10:_(<8 x s32>) = COPY $wh0
      %0:_(s32), %1:_(s32), %2:_(s32), %3:_(s32), %4:_(s32), %5:_(s32), %6:_(s32), %7:_(s32) = G_UNMERGE_VALUES %10
      %8:_(s32) = G_IMPLICIT_DEF
      %11:_(<16 x s32>) = G_BUILD_VECTOR %0, %2, %1, %3, %4, %5, %6, %7, %8, %8, %8, %8, %8, %8, %8, %8
      $x0 = COPY %11
...
