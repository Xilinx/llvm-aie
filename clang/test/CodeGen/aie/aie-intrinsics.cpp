// NOTE: Assertions have been autogenerated by utils/update_cc_test_checks.py
//===- aie-intrinsics.cpp ---------------------------------------*- C++ -*-===//
//
// This file is licensed under the Apache License v2.0 with LLVM Exceptions.
// See https://llvm.org/LICENSE.txt for license information.
// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
//
// (c) Copyright 2023-2024 Advanced Micro Devices, Inc. or its affiliates
//
//===----------------------------------------------------------------------===//
// RUN: %clang -O1 %s --target=aie -S -emit-llvm -o - | FileCheck %s

#ifndef __AIENGINE__
#error("missing define")
#endif
#ifndef __AIEARCH__
#error("missing arch define")
#endif

// CHECK-LABEL: @_Z6eventsv(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    tail call void @llvm.aie.event(i32 0)
// CHECK-NEXT:    tail call void @llvm.aie.event(i32 1)
// CHECK-NEXT:    tail call void @llvm.aie.event(i32 2)
// CHECK-NEXT:    tail call void @llvm.aie.event(i32 3)
// CHECK-NEXT:    tail call void @llvm.aie.event(i32 2)
// CHECK-NEXT:    ret void
//
void events() {
  event0();
  event1();
  event_done();
  event_error();
  done();
}

// CHECK-LABEL: @_Z5locksi(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    tail call void @llvm.aie.lock.acquire.reg(i32 [[N:%.*]], i32 1)
// CHECK-NEXT:    tail call void @llvm.aie.lock.acquire.reg(i32 17, i32 0)
// CHECK-NEXT:    tail call void @llvm.aie.lock.release.reg(i32 [[N]], i32 1)
// CHECK-NEXT:    tail call void @llvm.aie.lock.release.reg(i32 17, i32 0)
// CHECK-NEXT:    ret i32 1
//
int locks(int n) {
  int x = 1;
  acquire(n, x);
  acquire(17, 0);
  release(n, 1);
  release(17, 0);
  return x;
}

// CHECK-LABEL: @_Z7streamsv(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call noundef i32 @llvm.aie.get.ss(i32 0)
// CHECK-NEXT:    [[TMP1:%.*]] = tail call noundef i32 @llvm.aie.get.ss(i32 1)
// CHECK-NEXT:    tail call void @llvm.aie.put.ms(i32 0, i32 [[TMP1]])
// CHECK-NEXT:    tail call void @llvm.aie.put.ms(i32 1, i32 [[TMP0]])
// CHECK-NEXT:    ret i32 1
//
int streams() {
  int x = get_ss(0);
  int y = get_ss(1);
  put_ms(0, y);
  put_ms(1, x);
  return 1;
}

// CHECK-LABEL: @_Z12stream_tlastv(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call noundef i32 @llvm.aie.bitget.mc0(i32 1)
// CHECK-NEXT:    [[TMP1:%.*]] = tail call noundef i32 @llvm.aie.bitget.mc0(i32 2)
// CHECK-NEXT:    [[ADD2:%.*]] = add nsw i32 [[TMP1]], [[TMP0]]
// CHECK-NEXT:    [[TMP2:%.*]] = tail call noundef i32 @llvm.aie.bitget.mc0(i32 3)
// CHECK-NEXT:    [[ADD4:%.*]] = add nsw i32 [[ADD2]], [[TMP2]]
// CHECK-NEXT:    [[TMP3:%.*]] = tail call noundef i32 @llvm.aie.bitget.mc0(i32 4)
// CHECK-NEXT:    [[ADD6:%.*]] = add nsw i32 [[ADD4]], [[TMP3]]
// CHECK-NEXT:    ret i32 [[ADD6]]
//
int stream_tlast() {
  int x = 0;
  x += get_ss0_tlast();
  x += get_ss1_tlast();
  x += get_wss0_tlast();
  x += get_wss1_tlast();
  return x;
}


// CHECK-LABEL: @_Z8pckt_hdrv(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call noundef i32 @llvm.aie.packet.header(i32 31, i32 3)
// CHECK-NEXT:    tail call void @llvm.aie.put.ms(i32 0, i32 [[TMP0]])
// CHECK-NEXT:    tail call void @llvm.aie.put.ms(i32 1, i32 [[TMP0]])
// CHECK-NEXT:    [[TMP1:%.*]] = tail call noundef i32 @llvm.aie.ctrl.packet.header(i20 0, i32 3, i32 0, i32 31)
// CHECK-NEXT:    tail call void @llvm.aie.put.ms(i32 1, i32 [[TMP1]])
// CHECK-NEXT:    ret void
//
void pckt_hdr() {
  // packet_header/put_ms has 2 intrinsics mapping to 1 instruction
  int x = packet_header(31, 3);
  put_ms(0, x);
  put_ms(1, x);
  int y = ctrl_packet_header(0, 3, 0, 31);
  put_ms(1, y);
}

// CHECK-LABEL: @_Z9bitsetgetii(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call noundef i32 @llvm.aie.bitset(i32 [[A:%.*]], i32 [[B:%.*]], i32 1)
// CHECK-NEXT:    [[TMP1:%.*]] = tail call noundef i32 @llvm.aie.bitget(i32 [[A]], i32 1)
// CHECK-NEXT:    [[ADD:%.*]] = add i32 [[TMP1]], [[TMP0]]
// CHECK-NEXT:    ret i32 [[ADD]]
//
int bitsetget(int a, int b) {
  int x = bitset(a, b, 1);
  return x + bitget(a, 1);
}

v8float acc __attribute__((aligned(128)));
v8float xbuf __attribute__((aligned(128)));
v32float xbuf32 __attribute__((aligned(128)));
v8float zbuf __attribute__((aligned(128)));

// CHECK-LABEL: @_Z5fpopsDv32_fijj(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = load <8 x float>, ptr @acc, align 128, !tbaa [[TBAA2:![0-9]+]]
// CHECK-NEXT:    [[TMP1:%.*]] = load <8 x float>, ptr @zbuf, align 128, !tbaa [[TBAA2]]
// CHECK-NEXT:    [[TMP2:%.*]] = tail call noundef <8 x float> @llvm.aie.vfpmac(<8 x float> [[TMP0]], <32 x float> [[XBUF32:%.*]], i32 [[XSTART:%.*]], i32 [[XOFFS:%.*]], <8 x float> [[TMP1]], i32 0, i32 [[ZOFFS:%.*]], i32 0, i32 9437184)
// CHECK-NEXT:    [[TMP3:%.*]] = tail call noundef <8 x float> @llvm.aie.vfpmul(<32 x float> [[XBUF32]], i32 [[XSTART]], i32 [[XOFFS]], <8 x float> [[TMP2]], i32 0, i32 [[ZOFFS]], i32 0, i32 9437184)
// CHECK-NEXT:    ret <8 x float> [[TMP3]]
//
v8float fpops(v32float xbuf32, int xstart, unsigned int xoffs,
              unsigned int zoffs) {
  int zstart = 0; // Must be constant
  v8float r1 = fpmac(acc, xbuf32, xstart, xoffs, zbuf, zstart, zoffs);
  v8float r2 = fpmul(xbuf32, xstart, xoffs, r1, zstart, zoffs);
  return r2;
}
// CHECK-LABEL: @_Z7fpopaddDv32_fij(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = load <8 x float>, ptr @acc, align 128, !tbaa [[TBAA2]]
// CHECK-NEXT:    [[TMP1:%.*]] = tail call noundef <8 x float> @llvm.aie.v8f32undef()
// CHECK-NEXT:    [[TMP2:%.*]] = tail call noundef <8 x float> @llvm.aie.vfpmac(<8 x float> [[TMP0]], <32 x float> [[XBUF32:%.*]], i32 [[XSTART:%.*]], i32 [[XOFFS:%.*]], <8 x float> [[TMP1]], i32 0, i32 0, i32 0, i32 11534336)
// CHECK-NEXT:    ret <8 x float> [[TMP2]]
//
v8float fpopadd(v32float xbuf32, int xstart, unsigned int xoffs) {
  return fpadd(acc, xbuf32, xstart, xoffs);
}
// CHECK-LABEL: @_Z7fpopminDv32_fij(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = load <8 x float>, ptr @acc, align 128, !tbaa [[TBAA2]]
// CHECK-NEXT:    [[TMP1:%.*]] = tail call noundef <8 x float> @llvm.aie.v8f32undef()
// CHECK-NEXT:    [[TMP2:%.*]] = tail call noundef <8 x float> @llvm.aie.vfpmac(<8 x float> [[TMP0]], <32 x float> [[XBUF32:%.*]], i32 [[XSTART:%.*]], i32 [[XOFFS:%.*]], <8 x float> [[TMP1]], i32 0, i32 0, i32 1, i32 7340032)
// CHECK-NEXT:    ret <8 x float> [[TMP2]]
//
v8float fpopmin(v32float xbuf32, int xstart, unsigned int xoffs) {
  return fpmin(acc, xbuf32, xstart, xoffs);
}
// CHECK-LABEL: @_Z7fpopmaxDv32_fij(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = load <8 x float>, ptr @acc, align 128, !tbaa [[TBAA2]]
// CHECK-NEXT:    [[TMP1:%.*]] = tail call noundef <8 x float> @llvm.aie.v8f32undef()
// CHECK-NEXT:    [[TMP2:%.*]] = tail call noundef <8 x float> @llvm.aie.vfpmac(<8 x float> [[TMP0]], <32 x float> [[XBUF32:%.*]], i32 [[XSTART:%.*]], i32 [[XOFFS:%.*]], <8 x float> [[TMP1]], i32 0, i32 0, i32 1, i32 3145728)
// CHECK-NEXT:    ret <8 x float> [[TMP2]]
//
v8float fpopmax(v32float xbuf32, int xstart, unsigned int xoffs) {
  return fpmax(acc, xbuf32, xstart, xoffs);
}
// CHECK-LABEL: @_Z7fpopabsDv32_fij(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call noundef <8 x float> @llvm.aie.v8f32undef()
// CHECK-NEXT:    [[TMP1:%.*]] = tail call noundef <8 x float> @llvm.aie.vfpmul(<32 x float> [[XBUF32:%.*]], i32 [[XSTART:%.*]], i32 [[XOFFS:%.*]], <8 x float> [[TMP0]], i32 0, i32 0, i32 0, i32 12058624)
// CHECK-NEXT:    ret <8 x float> [[TMP1]]
//
v8float fpopabs(v32float xbuf32, int xstart, unsigned int xoffs) {
  return fpabs(xbuf32, xstart, xoffs);
}
// CHECK-LABEL: @_Z11fpopshuffleDv32_fij(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call noundef <8 x float> @llvm.aie.v8f32undef()
// CHECK-NEXT:    [[TMP1:%.*]] = tail call noundef <8 x float> @llvm.aie.vfpmul(<32 x float> [[XBUF32:%.*]], i32 [[XSTART:%.*]], i32 [[XOFFS:%.*]], <8 x float> [[TMP0]], i32 0, i32 0, i32 0, i32 11534336)
// CHECK-NEXT:    ret <8 x float> [[TMP1]]
//
v8float fpopshuffle(v32float xbuf32, int xstart, unsigned int xoffs) {
  return fpshuffle(xbuf32, xstart, xoffs);
}

// CHECK-LABEL: @_Z5fpopsv(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = load <8 x float>, ptr @acc, align 128, !tbaa [[TBAA2]]
// CHECK-NEXT:    [[TMP1:%.*]] = load <8 x float>, ptr @xbuf, align 128, !tbaa [[TBAA2]]
// CHECK-NEXT:    [[TMP2:%.*]] = load <8 x float>, ptr @zbuf, align 128, !tbaa [[TBAA2]]
// CHECK-NEXT:    [[TMP3:%.*]] = tail call noundef <8 x float> @llvm.aie.vfpsimplemac(<8 x float> [[TMP0]], <8 x float> [[TMP1]], <8 x float> [[TMP2]], i32 0, i32 9437184)
// CHECK-NEXT:    [[TMP4:%.*]] = tail call noundef <8 x float> @llvm.aie.vfpsimplemul(<8 x float> [[TMP1]], <8 x float> [[TMP3]], i32 0, i32 9437184)
// CHECK-NEXT:    ret <8 x float> [[TMP4]]
//
v8float fpops() {
  v8float r1 = fpmac(acc, xbuf, zbuf);
  v8float r2 = fpmul(xbuf, r1);
  return r2;
}
// CHECK-LABEL: @_Z7fpopaddv(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = load <8 x float>, ptr @acc, align 128, !tbaa [[TBAA2]]
// CHECK-NEXT:    [[TMP1:%.*]] = load <8 x float>, ptr @xbuf, align 128, !tbaa [[TBAA2]]
// CHECK-NEXT:    [[TMP2:%.*]] = tail call noundef <8 x float> @llvm.aie.v8f32undef()
// CHECK-NEXT:    [[TMP3:%.*]] = tail call noundef <8 x float> @llvm.aie.vfpsimplemac(<8 x float> [[TMP0]], <8 x float> [[TMP1]], <8 x float> [[TMP2]], i32 0, i32 11534336)
// CHECK-NEXT:    ret <8 x float> [[TMP3]]
//
v8float fpopadd() {
  return fpadd(acc, xbuf);
}
// CHECK-LABEL: @_Z7fpopminv(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = load <8 x float>, ptr @acc, align 128, !tbaa [[TBAA2]]
// CHECK-NEXT:    [[TMP1:%.*]] = load <8 x float>, ptr @xbuf, align 128, !tbaa [[TBAA2]]
// CHECK-NEXT:    [[TMP2:%.*]] = tail call noundef <8 x float> @llvm.aie.v8f32undef()
// CHECK-NEXT:    [[TMP3:%.*]] = tail call noundef <8 x float> @llvm.aie.vfpsimplemac(<8 x float> [[TMP0]], <8 x float> [[TMP1]], <8 x float> [[TMP2]], i32 1, i32 7340032)
// CHECK-NEXT:    ret <8 x float> [[TMP3]]
//
v8float fpopmin() {
  return fpmin(acc, xbuf);
}
// CHECK-LABEL: @_Z7fpopmaxv(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = load <8 x float>, ptr @acc, align 128, !tbaa [[TBAA2]]
// CHECK-NEXT:    [[TMP1:%.*]] = load <8 x float>, ptr @xbuf, align 128, !tbaa [[TBAA2]]
// CHECK-NEXT:    [[TMP2:%.*]] = tail call noundef <8 x float> @llvm.aie.v8f32undef()
// CHECK-NEXT:    [[TMP3:%.*]] = tail call noundef <8 x float> @llvm.aie.vfpsimplemac(<8 x float> [[TMP0]], <8 x float> [[TMP1]], <8 x float> [[TMP2]], i32 1, i32 3145728)
// CHECK-NEXT:    ret <8 x float> [[TMP3]]
//
v8float fpopmax() {
  return fpmax(acc, xbuf);
}
// CHECK-LABEL: @_Z7fpopabsv(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = load <8 x float>, ptr @xbuf, align 128, !tbaa [[TBAA2]]
// CHECK-NEXT:    [[TMP1:%.*]] = tail call noundef <8 x float> @llvm.aie.v8f32undef()
// CHECK-NEXT:    [[TMP2:%.*]] = tail call noundef <8 x float> @llvm.aie.vfpsimplemul(<8 x float> [[TMP0]], <8 x float> [[TMP1]], i32 0, i32 12058624)
// CHECK-NEXT:    ret <8 x float> [[TMP2]]
//
v8float fpopabs() {
  return fpabs(xbuf);
}
// CHECK-LABEL: @_Z12test_v8acc48v(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call noundef <8 x i48> @llvm.aie.v8i48undef()
// CHECK-NEXT:    ret <8 x i48> [[TMP0]]
//
v8acc48 test_v8acc48()
{
  return undef_v8acc48();
}
// CHECK-LABEL: @_Z12test_v8acc80v(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call noundef <16 x i48> @llvm.aie.v16i48undef()
// CHECK-NEXT:    ret <16 x i48> [[TMP0]]
//
v8acc80 test_v8acc80()
{
  return undef_v8acc80();
}
// CHECK-LABEL: @_Z10test_lmul4v(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call noundef <2 x i32> @llvm.aie.v2i32undef()
// CHECK-NEXT:    [[VECINS_I:%.*]] = insertelement <2 x i32> [[TMP0]], i32 1985229328, i64 0
// CHECK-NEXT:    [[TMP1:%.*]] = tail call noundef <8 x i48> @llvm.aie.lmul4.v32int32(<32 x i32> undef, <8 x i32> undef, i32 0, i32 0, i32 1, <2 x i32> [[VECINS_I]], <2 x i32> [[VECINS_I]], <2 x i32> <i32 1, i32 0>)
// CHECK-NEXT:    ret <8 x i48> [[TMP1]]
//
v4acc80 test_lmul4()
{
  v32int32 xbuff;
  v8int32 *zbuff;
  return lmul4(xbuff, 0, 0x76543210, 1, zbuff[0], 1, 0x76543210, 0);
}
extern void foo(v8acc48);
// CHECK-LABEL: @_Z12call_v8acc48v(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call noundef <8 x i48> @llvm.aie.v8i48undef()
// CHECK-NEXT:    tail call void @_Z3fooDv8_u7__acc48(<8 x i48> noundef [[TMP0]])
// CHECK-NEXT:    ret void
//
void call_v8acc48()
{
  foo(undef_v8acc48());
}

extern void bar(v8acc80);
// CHECK-LABEL: @_Z12call_v8acc80v(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call noundef <16 x i48> @llvm.aie.v16i48undef()
// CHECK-NEXT:    tail call void @_Z3barDv16_u7__acc48(<16 x i48> noundef [[TMP0]])
// CHECK-NEXT:    ret void
//
void call_v8acc80()
{
  bar(undef_v8acc80());
}

extern void foo_v4acc80(v4acc80);
// CHECK-LABEL: @_Z12call_v4acc80v(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call noundef <8 x i48> @llvm.aie.v8i48undef()
// CHECK-NEXT:    tail call void @_Z11foo_v4acc80Dv8_u7__acc48(<8 x i48> noundef [[TMP0]])
// CHECK-NEXT:    ret void
//
void call_v4acc80()
{
 foo_v4acc80(undef_v4acc80());
}

extern void foo_v16acc48(v16acc48);
// CHECK-LABEL: @_Z13call_v16acc48v(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call noundef <16 x i48> @llvm.aie.v16i48undef()
// CHECK-NEXT:    tail call void @_Z12foo_v16acc48Dv16_u7__acc48(<16 x i48> noundef [[TMP0]])
// CHECK-NEXT:    ret void
//
void call_v16acc48()
{
 foo_v16acc48(undef_v16acc48());
}

// CHECK-LABEL: @_Z9bsrs_testv(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call noundef <16 x i8> @llvm.aie.bsrs.v16i8.v16acc48(<16 x i48> undef, i32 2)
// CHECK-NEXT:    ret <16 x i8> [[TMP0]]
//
v16int8 bsrs_test()
{
  v16acc48 bm;
  v16int8 val = bsrs(bm, 2);
  return val;
}
// CHECK-LABEL: @_Z10ubsrs_testv(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call noundef <16 x i8> @llvm.aie.ubsrs.v16i8.v16acc48(<16 x i48> undef, i32 2)
// CHECK-NEXT:    ret <16 x i8> [[TMP0]]
//
v16uint8 ubsrs_test()
{
  v16acc48 bm;
  v16uint8 val = ubsrs(bm, 2);
  return val;
}
// CHECK-LABEL: @_Z12bsrs_st_testv(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[VAL:%.*]] = alloca <16 x i8>, align 16
// CHECK-NEXT:    call void @llvm.lifetime.start.p0(i64 16, ptr nonnull [[VAL]])
// CHECK-NEXT:    [[TMP0:%.*]] = tail call noundef <16 x i8> @llvm.aie.bsrs.v16i8.v16acc48(<16 x i48> undef, i32 2)
// CHECK-NEXT:    store volatile <16 x i8> [[TMP0]], ptr [[VAL]], align 16, !tbaa [[TBAA2]]
// CHECK-NEXT:    call void @llvm.lifetime.end.p0(i64 16, ptr nonnull [[VAL]])
// CHECK-NEXT:    ret void
//
void bsrs_st_test()
{
  v16acc48 bm;
  volatile v16int8 val = bsrs(bm, 2);
}
// CHECK-LABEL: @_Z9mac16_symDv16_u7__acc48Dv64_sDv8_i(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call noundef <2 x i32> @llvm.aie.v2i32undef()
// CHECK-NEXT:    [[TMP1:%.*]] = tail call noundef <16 x i48> @llvm.aie.mac16.v64int16(<64 x i16> [[LBUFF:%.*]], <8 x i32> [[RBUFF:%.*]], <16 x i48> [[ACC:%.*]], i32 2, i32 2, i32 12, <2 x i32> <i32 50462976, i32 8464>, <2 x i32> <i32 117835012, i32 4609>, <2 x i32> <i32 32768, i32 0>)
// CHECK-NEXT:    ret <16 x i48> [[TMP1]]
//
v16acc48 mac16_sym(v16acc48 acc, v64int16 lbuff, v8int32 rbuff) {
  return mac16_sym(acc, lbuff, 2, 0x03020100, 0x2110, 2, rbuff, 12, 0x07060504, 0x1201);
}
// CHECK-LABEL: @_Z5msc16Dv16_u7__acc48Dv128_aDv32_a(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call noundef <2 x i32> @llvm.aie.v2i32undef()
// CHECK-NEXT:    [[VECINS_I:%.*]] = insertelement <2 x i32> [[TMP0]], i32 50462976, i64 0
// CHECK-NEXT:    [[VECINS2_I:%.*]] = insertelement <2 x i32> [[TMP0]], i32 117835012, i64 0
// CHECK-NEXT:    [[TMP1:%.*]] = tail call noundef <16 x i48> @llvm.aie.mac16.v128int8(<128 x i8> [[XBUFF:%.*]], <32 x i8> [[ZBUFF:%.*]], <16 x i48> [[ACC:%.*]], i32 32, i32 0, i32 0, <2 x i32> [[VECINS_I]], <2 x i32> [[VECINS2_I]], <2 x i32> <i32 256, i32 169108>)
// CHECK-NEXT:    ret <16 x i48> [[TMP1]]
//
v16acc48 msc16(v16acc48 acc, v128int8 xbuff, v32int8 zbuff) {
  return msc16(acc, xbuff, 32, 0x03020100, 0, 0x2110, zbuff, 0, 0x07060504, 1, 0x2110);
}
// CHECK-LABEL: @_Z13mul16_antisymDv32_iDv16_s(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call noundef <2 x i32> @llvm.aie.v2i32undef()
// CHECK-NEXT:    [[TMP1:%.*]] = tail call noundef <16 x i48> @llvm.aie.mul16.v32int32(<32 x i32> [[XBUFF:%.*]], <16 x i16> [[ZBUFF:%.*]], i32 0, i32 16, i32 0, <2 x i32> <i32 286265616, i32 12576>, <2 x i32> <i32 -2004353024, i32 12816>, <2 x i32> <i32 98304, i32 0>)
// CHECK-NEXT:    ret <16 x i48> [[TMP1]]
//
v16acc48 mul16_antisym(v32int32 xbuff, v16int16 zbuff) {
  return mul16_antisym(xbuff, 0, 0x11101110, 0x3120, 16, zbuff, 0, 0x88880000, 0x3210);
}
// CHECK-LABEL: @_Z8negmul16Dv128_aDv32_a(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call noundef <2 x i32> @llvm.aie.v2i32undef()
// CHECK-NEXT:    [[VECINS_I:%.*]] = insertelement <2 x i32> [[TMP0]], i32 286265616, i64 0
// CHECK-NEXT:    [[VECINS2_I:%.*]] = insertelement <2 x i32> [[TMP0]], i32 -2004353024, i64 0
// CHECK-NEXT:    [[TMP1:%.*]] = tail call noundef <16 x i48> @llvm.aie.mul16.v128int8(<128 x i8> [[XBUFF:%.*]], <32 x i8> [[ZBUFF:%.*]], i32 0, i32 0, i32 0, <2 x i32> [[VECINS_I]], <2 x i32> [[VECINS2_I]], <2 x i32> <i32 520, i32 189656>)
// CHECK-NEXT:    ret <16 x i48> [[TMP1]]
//
v16acc48 negmul16(v128int8 xbuff, v32int8 zbuff) {
  return negmul16(xbuff, 0, 0x11101110, 16, 0x3120, zbuff, 0, 0x88880000, 2, 0x3210);
}
short *data;
// CHECK-LABEL: @_Z3foov(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = load ptr, ptr @data, align 4, !tbaa [[TBAA5:![0-9]+]]
// CHECK-NEXT:    [[TMP1:%.*]] = load <16 x i16>, ptr [[TMP0]], align 32, !tbaa [[TBAA2]]
// CHECK-NEXT:    [[TMP2:%.*]] = tail call noundef <16 x i8> @llvm.aie.pack.v16int16(<16 x i16> [[TMP1]])
// CHECK-NEXT:    ret <16 x i8> [[TMP2]]
//
v16int8 foo()
{
  v16int8   vecss =  pack(*(v16int16 *)data);
  return vecss;
}
